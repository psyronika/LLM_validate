{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1873f282-448b-4782-bcb6-c6caeba696c1",
   "metadata": {},
   "source": [
    "# Analysis of LLM-assisted human validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6ba838c-c786-4840-845d-5f0aa6848017",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import simpledorff\n",
    "from scipy.stats import ttest_ind"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b0d946-29a7-4e49-8900-ed22ff95b1e5",
   "metadata": {},
   "source": [
    "### Read in annotation data\n",
    "\n",
    "Half of the full validation set has been assisted and the other half has not been assisted. All 3 coders coded the unasisted set (df4), while coder 1 coded LLM-assited by LlaMA 7B, coder 2 coded LLM-assisted set by LlaMA 13B, and coder 3 coded LLM-assisted by both LlaMA 7B and Llama 13. Importantly these were all the same set of annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "725a5885-898b-4061-adee-f4e0af6d64e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('../LLM_7B_assisted.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "id": "0a864f4e-af61-4b40-bd03-9411ae1ad99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('../LLM_13B_assisted.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "id": "12d4f8f6-fd77-4235-8dd3-6adb29f2e557",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.read_csv('../LLM_mixed_assisted.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "620614cf-fca7-4a9f-a11e-1a9c2a19d930",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = pd.read_csv('../LLM_not_assisted.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b995731d-f9ad-4b75-8492-bc8bde861b89",
   "metadata": {},
   "source": [
    "### Calculate within annotator differences between the assisted versus the unassisted validation set "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3676fab2-cb33-4471-a465-515bd5e2246e",
   "metadata": {},
   "source": [
    "### 1. Annotation speed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1e22e5-f1cc-4452-b5ea-5ebf8f69e7ce",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Annotator A\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f676981-4398-41ae-81ad-d12d58ab7634",
   "metadata": {},
   "source": [
    "##### For LLM-assisted 7B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "57d30672-684c-47e6-ad36-3603e9ef479b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean time for completing topic-level and event-level matches: 12.855041414141414\n"
     ]
    }
   ],
   "source": [
    "#get avarege time to complete tasks overall\n",
    "\n",
    "# Assuming your DataFrame is named df1\n",
    "mean_time = df1.loc[df1['variable'].isin(['topic_match', 'event_match']), 'seconds'].mean()\n",
    "print(\"Mean time for completing topic-level and event-level matches:\", mean_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "12914f0c-076e-4826-a681-57364c7442f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average time to complete topic-level matches: 23.939715151515152\n"
     ]
    }
   ],
   "source": [
    "#get avarege time to complete tasks for topic-level match\n",
    "\n",
    "# Assuming your DataFrame is named df1\n",
    "topic_mean_time = df1.loc[df1['variable'] == 'topic_match', 'seconds'].mean()\n",
    "\n",
    "print(\"Average time to complete topic-level matches:\", topic_mean_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "27799a2c-0b0f-4201-8541-a99f01ff6d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average time to complete event-level matches: 1.770367676767677\n"
     ]
    }
   ],
   "source": [
    "#get avarege time to complete tasks event-level match\n",
    "# Assuming your DataFrame is named df1\n",
    "event_mean_time = df1.loc[df1['variable'] == 'event_match', 'seconds'].mean()\n",
    "\n",
    "print(\"Average time to complete event-level matches:\", event_mean_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced43a41-f564-440f-a247-be91fe1b1e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get avarege time to complete tasks event-level match\n",
    "# Assuming your DataFrame is named df1\n",
    "event_mean_time = df1.loc[df1['variable'] == 'event_match', 'seconds'].mean()\n",
    "\n",
    "print(\"Average time to complete event-level matches:\", event_mean_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4960a007-86a1-4dec-acea-0b29b98faa9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean time for completing confidence rating for topic-level and event-level matches: 1.339130303030303\n"
     ]
    }
   ],
   "source": [
    "#get avarege time to complete confidence overall\n",
    "\n",
    "mean_time = df1.loc[df1['variable'].isin(['confidence_1', 'confidence_2']), 'seconds'].mean()\n",
    "print(\"Mean time for completing confidence rating for topic-level and event-level matches:\", mean_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f684e47-f406-4462-acff-427c329bd3db",
   "metadata": {},
   "source": [
    "##### For not assisted "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ee4b6959-8188-4781-990b-8d52b133dd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get only the codings of annotator 1\n",
    "\n",
    "# Assuming your DataFrame is named df4\n",
    "df1_1 = df4[df4['coder_id'] == 2608]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "823b4e3b-9196-44a8-9abe-9308a610c2df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean time for completing topic-level and event-level matches unassisted: 6.448849494949494\n"
     ]
    }
   ],
   "source": [
    "# Assuming your DataFrame is named df1\n",
    "mean_time = df1_1.loc[df1_1['variable'].isin(['topic_match', 'event_match']), 'seconds'].mean()\n",
    "print(\"Mean time for completing topic-level and event-level matches unassisted:\", mean_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "76a55e49-8bce-4e05-8e26-47d6943a1dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average time to complete topic-level matches unassited: 11.173923232323231\n"
     ]
    }
   ],
   "source": [
    "#get avarege time to complete tasks for topic-level match\n",
    "\n",
    "# Assuming your DataFrame is named df1\n",
    "topic_mean_time = df1_1.loc[df1_1['variable'] == 'topic_match', 'seconds'].mean()\n",
    "\n",
    "print(\"Average time to complete topic-level matches unassisted:\", topic_mean_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1f8aa62c-5bfa-4349-99bc-bbfde750dc9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average time to complete event-level matches: 1.7237757575757575\n"
     ]
    }
   ],
   "source": [
    "#get avarege time to complete tasks event-level match\n",
    "# Assuming your DataFrame is named df1\n",
    "event_mean_time = df1_1.loc[df1_1['variable'] == 'event_match', 'seconds'].mean()\n",
    "\n",
    "print(\"Average time to complete event-level matches unassisted:\", event_mean_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1ee1d213-f4b1-4a2c-9b30-7054588a1632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean time for completing confidence rating for topic-level and event-level matches: 1.5567313131313132\n"
     ]
    }
   ],
   "source": [
    "#get avarege time to complete confidence overall\n",
    "\n",
    "mean_time = df1_1.loc[df1_1['variable'].isin(['confidence_1', 'confidence_2']), 'seconds'].mean()\n",
    "print(\"Mean time for completing confidence rating for topic-level and event-level matches:\", mean_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443e4c68-0181-4e9f-a930-156470ed3add",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Annotator B\n",
    "\n",
    "#### For LLM-assisted 13B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e5218815-1add-48e5-a64c-61cf18bdd53a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean time for completing topic-level and event-level matches: 17.430112121212122\n"
     ]
    }
   ],
   "source": [
    "#get avarege time to complete tasks overall\n",
    "\n",
    "# Assuming your DataFrame is named df1\n",
    "mean_time = df2.loc[df2['variable'].isin(['topic_match', 'event_match']), 'seconds'].mean()\n",
    "print(\"Mean time for completing topic-level and event-level matches:\", mean_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "837c7beb-c6c8-4d56-9e0e-04d72afecfe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average time to complete topic-level matches: 20.77467676767677\n"
     ]
    }
   ],
   "source": [
    "#get avarege time to complete tasks for topic-level match\n",
    "\n",
    "# Assuming your DataFrame is named df1\n",
    "topic_mean_time = df2.loc[df2['variable'] == 'topic_match', 'seconds'].mean()\n",
    "\n",
    "print(\"Average time to complete topic-level matches:\", topic_mean_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4c04e68a-1af7-417b-b826-54e2e8ddefbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average time to complete event-level matches: 14.085547474747475\n"
     ]
    }
   ],
   "source": [
    "#get avarege time to complete tasks for event-level match\n",
    "\n",
    "# Assuming your DataFrame is named df1\n",
    "event_mean_time = df2.loc[df2['variable'] == 'event_match', 'seconds'].mean()\n",
    "\n",
    "print(\"Average time to complete event-level matches:\", event_mean_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9637e6c8-1b75-4e52-b612-8cea8b0da826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean time for completing confidence rating for topic-level and event-level matches: 1.8730373737373738\n"
     ]
    }
   ],
   "source": [
    "#get avarege time to complete confidence overall\n",
    "\n",
    "mean_time = df2.loc[df2['variable'].isin(['confidence_1', 'confidence_2']), 'seconds'].mean()\n",
    "print(\"Mean time for completing confidence rating for topic-level and event-level matches:\", mean_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c02f536-396d-4090-9bdc-6c2d7af1e348",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### For not assisted "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e3670336-5259-444f-a5da-bf5a7bc6d240",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get only the codings of annotator 2\n",
    "\n",
    "# Assuming your DataFrame is named df4\n",
    "df2_1 = df4[df4['coder_id'] == 2606]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4d0750b3-84c7-4c39-a5b1-2153a350d7e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean time for completing topic-level and event-level matches unassisted: 14.81311111111111\n"
     ]
    }
   ],
   "source": [
    "# Assuming your DataFrame is named df1\n",
    "mean_time = df2_1.loc[df2_1['variable'].isin(['topic_match', 'event_match']), 'seconds'].mean()\n",
    "print(\"Mean time for completing topic-level and event-level matches unassisted:\", mean_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b8984c06-5fd5-4bf0-9c27-4ab6b5f035b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average time to complete topic-level matches unassisted: 20.280268686868688\n"
     ]
    }
   ],
   "source": [
    "#get avarege time to complete tasks for topic-level match\n",
    "\n",
    "# Assuming your DataFrame is named df1\n",
    "topic_mean_time = df2_1.loc[df2_1['variable'] == 'topic_match', 'seconds'].mean()\n",
    "\n",
    "print(\"Average time to complete topic-level matches unassisted:\", topic_mean_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "87b5849f-6874-4571-a4a7-e6632d81953a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average time to complete event-level matches unassisted: 9.345953535353535\n"
     ]
    }
   ],
   "source": [
    "#get avarege time to complete tasks event-level match\n",
    "# Assuming your DataFrame is named df1\n",
    "event_mean_time = df2_1.loc[df2_1['variable'] == 'event_match', 'seconds'].mean()\n",
    "\n",
    "print(\"Average time to complete event-level matches unassisted:\", event_mean_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "286998d8-664b-45de-a882-bf018bfb8940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean time for completing confidence rating for topic-level and event-level matches: 2.872646464646465\n"
     ]
    }
   ],
   "source": [
    "#get avarege time to complete confidence overall\n",
    "\n",
    "mean_time = df2_1.loc[df2_1['variable'].isin(['confidence_1', 'confidence_2']), 'seconds'].mean()\n",
    "print(\"Mean time for completing confidence rating for topic-level and event-level matches:\", mean_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a84283-0fbf-4712-b321-47c248dab61f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Annotator C\n",
    "\n",
    "#### For LLM_mixed partially assisted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "929bc55a-3227-49b3-b11a-c2e873387455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean time for completing topic-level and event-level matches: 5.112763636363637\n"
     ]
    }
   ],
   "source": [
    "#get avarege time to complete tasks overall\n",
    "\n",
    "# Assuming your DataFrame is named df1\n",
    "mean_time = df3.loc[df3['variable'].isin(['topic_match', 'event_match']), 'seconds'].mean()\n",
    "print(\"Mean time for completing topic-level and event-level matches:\", mean_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "dd8eb34b-a9b9-4772-a839-9f20947f4677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average time to complete topic-level matches: 8.849515151515153\n"
     ]
    }
   ],
   "source": [
    "#get avarege time to complete tasks for topic-level match\n",
    "\n",
    "# Assuming your DataFrame is named df1\n",
    "topic_mean_time = df3.loc[df3['variable'] == 'topic_match', 'seconds'].mean()\n",
    "\n",
    "print(\"Average time to complete topic-level matches:\", topic_mean_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2664d6b2-fb7f-403b-bddd-2e406ba27b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average time to complete event-level matches: 1.3760121212121212\n"
     ]
    }
   ],
   "source": [
    "#get avarege time to complete tasks for event-level match\n",
    "\n",
    "# Assuming your DataFrame is named df1\n",
    "event_mean_time = df3.loc[df3['variable'] == 'event_match', 'seconds'].mean()\n",
    "\n",
    "print(\"Average time to complete event-level matches:\", event_mean_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6050b94a-0393-4223-80df-d8d811c99fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean time for completing confidence rating for topic-level and event-level matches: 1.2556757575757578\n"
     ]
    }
   ],
   "source": [
    "#get avarege time to complete confidence overall\n",
    "\n",
    "mean_time = df3.loc[df3['variable'].isin(['confidence_1', 'confidence_2']), 'seconds'].mean()\n",
    "print(\"Mean time for completing confidence rating for topic-level and event-level matches:\", mean_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2860450f-0686-4e28-88ea-2cde513a344b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2608, 2607, 2606])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4['coder_id'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1583d368-565a-4f2f-a1dd-f6a04e3269ec",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### For not assisted "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2dc4b7eb-4c2d-4f2e-ae03-74d3587fc250",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get only the codings of annotator 2\n",
    "\n",
    "# Assuming your DataFrame is named df4\n",
    "df3_1 = df4[df4['coder_id'] == 2607]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d10e7e1e-e2b5-411b-ab26-e74dc48f4ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean time for completing topic-level and event-level matches unassisted: 9.004171717171719\n"
     ]
    }
   ],
   "source": [
    "# Assuming your DataFrame is named df1\n",
    "mean_time = df3_1.loc[df3_1['variable'].isin(['topic_match', 'event_match']), 'seconds'].mean()\n",
    "print(\"Mean time for completing topic-level and event-level matches unassisted:\", mean_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "aef25e3d-8d4c-438c-9bd9-f7ba1b2bfb2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average time to complete topic-level matches unassisted: 14.414521212121212\n"
     ]
    }
   ],
   "source": [
    "#get avarege time to complete tasks for topic-level match\n",
    "\n",
    "# Assuming your DataFrame is named df1\n",
    "topic_mean_time = df3_1.loc[df3_1['variable'] == 'topic_match', 'seconds'].mean()\n",
    "\n",
    "print(\"Average time to complete topic-level matches unassisted:\", topic_mean_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8e89f79d-0ff7-428e-86df-d1300e995603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average time to complete event-level matches unassisted: 3.5938222222222223\n"
     ]
    }
   ],
   "source": [
    "#get avarege time to complete tasks event-level match\n",
    "# Assuming your DataFrame is named df1\n",
    "event_mean_time = df3_1.loc[df3_1['variable'] == 'event_match', 'seconds'].mean()\n",
    "\n",
    "print(\"Average time to complete event-level matches unassisted:\", event_mean_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ef65321b-a934-4d48-88c3-fa07af24b021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean time for completing confidence rating for topic-level and event-level matches: 1.5022444444444445\n"
     ]
    }
   ],
   "source": [
    "#get avarege time to complete confidence overall\n",
    "\n",
    "mean_time = df3_1.loc[df3_1['variable'].isin(['confidence_1', 'confidence_2']), 'seconds'].mean()\n",
    "print(\"Mean time for completing confidence rating for topic-level and event-level matches:\", mean_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45154bed-1e2a-45ab-8a56-84957c787e37",
   "metadata": {},
   "source": [
    "#### Within Annotators comparison (annotation speed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "28c2a23a-068d-4cb8-aa93-662f55066633",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to calculate independent samples t-test within annotators\n",
    "\n",
    "def perform_independent_t_test(df1, df2, test_type='overall'):\n",
    "    # Exclude rows where 'variable' is 'confidence'\n",
    "    filtered_df1 = df1[~((df1['variable'] == 'confidence_1') | (df1['variable'] == 'confidence_2'))]\n",
    "    filtered_df2 = df2[~((df2['variable'] == 'confidence_1') | (df2['variable'] == 'confidence_2'))]\n",
    "\n",
    "    if test_type == 'overall':\n",
    "        variable_name = 'Overall'\n",
    "    elif test_type == 'topic_match':\n",
    "        filtered_df1 = filtered_df1[filtered_df1['variable'] == 'topic_match']\n",
    "        filtered_df2 = filtered_df2[filtered_df2['variable'] == 'topic_match']\n",
    "        variable_name = 'Topic Match'\n",
    "    elif test_type == 'event_match':\n",
    "        filtered_df1 = filtered_df1[filtered_df1['variable'] == 'event_match']\n",
    "        filtered_df2 = filtered_df2[filtered_df2['variable'] == 'event_match']\n",
    "        variable_name = 'Event Match'\n",
    "    else:\n",
    "        raise ValueError(\"Invalid test_type. Use 'overall', 'topic_match', or 'event_match'.\")\n",
    "    \n",
    "    # Extract 'seconds' column\n",
    "    seconds_df1 = filtered_df1['seconds']\n",
    "    seconds_df2 = filtered_df2['seconds']\n",
    "\n",
    "    # Perform t-test\n",
    "    t_stat, p_value = ttest_ind(seconds_df1, seconds_df2)\n",
    "\n",
    "    # Calculate means and standard deviations\n",
    "    mean_df1 = seconds_df1.mean()\n",
    "    mean_df2 = seconds_df2.mean()\n",
    "    std_df1 = seconds_df1.std()\n",
    "    std_df2 = seconds_df2.std()\n",
    "\n",
    "    # Print the statistics\n",
    "    print(f\"Mean of df1 '{variable_name}' seconds: {mean_df1}\")\n",
    "    print(f\"Standard deviation of df1 '{variable_name}' seconds: {std_df1}\")\n",
    "    print()\n",
    "    print(f\"Mean of df2 '{variable_name}' seconds: {mean_df2}\")\n",
    "    print(f\"Standard deviation of df2 '{variable_name}' seconds: {std_df2}\")\n",
    "    print()\n",
    "    print(f\"T-statistic for '{variable_name}': {t_stat}\")\n",
    "    print(f\"P-value for '{variable_name}': {p_value}\")\n",
    "\n",
    "    # Check p-value\n",
    "    if p_value < 0.05:\n",
    "        print(f\"The difference in '{variable_name}' seconds is statistically significant.\")\n",
    "    else:\n",
    "        print(f\"There is no statistically significant difference in '{variable_name}' seconds.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac12a5b-f243-402b-9d78-35b6c864750c",
   "metadata": {},
   "source": [
    "#### Annotator A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d3aae25c-5bbf-4c23-907d-8e8f7cfda98d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of df1 'Overall' seconds: 12.855041414141414\n",
      "Standard deviation of df1 'Overall' seconds: 130.2492764574991\n",
      "\n",
      "Mean of df2 'Overall' seconds: 6.448849494949494\n",
      "Standard deviation of df2 'Overall' seconds: 19.538858852926786\n",
      "\n",
      "T-statistic for 'Overall': 1.5304172318196783\n",
      "P-value for 'Overall': 0.1260733890837042\n",
      "There is no statistically significant difference in 'Overall' seconds.\n",
      "Mean of df1 'Topic Match' seconds: 23.939715151515152\n",
      "Standard deviation of df1 'Topic Match' seconds: 183.58216538084721\n",
      "\n",
      "Mean of df2 'Topic Match' seconds: 11.173923232323231\n",
      "Standard deviation of df2 'Topic Match' seconds: 26.673838939139973\n",
      "\n",
      "T-statistic for 'Topic Match': 1.5310288770978204\n",
      "P-value for 'Topic Match': 0.12608236321371927\n",
      "There is no statistically significant difference in 'Topic Match' seconds.\n",
      "Mean of df1 'Event Match' seconds: 1.770367676767677\n",
      "Standard deviation of df1 'Event Match' seconds: 3.9295046295647627\n",
      "\n",
      "Mean of df2 'Event Match' seconds: 1.7237757575757575\n",
      "Standard deviation of df2 'Event Match' seconds: 2.840792299141299\n",
      "\n",
      "T-statistic for 'Event Match': 0.21378471725047693\n",
      "P-value for 'Event Match': 0.830759052305562\n",
      "There is no statistically significant difference in 'Event Match' seconds.\n"
     ]
    }
   ],
   "source": [
    "perform_independent_t_test(df1, df1_1, test_type='overall')\n",
    "perform_independent_t_test(df1, df1_1, test_type='topic_match')\n",
    "perform_independent_t_test(df1, df1_1, test_type='event_match')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcc5d7b-839d-4081-b9cf-b0dd0d3ba174",
   "metadata": {},
   "source": [
    "#### Annotator B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "80625f39-e5f3-4b2e-977c-fc7a7d12a517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of df1 'Overall' seconds: 17.430112121212122\n",
      "Standard deviation of df1 'Overall' seconds: 78.71832765881116\n",
      "\n",
      "Mean of df2 'Overall' seconds: 14.81311111111111\n",
      "Standard deviation of df2 'Overall' seconds: 85.22320782694844\n",
      "\n",
      "T-statistic for 'Overall': 0.7097507998217069\n",
      "P-value for 'Overall': 0.47794234154057214\n",
      "There is no statistically significant difference in 'Overall' seconds.\n",
      "Mean of df1 'Topic Match' seconds: 20.77467676767677\n",
      "Standard deviation of df1 'Topic Match' seconds: 73.00063209276952\n",
      "\n",
      "Mean of df2 'Topic Match' seconds: 20.280268686868688\n",
      "Standard deviation of df2 'Topic Match' seconds: 68.70245099855636\n",
      "\n",
      "T-statistic for 'Topic Match': 0.10972969298119084\n",
      "P-value for 'Topic Match': 0.9126460340869996\n",
      "There is no statistically significant difference in 'Topic Match' seconds.\n",
      "Mean of df1 'Event Match' seconds: 14.085547474747475\n",
      "Standard deviation of df1 'Event Match' seconds: 83.98919033966345\n",
      "\n",
      "Mean of df2 'Event Match' seconds: 9.345953535353535\n",
      "Standard deviation of df2 'Event Match' seconds: 98.79658554554072\n",
      "\n",
      "T-statistic for 'Event Match': 0.8131973457200112\n",
      "P-value for 'Event Match': 0.4163008385981418\n",
      "There is no statistically significant difference in 'Event Match' seconds.\n"
     ]
    }
   ],
   "source": [
    "perform_independent_t_test(df2, df2_1, test_type='overall')\n",
    "perform_independent_t_test(df2, df2_1, test_type='topic_match')\n",
    "perform_independent_t_test(df2, df2_1, test_type='event_match')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687ee599-1db7-4b8f-9f45-cab208a45926",
   "metadata": {},
   "source": [
    "#### Annotator C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "00d3eaa6-2be9-4ccc-a42b-676de58f7020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of df1 'Overall' seconds: 5.112763636363637\n",
      "Standard deviation of df1 'Overall' seconds: 40.26040445706177\n",
      "\n",
      "Mean of df2 'Overall' seconds: 9.004171717171719\n",
      "Standard deviation of df2 'Overall' seconds: 68.73251134613238\n",
      "\n",
      "T-statistic for 'Overall': -1.5371157262553772\n",
      "P-value for 'Overall': 0.12442491121593799\n",
      "There is no statistically significant difference in 'Overall' seconds.\n",
      "Mean of df1 'Topic Match' seconds: 8.849515151515153\n",
      "Standard deviation of df1 'Topic Match' seconds: 56.69286271113746\n",
      "\n",
      "Mean of df2 'Topic Match' seconds: 14.414521212121212\n",
      "Standard deviation of df2 'Topic Match' seconds: 96.69664705324132\n",
      "\n",
      "T-statistic for 'Topic Match': -1.1045838980622236\n",
      "P-value for 'Topic Match': 0.2696088598239705\n",
      "There is no statistically significant difference in 'Topic Match' seconds.\n",
      "Mean of df1 'Event Match' seconds: 1.3760121212121212\n",
      "Standard deviation of df1 'Event Match' seconds: 1.7371444202181017\n",
      "\n",
      "Mean of df2 'Event Match' seconds: 3.5938222222222223\n",
      "Standard deviation of df2 'Event Match' seconds: 6.998248402648565\n",
      "\n",
      "T-statistic for 'Event Match': -6.843115742969086\n",
      "P-value for 'Event Match': 1.3577794099098096e-11\n",
      "The difference in 'Event Match' seconds is statistically significant.\n"
     ]
    }
   ],
   "source": [
    "perform_independent_t_test(df3, df3_1, test_type='overall')\n",
    "perform_independent_t_test(df3, df3_1, test_type='topic_match')\n",
    "perform_independent_t_test(df3, df3_1, test_type='event_match')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feab0bf5-1143-4d88-946b-317e505044dd",
   "metadata": {},
   "source": [
    "### 2. Annotation confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c90047ac-0ebd-45e1-ad01-e0e9b8294c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get rows where only confidence metrics present\n",
    "\n",
    "desired_variables = ['confidence_1', 'confidence_2']\n",
    "filtered_df1 = df1[df1['variable'].isin(desired_variables)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "d69afd12-d286-453f-96df-81b33eea52f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_and_calculate_mean(df):\n",
    "    # Assuming your DataFrame is named df\n",
    "    desired_variables = ['confidence_1', 'confidence_2']\n",
    "    filtered_df = df[df['variable'].isin(desired_variables)]\n",
    "\n",
    "    # Recode values\n",
    "    recode_map = {'--': 0, '-': 1, '+/-': 2, '+': 3, '++': 4}\n",
    "    filtered_df['value'] = filtered_df['value'].replace(recode_map)\n",
    "\n",
    "    # Pivot the DataFrame\n",
    "    pivoted_df = filtered_df.pivot_table(index='unit_id',\n",
    "                                         columns='variable',\n",
    "                                         values='value',\n",
    "                                         aggfunc='first').reset_index()\n",
    "\n",
    "    # If you want to fill NaN values with something, you can use the fillna method\n",
    "    pivoted_df.fillna(0, inplace=True)\n",
    "\n",
    "    # Convert columns to numeric\n",
    "    pivoted_df['confidence_1'] = pd.to_numeric(pivoted_df['confidence_1'])\n",
    "    pivoted_df['confidence_2'] = pd.to_numeric(pivoted_df['confidence_2'])\n",
    "\n",
    "    # Set 'unit_id' as the index\n",
    "    pivoted_df.set_index('unit_id', inplace=True)\n",
    "\n",
    "    # Calculate the mean of 'confidence_1' and 'confidence_2'\n",
    "    mean_confidence_1 = pivoted_df['confidence_1'].mean()\n",
    "    mean_confidence_2 = pivoted_df['confidence_2'].mean()\n",
    "\n",
    "    # Calculate the overall mean\n",
    "    overall_mean = pivoted_df[['confidence_1', 'confidence_2']].values.flatten().mean()\n",
    "\n",
    "    return pivoted_df, mean_confidence_1, mean_confidence_2, overall_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfcef95-6a64-4707-86ea-7cdea7862a50",
   "metadata": {},
   "source": [
    "#### Annotator A - assisted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "ce5cadba-5a1c-4eb3-8046-b1d1e770bd13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean Confidence_1: 4.0\n",
      "Mean Confidence_2: 4.0\n",
      "Overall Mean Confidence: 4.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2290/2235581490.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['value'] = filtered_df['value'].replace(recode_map)\n"
     ]
    }
   ],
   "source": [
    "processed_df, mean_confidence_1, mean_confidence_2, overall_mean = preprocess_and_calculate_mean(df1)\n",
    "\n",
    "print(f\"\\nMean Confidence_1: {mean_confidence_1}\")\n",
    "print(f\"Mean Confidence_2: {mean_confidence_2}\")\n",
    "print(f\"Overall Mean Confidence: {overall_mean}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd391b5-890b-4be9-b609-b9ec3f895f39",
   "metadata": {},
   "source": [
    "#### Annotator A - not assisted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "43b79ce6-8353-402f-b3d2-e4abe0a08f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean Confidence_topic: 3.95959595959596\n",
      "Mean Confidence_event: 4.0\n",
      "Overall Mean Confidence: 3.9797979797979797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2290/4090869044.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['value'] = filtered_df['value'].replace(recode_map)\n"
     ]
    }
   ],
   "source": [
    "# df1 = ...  # your original DataFrame\n",
    "processed_df, mean_confidence_1, mean_confidence_2, overall_mean = preprocess_and_calculate_mean(df1_1)\n",
    "\n",
    "print(f\"\\nMean Confidence_topic: {mean_confidence_1}\")\n",
    "print(f\"Mean Confidence_event: {mean_confidence_2}\")\n",
    "print(f\"Overall Mean Confidence: {overall_mean}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2af51c-7779-4141-8e3f-9aa9d6255d59",
   "metadata": {},
   "source": [
    "#### Annotator B - assisted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "17434f19-5c0e-45ba-bf51-7099fcb74b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean Confidence_topic: 3.9515151515151516\n",
      "Mean Confidence_event: 3.9353535353535354\n",
      "Overall Mean Confidence: 3.9434343434343435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2290/4090869044.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['value'] = filtered_df['value'].replace(recode_map)\n"
     ]
    }
   ],
   "source": [
    "processed_df, mean_confidence_1, mean_confidence_2, overall_mean = preprocess_and_calculate_mean(df2)\n",
    "print(f\"\\nMean Confidence_topic: {mean_confidence_1}\")\n",
    "print(f\"Mean Confidence_event: {mean_confidence_2}\")\n",
    "print(f\"Overall Mean Confidence: {overall_mean}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9661fb-d3d9-4936-aedc-4dd4c9fd9a67",
   "metadata": {},
   "source": [
    "#### Annotator B - unassisted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "3fc389f9-70f0-4a2e-bf69-e2a0daee7720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean Confidence_topic: 3.95959595959596\n",
      "Mean Confidence_event: 3.9575757575757575\n",
      "Overall Mean Confidence: 3.9585858585858587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2290/4090869044.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['value'] = filtered_df['value'].replace(recode_map)\n"
     ]
    }
   ],
   "source": [
    "processed_df, mean_confidence_1, mean_confidence_2, overall_mean = preprocess_and_calculate_mean(df2_1)\n",
    "\n",
    "print(f\"\\nMean Confidence_topic: {mean_confidence_1}\")\n",
    "print(f\"Mean Confidence_event: {mean_confidence_2}\")\n",
    "print(f\"Overall Mean Confidence: {overall_mean}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73287b2a-5e9d-465f-a334-e142814afa6a",
   "metadata": {},
   "source": [
    "#### Annotator C - assisted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "159e6458-4aef-415c-9a9b-95bb93479ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean Confidence_topic: 3.9575757575757575\n",
      "Mean Confidence_event: 3.98989898989899\n",
      "Overall Mean Confidence: 3.973737373737374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2290/4090869044.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['value'] = filtered_df['value'].replace(recode_map)\n"
     ]
    }
   ],
   "source": [
    "processed_df, mean_confidence_1, mean_confidence_2, overall_mean = preprocess_and_calculate_mean(df3)\n",
    "print(f\"\\nMean Confidence_topic: {mean_confidence_1}\")\n",
    "print(f\"Mean Confidence_event: {mean_confidence_2}\")\n",
    "print(f\"Overall Mean Confidence: {overall_mean}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2dad802-8ff1-4431-bb20-8eb60c33158f",
   "metadata": {},
   "source": [
    "#### Annotator C - unassisted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "6d916167-1277-4228-b314-2869b432dfca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean Confidence_topic: 3.9515151515151516\n",
      "Mean Confidence_event: 3.9474747474747476\n",
      "Overall Mean Confidence: 3.9494949494949494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2290/4090869044.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['value'] = filtered_df['value'].replace(recode_map)\n"
     ]
    }
   ],
   "source": [
    "processed_df, mean_confidence_1, mean_confidence_2, overall_mean = preprocess_and_calculate_mean(df3_1)\n",
    "\n",
    "print(f\"\\nMean Confidence_topic: {mean_confidence_1}\")\n",
    "print(f\"Mean Confidence_event: {mean_confidence_2}\")\n",
    "print(f\"Overall Mean Confidence: {overall_mean}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40124048-4d6a-43c7-990c-519da0f6153c",
   "metadata": {},
   "source": [
    "### 3. Annotation quality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29243109-4c57-445e-8393-6f09f633d627",
   "metadata": {},
   "source": [
    "#### ICR for unassisted (Krippendorff's alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "f72e6559-8630-4bb3-86c3-857845c9ccd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot the DataFrame to calculate Krippendorff's alpha\n",
    "unassisted_df = df4.pivot(index=['coder_id', 'coder', 'jobset', 'unit_id', 'unit_status'],\n",
    "                     columns='variable', values='value').reset_index()\n",
    "\n",
    "unassisted_df = unassisted_df.rename_axis(None, axis=1)\n",
    "\n",
    "# If there are NaN values in the pivoted DataFrame, you can replace them with a default value like this\n",
    "unassisted_df = unassisted_df.fillna('N/A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "id": "ab47157f-bcb3-499a-95d5-9cc1b0a27996",
   "metadata": {},
   "outputs": [],
   "source": [
    "unassisted_df.to_csv('../unassisted_pivoted.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "67365495-2940-4330-a7de-9afa3e4246cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8327855329679441"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate alpha before any removal of flagged cases\n",
    "alpha_topic = simpledorff.calculate_krippendorffs_alpha_for_df(unassisted_df,\n",
    "                                                        experiment_col='unit_id',\n",
    "                                                        annotator_col='coder_id',\n",
    "                                                        class_col='topic_match')\n",
    "alpha_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "37b561ff-28c0-4f4b-a329-fc03ceadc9f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5984078839063223"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate alpha before any removal of flagged cases\n",
    "alpha_event = simpledorff.calculate_krippendorffs_alpha_for_df(unassisted_df,\n",
    "                                                        experiment_col='unit_id',\n",
    "                                                        annotator_col='coder_id',\n",
    "                                                        class_col='event_match')\n",
    "alpha_event"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6bb6ebf-c7e9-4eed-bf72-16e0eec7c9eb",
   "metadata": {},
   "source": [
    "#### ICR for assisted (Krippendorff's alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "id": "d1ba957e-9d35-4f76-8750-1966df2effe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df1, df2, and df3 are your DataFrames\n",
    "df5 = pd.concat([df1, df2, df3])\n",
    "df5.to_csv('../assisted.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "68f77926-c9bc-4fef-b606-a416b3d1bbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot the DataFrame to calculate Krippendorff's alpha\n",
    "assisted_df = df5.pivot(index=['coder_id', 'coder', 'jobset', 'unit_id', 'unit_status'],\n",
    "                     columns='variable', values='value').reset_index()\n",
    "\n",
    "assisted_df = assisted_df.rename_axis(None, axis=1)\n",
    "\n",
    "# If there are NaN values in the pivoted DataFrame, you can replace them with a default value like this\n",
    "assisted_df = assisted_df.fillna('N/A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "id": "5971b66a-e6f4-4b50-925a-fdb7dd6235a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "assisted_df.to_csv('../assisted_pivoted.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "d638122e-4298-42c8-9efc-fa8ef8a394cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7991604967061156"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate alpha before any removal of flagged cases\n",
    "alpha_topic = simpledorff.calculate_krippendorffs_alpha_for_df(assisted_df,\n",
    "                                                        experiment_col='unit_id',\n",
    "                                                        annotator_col='coder_id',\n",
    "                                                        class_col='topic_match')\n",
    "alpha_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "9e20b280-69d3-4918-9ebe-9a11445ca9df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6374721189591078"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate alpha before any removal of flagged cases\n",
    "alpha_event = simpledorff.calculate_krippendorffs_alpha_for_df(assisted_df,\n",
    "                                                        experiment_col='unit_id',\n",
    "                                                        annotator_col='coder_id',\n",
    "                                                        class_col='event_match')\n",
    "alpha_event"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bdb35f-3741-4b2a-b383-0a12ae15f13e",
   "metadata": {},
   "source": [
    "It seems that ICR is better for topic match when unassisted, but worse for event match when unassisted compared to the assisted version which scores  sligthly below the ICR of topic match and slightly above event match.\n",
    "\n",
    "What can we tell based on this? coders seem to perform similarly regardless of assistance it appears that the difference is more pronounced for the event-match level where assistance seems to help annotators. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c899b75-60be-42d3-ba16-acded218e55b",
   "metadata": {},
   "source": [
    "shall I do some kind of regression to see the type of model's influence on the results?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072c43ec-16b4-4604-85a4-ce9f6fbef461",
   "metadata": {},
   "source": [
    "### 4. Alignment between human annotation and LLM decision making"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "05903b0e-4804-4b5f-ab9a-b83b27057aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in LLM-annotated files\n",
    "\n",
    "d1 = pd.read_csv('../7b_assisted.csv')\n",
    "d2 = pd.read_csv('../13b_assisted.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "aeee1054-9f8d-47d5-b704-f4457f7e7c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1['unit_id'] = d1['ID1'].astype(str) + '_' + d1['ID2'].astype(str)\n",
    "# Rename the 'ID1' column to 'new_column_name'\n",
    "d1.rename(columns={'Topic_match': 'topic_match', 'Event_match' : 'event_match'}, inplace=True)\n",
    "d1['coder_id'] = '7B-chat'\n",
    "d1['coder_id'] = d1['coder_id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "23cac904-3db7-416a-b2cd-04723cbb8420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge ID1 and ID2 into a new column unit_id\n",
    "d2['unit_id'] = d2['ID1'].astype(str) + '_' + d2['ID2'].astype(str)\n",
    "# Rename the 'ID1' column to 'new_column_name'\n",
    "d2.rename(columns={'Topic_match': 'topic_match', 'Event_match' : 'event_match'}, inplace=True)\n",
    "\n",
    "d2['coder_id'] = '13B-chat'\n",
    "d2['coder_id'] = d2['coder_id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "4c0eae84-a1a7-466e-a5af-579584e26fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your data is stored in a DataFrame called 'df'\n",
    "assisted_df['event_match'] = assisted_df['event_match'].map({'Yes': 1, 'No': 0})\n",
    "assisted_df['topic_match'] = assisted_df['topic_match'].map({'Yes': 1, 'No': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "b3a60556-8e05-4990-948f-2cd51af81427",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coder_id</th>\n",
       "      <th>coder</th>\n",
       "      <th>jobset</th>\n",
       "      <th>unit_id</th>\n",
       "      <th>unit_status</th>\n",
       "      <th>confidence_1</th>\n",
       "      <th>confidence_2</th>\n",
       "      <th>event_match</th>\n",
       "      <th>topic_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2606</td>\n",
       "      <td>s_ching@annotator.com</td>\n",
       "      <td>All</td>\n",
       "      <td>3285217_3285337</td>\n",
       "      <td>DONE</td>\n",
       "      <td>++</td>\n",
       "      <td>++</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2606</td>\n",
       "      <td>s_ching@annotator.com</td>\n",
       "      <td>All</td>\n",
       "      <td>3285217_3286175</td>\n",
       "      <td>DONE</td>\n",
       "      <td>++</td>\n",
       "      <td>++</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2606</td>\n",
       "      <td>s_ching@annotator.com</td>\n",
       "      <td>All</td>\n",
       "      <td>3285217_3287465</td>\n",
       "      <td>DONE</td>\n",
       "      <td>++</td>\n",
       "      <td>++</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2606</td>\n",
       "      <td>s_ching@annotator.com</td>\n",
       "      <td>All</td>\n",
       "      <td>3285217_6290567</td>\n",
       "      <td>DONE</td>\n",
       "      <td>++</td>\n",
       "      <td>++</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2606</td>\n",
       "      <td>s_ching@annotator.com</td>\n",
       "      <td>All</td>\n",
       "      <td>3285217_6290581</td>\n",
       "      <td>DONE</td>\n",
       "      <td>++</td>\n",
       "      <td>++</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1480</th>\n",
       "      <td>2608</td>\n",
       "      <td>floris_v@annotator.com</td>\n",
       "      <td>All</td>\n",
       "      <td>6290557_6290579</td>\n",
       "      <td>DONE</td>\n",
       "      <td>++</td>\n",
       "      <td>++</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1481</th>\n",
       "      <td>2608</td>\n",
       "      <td>floris_v@annotator.com</td>\n",
       "      <td>All</td>\n",
       "      <td>6290567_6290556</td>\n",
       "      <td>DONE</td>\n",
       "      <td>++</td>\n",
       "      <td>++</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1482</th>\n",
       "      <td>2608</td>\n",
       "      <td>floris_v@annotator.com</td>\n",
       "      <td>All</td>\n",
       "      <td>6290568_3287414</td>\n",
       "      <td>DONE</td>\n",
       "      <td>++</td>\n",
       "      <td>++</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1483</th>\n",
       "      <td>2608</td>\n",
       "      <td>floris_v@annotator.com</td>\n",
       "      <td>All</td>\n",
       "      <td>6290568_3287485</td>\n",
       "      <td>DONE</td>\n",
       "      <td>++</td>\n",
       "      <td>++</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1484</th>\n",
       "      <td>2608</td>\n",
       "      <td>floris_v@annotator.com</td>\n",
       "      <td>All</td>\n",
       "      <td>6290579_6290505</td>\n",
       "      <td>DONE</td>\n",
       "      <td>++</td>\n",
       "      <td>++</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1485 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      coder_id                   coder jobset          unit_id unit_status  \\\n",
       "0         2606   s_ching@annotator.com    All  3285217_3285337        DONE   \n",
       "1         2606   s_ching@annotator.com    All  3285217_3286175        DONE   \n",
       "2         2606   s_ching@annotator.com    All  3285217_3287465        DONE   \n",
       "3         2606   s_ching@annotator.com    All  3285217_6290567        DONE   \n",
       "4         2606   s_ching@annotator.com    All  3285217_6290581        DONE   \n",
       "...        ...                     ...    ...              ...         ...   \n",
       "1480      2608  floris_v@annotator.com    All  6290557_6290579        DONE   \n",
       "1481      2608  floris_v@annotator.com    All  6290567_6290556        DONE   \n",
       "1482      2608  floris_v@annotator.com    All  6290568_3287414        DONE   \n",
       "1483      2608  floris_v@annotator.com    All  6290568_3287485        DONE   \n",
       "1484      2608  floris_v@annotator.com    All  6290579_6290505        DONE   \n",
       "\n",
       "     confidence_1 confidence_2  event_match  topic_match  \n",
       "0              ++           ++          NaN          NaN  \n",
       "1              ++           ++          NaN          NaN  \n",
       "2              ++           ++          NaN          NaN  \n",
       "3              ++           ++          NaN          NaN  \n",
       "4              ++           ++          NaN          NaN  \n",
       "...           ...          ...          ...          ...  \n",
       "1480           ++           ++          NaN          NaN  \n",
       "1481           ++           ++          NaN          NaN  \n",
       "1482           ++           ++          NaN          NaN  \n",
       "1483           ++           ++          NaN          NaN  \n",
       "1484           ++           ++          NaN          NaN  \n",
       "\n",
       "[1485 rows x 9 columns]"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assisted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "dbed83d3-87c4-48e3-a999-eaab12fb6941",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_dfs = dict(tuple(assisted_df.groupby('coder_id')))\n",
    "\n",
    "# Accessing individual DataFrames based on coder_id\n",
    "coder_id_2606 = grouped_dfs[2606]\n",
    "coder_id_2607 = grouped_dfs[2607]\n",
    "coder_id_2608 = grouped_dfs[2608]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328a1739-98e3-4565-8de7-e19d7f26460e",
   "metadata": {},
   "source": [
    "#### For annotator A and LlaMA 7B-chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "256a230c-025c-48ac-a0e7-6ae750955274",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check agreement between coder_id_2608 and Llama 7B\n",
    "coder_id_2608['coder_id'] = coder_id_2608['coder_id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "e6a4438e-cbe8-4ac8-8b65-93e8776b2bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge ID1 and ID2 into a new column unit_id\n",
    "d1['unit_id'] = d1['ID1'].astype(str) + '_' + d1['ID2'].astype(str)\n",
    "# Rename the 'ID1' column to 'new_column_name'\n",
    "d1.rename(columns={'Topic_match': 'topic_match', 'Event_match' : 'event_match'}, inplace=True)\n",
    "d1\n",
    "d1['coder_id'] = '7B-chat'\n",
    "d1['coder_id'] = d1['coder_id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "ac04eace-28f1-4362-a03e-714e888924f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the two dataframes vertically\n",
    "combined_df = pd.concat([d1, coder_id_2608], ignore_index=True)\n",
    "\n",
    "# Calculate Krippendorff's alpha for the combined dataframe\n",
    "alpha_topic = simpledorff.calculate_krippendorffs_alpha_for_df(combined_df,\n",
    "                                                               experiment_col='unit_id',\n",
    "                                                               annotator_col='coder_id',\n",
    "                                                               class_col='topic_match')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "3922478f-48a5-4422-b14b-73fa4e037e84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.290184906177236"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aae3292-afc1-4557-acbc-e6db33e4df3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the two dataframes vertically\n",
    "combined_df = pd.concat([d1, coder_id_2608], ignore_index=True)\n",
    "\n",
    "# Calculate Krippendorff's alpha for the combined dataframe\n",
    "alpha_event = simpledorff.calculate_krippendorffs_alpha_for_df(combined_df,\n",
    "                                                               experiment_col='unit_id',\n",
    "                                                               annotator_col='coder_id',\n",
    "                                                               class_col='event_match')\n",
    "alpha_event"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04044676-3edb-4aa2-af1c-9daffcb35d97",
   "metadata": {},
   "source": [
    "#### For annotator B and LlaMA 13B-chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "3d01f0bf-3bd5-46eb-98aa-85a160089af5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coder_id</th>\n",
       "      <th>coder</th>\n",
       "      <th>jobset</th>\n",
       "      <th>unit_id</th>\n",
       "      <th>unit_status</th>\n",
       "      <th>confidence_1</th>\n",
       "      <th>confidence_2</th>\n",
       "      <th>event_match</th>\n",
       "      <th>topic_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2606</td>\n",
       "      <td>s_ching@annotator.com</td>\n",
       "      <td>All</td>\n",
       "      <td>3285217_3285337</td>\n",
       "      <td>DONE</td>\n",
       "      <td>++</td>\n",
       "      <td>++</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2606</td>\n",
       "      <td>s_ching@annotator.com</td>\n",
       "      <td>All</td>\n",
       "      <td>3285217_3286175</td>\n",
       "      <td>DONE</td>\n",
       "      <td>++</td>\n",
       "      <td>++</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2606</td>\n",
       "      <td>s_ching@annotator.com</td>\n",
       "      <td>All</td>\n",
       "      <td>3285217_3287465</td>\n",
       "      <td>DONE</td>\n",
       "      <td>++</td>\n",
       "      <td>++</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2606</td>\n",
       "      <td>s_ching@annotator.com</td>\n",
       "      <td>All</td>\n",
       "      <td>3285217_6290567</td>\n",
       "      <td>DONE</td>\n",
       "      <td>++</td>\n",
       "      <td>++</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2606</td>\n",
       "      <td>s_ching@annotator.com</td>\n",
       "      <td>All</td>\n",
       "      <td>3285217_6290581</td>\n",
       "      <td>DONE</td>\n",
       "      <td>++</td>\n",
       "      <td>++</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>2606</td>\n",
       "      <td>s_ching@annotator.com</td>\n",
       "      <td>All</td>\n",
       "      <td>6290557_6290579</td>\n",
       "      <td>DONE</td>\n",
       "      <td>++</td>\n",
       "      <td>++</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>2606</td>\n",
       "      <td>s_ching@annotator.com</td>\n",
       "      <td>All</td>\n",
       "      <td>6290567_6290556</td>\n",
       "      <td>DONE</td>\n",
       "      <td>++</td>\n",
       "      <td>++</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>2606</td>\n",
       "      <td>s_ching@annotator.com</td>\n",
       "      <td>All</td>\n",
       "      <td>6290568_3287414</td>\n",
       "      <td>DONE</td>\n",
       "      <td>++</td>\n",
       "      <td>++</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>2606</td>\n",
       "      <td>s_ching@annotator.com</td>\n",
       "      <td>All</td>\n",
       "      <td>6290568_3287485</td>\n",
       "      <td>DONE</td>\n",
       "      <td>++</td>\n",
       "      <td>++</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>2606</td>\n",
       "      <td>s_ching@annotator.com</td>\n",
       "      <td>All</td>\n",
       "      <td>6290579_6290505</td>\n",
       "      <td>DONE</td>\n",
       "      <td>++</td>\n",
       "      <td>++</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>495 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     coder_id                  coder jobset          unit_id unit_status  \\\n",
       "0        2606  s_ching@annotator.com    All  3285217_3285337        DONE   \n",
       "1        2606  s_ching@annotator.com    All  3285217_3286175        DONE   \n",
       "2        2606  s_ching@annotator.com    All  3285217_3287465        DONE   \n",
       "3        2606  s_ching@annotator.com    All  3285217_6290567        DONE   \n",
       "4        2606  s_ching@annotator.com    All  3285217_6290581        DONE   \n",
       "..        ...                    ...    ...              ...         ...   \n",
       "490      2606  s_ching@annotator.com    All  6290557_6290579        DONE   \n",
       "491      2606  s_ching@annotator.com    All  6290567_6290556        DONE   \n",
       "492      2606  s_ching@annotator.com    All  6290568_3287414        DONE   \n",
       "493      2606  s_ching@annotator.com    All  6290568_3287485        DONE   \n",
       "494      2606  s_ching@annotator.com    All  6290579_6290505        DONE   \n",
       "\n",
       "    confidence_1 confidence_2  event_match  topic_match  \n",
       "0             ++           ++            0            1  \n",
       "1             ++           ++            1            1  \n",
       "2             ++           ++            1            1  \n",
       "3             ++           ++            0            1  \n",
       "4             ++           ++            1            1  \n",
       "..           ...          ...          ...          ...  \n",
       "490           ++           ++            0            1  \n",
       "491           ++           ++            0            1  \n",
       "492           ++           ++            0            1  \n",
       "493           ++           ++            1            1  \n",
       "494           ++           ++            1            1  \n",
       "\n",
       "[495 rows x 9 columns]"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coder_id_2606 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "83d523e3-4575-46cd-b9a4-9f92ced1e162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge ID1 and ID2 into a new column unit_id\n",
    "d2['unit_id'] = d2['ID1'].astype(str) + '_' + d2['ID2'].astype(str)\n",
    "# Rename the 'ID1' column to 'new_column_name'\n",
    "d2.rename(columns={'Topic_match': 'topic_match', 'Event_match' : 'event_match'}, inplace=True)\n",
    "\n",
    "d2['coder_id'] = '13B-chat'\n",
    "d2['coder_id'] = d2['coder_id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "6bcdcfb5-0d62-47e5-8133-b121239095d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check agreement between coder_id_2608 and Llama 7B\n",
    "coder_id_2606['coder_id'] = coder_id_2606['coder_id'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "1353e4a2-5c4a-40d9-9f20-87c1ed671d10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2160486616380749"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate the two dataframes vertically\n",
    "combined_df = pd.concat([d2, coder_id_2606], ignore_index=True)\n",
    "\n",
    "# Calculate Krippendorff's alpha for the combined dataframe\n",
    "alpha_topic = simpledorff.calculate_krippendorffs_alpha_for_df(combined_df,\n",
    "                                                               experiment_col='unit_id',\n",
    "                                                               annotator_col='coder_id',\n",
    "                                                               class_col='topic_match')\n",
    "alpha_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "74b49278-cae9-41fe-824e-76305389e937",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09721311776706343"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate the two dataframes vertically\n",
    "combined_df = pd.concat([d2, coder_id_2606], ignore_index=True)\n",
    "\n",
    "# Calculate Krippendorff's alpha for the combined dataframe\n",
    "alpha_event = simpledorff.calculate_krippendorffs_alpha_for_df(combined_df,\n",
    "                                                               experiment_col='unit_id',\n",
    "                                                               annotator_col='coder_id',\n",
    "                                                               class_col='event_match')\n",
    "alpha_event"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb80b4c-49ec-4d1a-a04e-fdf0d06cb000",
   "metadata": {},
   "source": [
    "#### For LlaMA 7B-chat and LlaMA 13B-chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "d808e96e-8dc3-46b4-8d56-162a392d54d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09455450983264357"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate the two dataframes vertically\n",
    "combined_df = pd.concat([d1, d2], ignore_index=True)\n",
    "\n",
    "# Calculate Krippendorff's alpha for the combined dataframe\n",
    "alpha_topic = simpledorff.calculate_krippendorffs_alpha_for_df(combined_df,\n",
    "                                                               experiment_col='unit_id',\n",
    "                                                               annotator_col='coder_id',\n",
    "                                                               class_col='topic_match')\n",
    "alpha_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "3a14c89c-f4b6-4c32-90ee-aa9f862089a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3453632876712329"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate the two dataframes vertically\n",
    "combined_df = pd.concat([d1, d2], ignore_index=True)\n",
    "\n",
    "# Calculate Krippendorff's alpha for the combined dataframe\n",
    "alpha_event = simpledorff.calculate_krippendorffs_alpha_for_df(combined_df,\n",
    "                                                               experiment_col='unit_id',\n",
    "                                                               annotator_col='coder_id',\n",
    "                                                               class_col='event_match')\n",
    "alpha_event"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758b1fdd-0fda-478d-8dc9-691b2017dc4f",
   "metadata": {},
   "source": [
    "### 5. Expert annotator makes final decision on mismatched cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "d137cc1d-73ac-466a-886f-8a52e69e36d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#take dataset with assisted and unassisted tasks \n",
    "#find all mismatched cases for both sets and make final decision on them - note down final code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "4a5094ea-631b-4605-872b-04af18116321",
   "metadata": {},
   "outputs": [],
   "source": [
    "disagreements_assisted = pd.crosstab(index=[assisted_df['unit_id'], assisted_df['coder_id']], columns=assisted_df['topic_match'], margins=True)\n",
    "disagreements_assisted.to_excel('../dis_assisted.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "dba5afd4-19e9-47a8-80f0-c6cda7b1d7ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_match</th>\n",
       "      <th>No</th>\n",
       "      <th>Yes</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unit_id</th>\n",
       "      <th>coder_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">3285217_3285337</th>\n",
       "      <th>2606</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2607</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2608</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">3285217_3286175</th>\n",
       "      <th>2606</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2607</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6290568_3287485</th>\n",
       "      <th>2608</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">6290579_6290505</th>\n",
       "      <th>2606</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2607</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2608</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <th></th>\n",
       "      <td>476</td>\n",
       "      <td>1009</td>\n",
       "      <td>1485</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1486 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "topic_match                No   Yes   All\n",
       "unit_id         coder_id                 \n",
       "3285217_3285337 2606        0     1     1\n",
       "                2607        0     1     1\n",
       "                2608        0     1     1\n",
       "3285217_3286175 2606        0     1     1\n",
       "                2607        0     1     1\n",
       "...                       ...   ...   ...\n",
       "6290568_3287485 2608        0     1     1\n",
       "6290579_6290505 2606        0     1     1\n",
       "                2607        0     1     1\n",
       "                2608        0     1     1\n",
       "All                       476  1009  1485\n",
       "\n",
       "[1486 rows x 3 columns]"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disagreements_assisted "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "12c50920-0b45-439b-b26e-cfd5be1a5252",
   "metadata": {},
   "outputs": [],
   "source": [
    "disagreements_unassisted = pd.crosstab(index=[unassisted_df['unit_id'], unassisted_df['coder_id']], columns=unassisted_df['topic_match'], margins=True)\n",
    "disagreements_unassisted.to_excel('../dis_unassisted.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "1f71ec84-e059-4a80-b750-16471c411c6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_match</th>\n",
       "      <th>No</th>\n",
       "      <th>Yes</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unit_id</th>\n",
       "      <th>coder_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">3285217_3285335</th>\n",
       "      <th>2606</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2607</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2608</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">3285217_3287448</th>\n",
       "      <th>2606</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2607</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6290574_6290556</th>\n",
       "      <th>2608</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">6290579_3287398</th>\n",
       "      <th>2606</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2607</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2608</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <th></th>\n",
       "      <td>458</td>\n",
       "      <td>1027</td>\n",
       "      <td>1485</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1486 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "topic_match                No   Yes   All\n",
       "unit_id         coder_id                 \n",
       "3285217_3285335 2606        1     0     1\n",
       "                2607        1     0     1\n",
       "                2608        1     0     1\n",
       "3285217_3287448 2606        0     1     1\n",
       "                2607        0     1     1\n",
       "...                       ...   ...   ...\n",
       "6290574_6290556 2608        0     1     1\n",
       "6290579_3287398 2606        0     1     1\n",
       "                2607        0     1     1\n",
       "                2608        0     1     1\n",
       "All                       458  1027  1485\n",
       "\n",
       "[1486 rows x 3 columns]"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disagreements_unassisted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "55d5761d-800e-4b70-9d52-5abd7b8ca5c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unit IDs where annotators disagreed on event_match: ['3285322_3287397', '3285325_3287414', '3285326_3285227', '3285625_3287399', '3285634_3285375', '3286377_3287414', '3287459_3287398', '3287459_6290507', '3287467_3285217', '3287468_3285227', '3287471_3285217', '3287471_3285627', '3287471_3285661', '3287472_3286375', '3287472_3287471', '3287472_3290571', '3287472_3290653', '3287473_3290604', '3287474_3285226', '3287475_3287471', '3287477_3287397', '3287477_3287414', '3287477_6290581', '3287479_3287467', '3287479_3287470', '3287480_3287470', '3287500_3285635', '3287516_3287477', '3287521_3287479', '3287521_3290622', '3287527_3287472', '3287536_3287500', '3287536_3288493', '3287578_3285375', '3287578_3286171', '3290580_3287448', '3290593_3290566', '3290593_3290653', '3290593_6290574', '3290596_3285325', '3290606_3290566', '3290621_6290555', '3290622_3285325', '3290622_6290568', '3290653_6290507', '3290705_3286175', '3290705_3290593', '6290579_3287398']\n",
      "Number of unit IDs where annotators disagreed on event_match: 48\n",
      "Unit IDs where annotators disagreed on topic_match: ['3285240_6290505', '3285370_3287485', '3285386_3290566', '3285615_6290555', '3285636_6290555', '3285637_3287414', '3285637_3290566', '3286174_3285386', '3286188_3285316', '3286195_3285230', '3286364_3290618', '3286377_3285230', '3286378_6290556', '3287472_3285637', '3287474_3285226', '3287475_3285386', '3287475_3286194', '3287516_3285647', '3287521_3287479', '3287522_3286377', '3287522_3286378', '3287529_3285335', '3287530_3285647', '3287531_3285325', '3287531_3287476', '3287531_3290620', '3287532_3286178', '3287533_3286178', '3287536_3288528', '3287538_3285332', '3287580_3285386', '3288419_3290621', '3288497_3286364', '3288497_3286377', '3288518_3285627', '3288518_3287527', '3288518_6290523', '3288528_3285240', '3288528_3285327', '3288528_3287447', '3288528_3290705', '3290570_3290566', '3290586_3285233', '3290586_6290506', '3290596_3286171', '3290606_3285386', '3290608_3286174', '3290618_3285634', '3290632_3285316', '3290668_3285370', '3290688_3285316', '3290695_3285633', '3290697_3290679']\n",
      "Number of unit IDs where annotators disagreed on topic_match: 53\n"
     ]
    }
   ],
   "source": [
    "def find_disagreements(unassisted_df):\n",
    "    # Group by unit_id and count unique values for event_match and topic_match\n",
    "    counts = unassisted_df.groupby('unit_id').agg({'event_match': 'nunique', 'topic_match': 'nunique'})\n",
    "\n",
    "    # Filter disagreements based on event_match and topic_match\n",
    "    disagreements_ua_event = list(counts[counts['event_match'] > 1].index)\n",
    "    disagreements_ua_topic = list(counts[counts['topic_match'] > 1].index)\n",
    "\n",
    "    # Return the results\n",
    "    return disagreements_ua_event, disagreements_ua_topic\n",
    "\n",
    "\n",
    "event_disagreements_ua, topic_disagreements_ua = find_disagreements(unassisted_df)\n",
    "\n",
    "print(\"Unit IDs where annotators disagreed on event_match:\", event_disagreements_ua)\n",
    "print(\"Number of unit IDs where annotators disagreed on event_match:\", len(event_disagreements_ua))\n",
    "print(\"Unit IDs where annotators disagreed on topic_match:\", topic_disagreements_ua)\n",
    "print(\"Number of unit IDs where annotators disagreed on topic_match:\", len(topic_disagreements_ua))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "3f1ea55e-e850-45c7-a6ac-868c8f891cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unit IDs where annotators disagreed on event_match: ['3285217_6290581', '3285322_3286175', '3285323_6290568', '3285323_6290579', '3285326_3285375', '3285326_3285636', '3285634_6290523', '3286373_6290505', '3287470_3286188', '3287471_3290656', '3287471_6290505', '3287472_3286174', '3287473_3287446', '3287473_6290574', '3287474_3287399', '3287474_3287459', '3287474_3290571', '3287475_3287470', '3287476_3287471', '3287477_3286373', '3287479_3287477', '3287516_3285226', '3287516_3287397', '3287516_3290656', '3287521_3287465', '3287527_3286375', '3287527_3287475', '3287527_3290593', '3287532_3285335', '3287577_3290580', '3287578_3287397', '3287580_3286171', '3288493_3287500', '3290580_3290622', '3290596_3286174', '3290596_3290621', '3290606_3287398', '3290606_3290653', '3290621_3290566', '3290621_3290622', '3290621_6290579', '3290622_3287446', '3290622_3287458', '3290697_3287522', '3290705_6290581', '6290568_3287485']\n",
      "Number of unit IDs where annotators disagreed on event_match: 46\n",
      "Unit IDs where annotators disagreed on topic_match: ['3285243_3285647', '3285316_3285240', '3285316_3287448', '3285316_3287485', '3285316_6290507', '3285323_6290579', '3285386_3287398', '3285386_6290556', '3285386_6290557', '3285615_3285370', '3285647_3286186', '3286194_6290579', '3286195_3285625', '3286195_6290568', '3286378_3285327', '3286379_3285657', '3287468_3287485', '3287471_3285386', '3287472_3285386', '3287472_3286377', '3287500_3286195', '3287512_3290570', '3287521_6290579', '3287529_3288493', '3287530_3287500', '3287531_3286171', '3287531_3286186', '3287531_3287397', '3287531_3287467', '3287531_3290570', '3287531_3290586', '3287531_3290622', '3287531_3290643', '3287531_6290506', '3287531_6290579', '3287532_3285335', '3287532_3286194', '3287532_3287414', '3287532_3287447', '3287535_3285386', '3287535_3288419', '3287536_3290606', '3288419_3285615', '3288419_3287448', '3288493_3285647', '3288497_3285386', '3288497_3285647', '3288518_3287529', '3288518_3290679', '3288528_3285316', '3288528_3285322', '3288528_3285375', '3288528_3286174', '3288528_3287446', '3288528_3287448', '3288528_3287531', '3288528_3290593', '3290567_3290596', '3290604_6290523', '3290679_3286178', '3290679_3288497', '3290688_3285386', '3290697_3285370', '3290697_6290506', '6290557_6290579']\n",
      "Number of unit IDs where annotators disagreed on topic_match: 65\n"
     ]
    }
   ],
   "source": [
    "event_disagreements_a, topic_disagreements_a = find_disagreements(assisted_df)\n",
    "print(\"Unit IDs where annotators disagreed on event_match:\", event_disagreements_a)\n",
    "print(\"Number of unit IDs where annotators disagreed on event_match:\", len(event_disagreements_a))\n",
    "print(\"Unit IDs where annotators disagreed on topic_match:\", topic_disagreements_a)\n",
    "print(\"Number of unit IDs where annotators disagreed on topic_match:\", len(topic_disagreements_a))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3720962e-0c25-43c5-9450-58f283d3a2a6",
   "metadata": {},
   "source": [
    "### Merge unassisted set with original data and then ammend disagreements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "c43c19a9-216b-4dd9-97a6-5c9ff6e3aba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in dataframe \n",
    "import os\n",
    "# Function to navigate up 'n' levels\n",
    "def navigate_up(current_directory, levels):\n",
    "    for _ in range(levels):\n",
    "        current_directory = os.path.dirname(current_directory)\n",
    "    return current_directory\n",
    "\n",
    "# Get the current working directory\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# Specify the number of levels to navigate up (4 levels in this case)\n",
    "levels_to_navigate = 4\n",
    "\n",
    "# Navigate up 'levels_to_navigate' folders\n",
    "parent_directory = navigate_up(current_directory, levels_to_navigate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "f4f8f38d-3268-4652-ae13-7efa2b85cd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the data file\n",
    "file_path = os.path.join(parent_directory, 'newspaper_data', 'final_1.csv')\n",
    "du=pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "372ff535-88a6-43e6-94bf-199abcb42642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge ID1 and ID2 into a new column unit_id\n",
    "du['unit_id'] = du['ID1'].astype(str) + '_' + du['ID2'].astype(str)\n",
    "# Rename the 'ID1' column to 'new_column_name'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "fe7ae5af-0394-4ef2-9ec2-7be7f3be5cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using the mismatched unit_ids filter the dataset \n",
    "topic_du_mis = du[du['unit_id'].isin(topic_disagreements_ua)]\n",
    "event_du_mis = du[du['unit_id'].isin(event_disagreements_ua)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "6a0726ab-f5f5-418f-9563-fe9524341706",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_du_mis.to_csv('../topic_ua_mis.csv')\n",
    "event_du_mis.to_csv('../event_ua_mis.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "be176faa-5daa-4a3e-ace2-2382c27f9dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge unasisted with unassited coded\n",
    "\n",
    "# Merge df1 with df2 on 'unit_id'\n",
    "#This contains also agreed and disagreed cases\n",
    "merged_ua = pd.merge(du, unassisted_df, on='unit_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "id": "db2ee42d-01dd-464d-8211-d3729d97dfcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop multiple columns\n",
    "columns_to_drop = ['ID1', 'ID2','coder','jobset','unit_status', 'confidence_1', 'confidence_2']\n",
    "merged_ua = merged_ua.drop(columns=columns_to_drop)\n",
    "merged_ua.to_csv('../final_unassisted_merged.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b1a4d5-4eae-467c-8fcf-5973f9de02d4",
   "metadata": {},
   "source": [
    "### For assisted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "id": "7e4ed021-af57-4666-aed1-181a64f88ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the data file\n",
    "file_path = os.path.join(parent_directory, 'newspaper_data', 'final_2.csv')\n",
    "da=pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "id": "51db52b0-b52e-4e70-985a-2beb33c00e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge ID1 and ID2 into a new column unit_id\n",
    "da['unit_id'] = da['ID1'].astype(str) + '_' + da['ID2'].astype(str)\n",
    "# Rename the 'ID1' column to 'new_column_name'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "id": "5fa8af71-fe15-4135-9b78-5e35bfe9272b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using the mismatched unit_ids filter the dataset \n",
    "topic_da_mis = da[da['unit_id'].isin(topic_disagreements_a)]\n",
    "event_da_mis = da[da['unit_id'].isin(event_disagreements_a)]\n",
    "\n",
    "topic_da_mis.to_csv('../topic_a_mis.csv')\n",
    "event_da_mis.to_csv('../event_a_mis.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "id": "a53ddc9c-e8b6-4d8e-bfac-c8b1fe5017a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge unasisted with unassited coded\n",
    "\n",
    "# Merge df1 with df2 on 'unit_id'\n",
    "#This contains also agreed and disagreed cases\n",
    "merged_a = pd.merge(da, assisted_df, on='unit_id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "id": "e5f5a6af-2a98-43c2-8b11-715ff066e386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop multiple columns\n",
    "columns_to_drop = ['ID1', 'ID2','coder','jobset','unit_status', 'confidence_1', 'confidence_2']\n",
    "merged_a = merged_a.drop(columns=columns_to_drop)\n",
    "merged_a.to_csv('../final_assisted_merged.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfde4cc-9192-4884-b4db-a41e2a0a6002",
   "metadata": {},
   "source": [
    "### Create final validated dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "id": "1b1cfdcd-5299-4bb6-a861-fd17c6afb80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_with_expert(df1_path, df2_path, df3_path):\n",
    "    # Read in the DataFrames\n",
    "    df1 = pd.read_csv(df1_path)\n",
    "    df2 = pd.read_csv(df2_path)\n",
    "    df3 = pd.read_csv(df3_path)\n",
    "\n",
    "    # Pivot df2\n",
    "    df2_piv = df2.pivot_table(index='unit_id',\n",
    "                              columns='variable',\n",
    "                              values='value',\n",
    "                              aggfunc='first').reset_index()\n",
    "\n",
    "    df2_piv.fillna(0, inplace=True)\n",
    "\n",
    "    # Pivot df3\n",
    "    df3_piv = df3.pivot_table(index='unit_id',\n",
    "                              columns='variable',\n",
    "                              values='value',\n",
    "                              aggfunc='first').reset_index()\n",
    "\n",
    "    df3_piv.fillna(0, inplace=True)\n",
    "\n",
    "    # Merge the three DataFrames on 'unit_id'\n",
    "    merged_df = pd.merge(df1, df2_piv[['unit_id', 'topic_match']], how='left', on='unit_id', suffixes=('_df1', '_df2'))\n",
    "    merged_df = pd.merge(merged_df, df3_piv[['unit_id', 'event_match']], how='left', on='unit_id', suffixes=('_merged', '_df3'))\n",
    "\n",
    "    # Replace 'topic_match' in df1 with the values from df2 where they exist\n",
    "    merged_df['topic_match'] = merged_df['topic_match_df2'].combine_first(merged_df['topic_match_df1'])\n",
    "\n",
    "    # Replace 'event_match' in the merged_df with the values from df3 where they exist\n",
    "    merged_df['event_match'] = merged_df['event_match_df3'].combine_first(merged_df['event_match_merged'])\n",
    "\n",
    "    # Drop the temporary columns used for merging\n",
    "    merged_df = merged_df.drop(['topic_match_df1','topic_match_df2', 'event_match_df3', 'event_match_merged'], axis=1)\n",
    "\n",
    "    #add function to retain only the codings of coder 2606 any coder would do as now the annotations are aligned\n",
    "    # Add function to retain only the codings of coder 2606\n",
    "    one_coder = merged_df[merged_df['coder_id'] == 2606].copy()\n",
    "\n",
    "    return one_coder\n",
    "\n",
    "# Example usage\n",
    "df1_path = '../final_assisted_merged.csv'\n",
    "df2_path = '../annotations_185_expert_topic_a.csv.csv'\n",
    "df3_path = '../annotations_186_expert_event_a.csv.csv'\n",
    "\n",
    "assisted_final = merge_with_expert(df1_path, df2_path, df3_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "id": "8c3d64c6-10e0-4066-82b6-ff8cb7051bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_path = '../final_unassisted_merged.csv'\n",
    "df2_path = '../annotations_184_expert_topic_ua.csv.csv'\n",
    "df3_path = '../annotations_187_expert_event_ua.csv.csv'\n",
    "unassisted_final = merge_with_expert(df1_path, df2_path, df3_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "id": "3b6df610-3a2f-457c-b9ff-cba0a25f641a",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_validated = pd.concat([assisted_final, unassisted_final])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c660de-ae18-4107-81cc-f0008f8e96d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_validated.to_csv('../full_validated.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392af6e9-70cc-4bb1-b260-579a99fce2cc",
   "metadata": {},
   "source": [
    "### Get embeddings for the texts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "425835a7-ea4f-4d5c-88ba-5f3da071b5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from tqdm import tqdm\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b282f650-ca4d-4716-b291-5043c8cacd7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Similarity_Score</th>\n",
       "      <th>Text1</th>\n",
       "      <th>Text2</th>\n",
       "      <th>Group</th>\n",
       "      <th>Date1</th>\n",
       "      <th>Date2</th>\n",
       "      <th>Publisher1</th>\n",
       "      <th>Publisher2</th>\n",
       "      <th>proper_nouns1</th>\n",
       "      <th>proper_nouns2</th>\n",
       "      <th>keywords1</th>\n",
       "      <th>keywords2</th>\n",
       "      <th>unit_id</th>\n",
       "      <th>coder_id</th>\n",
       "      <th>topic_match</th>\n",
       "      <th>event_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.646155</td>\n",
       "      <td>Geweld bij antilockdowndemo in Dublin; Bij een...</td>\n",
       "      <td>Esther Ouwehand had niets met de plek waar ze ...</td>\n",
       "      <td>medium</td>\n",
       "      <td>2021-02-27 20:30:26</td>\n",
       "      <td>2021-03-01 00:00:00</td>\n",
       "      <td>NOS liveblog</td>\n",
       "      <td>Algemeen Dagblad</td>\n",
       "      <td>Geweld, Dublin, Leo Varadkar</td>\n",
       "      <td>Esther Ouwehand, Vinex, Esther Ouwehand, Uranu...</td>\n",
       "      <td>['ongeregeldheden', 'antilockdowndemo', 'wapen...</td>\n",
       "      <td>['hoornespolder', 'neptunus', 'rijtjeswoningen...</td>\n",
       "      <td>3287531_3286186</td>\n",
       "      <td>2606</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.760930</td>\n",
       "      <td>Stelling 5: gevaccineerde burgers moeten als e...</td>\n",
       "      <td>Sportscholen demonstratief open: 'Bewegen is n...</td>\n",
       "      <td>high</td>\n",
       "      <td>2021-02-28 23:18:22</td>\n",
       "      <td>2021-03-01 00:00:00</td>\n",
       "      <td>NOS liveblog</td>\n",
       "      <td>Trouw</td>\n",
       "      <td>Wilders, Marijnissen, Marijnissen, Klaver van ...</td>\n",
       "      <td>Tino Hoogendijk Sport, J</td>\n",
       "      <td>['sneltesten', 'gevaccineerden', 'gevaccineerd...</td>\n",
       "      <td>['instructeur', 'hometrainers', 'housebeat', '...</td>\n",
       "      <td>3287467_3285332</td>\n",
       "      <td>2606</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.820325</td>\n",
       "      <td>Vraag van de eigenaresse van een couscousbar a...</td>\n",
       "      <td>De uitzending van 1 maart: Gasvrij duurder dan...</td>\n",
       "      <td>high</td>\n",
       "      <td>2021-02-28 22:43:49</td>\n",
       "      <td>2021-03-01 12:06:47</td>\n",
       "      <td>NOS liveblog</td>\n",
       "      <td>Nieuwsuur</td>\n",
       "      <td>Wilders, Nadia, Wilders, Wilders bestrijdt, Na...</td>\n",
       "      <td>Friese Garijp, Noord-Holland Noord, Jan Nieuwe...</td>\n",
       "      <td>['onwenselijk', 'couscousbar', 'couscous', 'ne...</td>\n",
       "      <td>['nieuwenburg', 'gasvrij', 'besmettingen', 'aa...</td>\n",
       "      <td>3287471_6290579</td>\n",
       "      <td>2606</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0.774437</td>\n",
       "      <td>Stelling 4: de rekening van de coronacrisis mo...</td>\n",
       "      <td>Helft potentiële Forumstemmers vermoedt wereld...</td>\n",
       "      <td>high</td>\n",
       "      <td>2021-02-28 22:48:57</td>\n",
       "      <td>2021-03-01 00:00:00</td>\n",
       "      <td>NOS liveblog</td>\n",
       "      <td>De Volkskrant</td>\n",
       "      <td>Marijnissen, CDA, VVD</td>\n",
       "      <td>Forum voor Democratie, Ipsos, Baudet, Urk</td>\n",
       "      <td>['inkomensongelijkheid', 'marijnissen', 'belas...</td>\n",
       "      <td>['ipsos', 'forumstemmers', 'kiesgerechtigden',...</td>\n",
       "      <td>3287470_3285229</td>\n",
       "      <td>2606</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>0.731456</td>\n",
       "      <td>Stelling 2:  minimaal 10 procent van de bewind...</td>\n",
       "      <td>CPB-doorrekening: risico op maken van uitglije...</td>\n",
       "      <td>high</td>\n",
       "      <td>2021-02-28 22:03:24</td>\n",
       "      <td>2021-03-01 00:00:00</td>\n",
       "      <td>NOS liveblog</td>\n",
       "      <td>Het Financieele Dagblad</td>\n",
       "      <td>GroenLinks, SP, D66, Wilders, Zwarte Piet, Fri...</td>\n",
       "      <td>Is de invloed, CPB, Jean Dohmen, Centraal Plan...</td>\n",
       "      <td>['ronald', 'hilariteit', 'zit', 'westerse', 'm...</td>\n",
       "      <td>['doorrekeningen', 'uitglijer', 'berekeningen'...</td>\n",
       "      <td>3287477_3290566</td>\n",
       "      <td>2606</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>1470</td>\n",
       "      <td>1470</td>\n",
       "      <td>0.631112</td>\n",
       "      <td>Jozef Deleu: ‘Iets onder woorden brengen gaat ...</td>\n",
       "      <td>Pittig RTL-debat over klimaat, discriminatie e...</td>\n",
       "      <td>medium</td>\n",
       "      <td>2021-03-01 00:00:00</td>\n",
       "      <td>2021-03-01 01:19:49</td>\n",
       "      <td>NRC Handelsblad</td>\n",
       "      <td>NOS nieuws</td>\n",
       "      <td>Jozef Deleu, Jozef Deleu, Nederland zelfzuchti...</td>\n",
       "      <td>Wilders, Zwarte Piet, VVD, Wilders, Marijnisse...</td>\n",
       "      <td>['vlaams', 'zelfzuchtiger', 'bejaard', 'rekkem...</td>\n",
       "      <td>['gevaccineerden', 'gamechanger', 'coronamaatr...</td>\n",
       "      <td>3285657_3287465</td>\n",
       "      <td>2606</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>1473</td>\n",
       "      <td>1473</td>\n",
       "      <td>0.758489</td>\n",
       "      <td>Stelling 2:  minimaal 10 procent van de bewind...</td>\n",
       "      <td>Partijen willen hogere lasten voor bedrijven, ...</td>\n",
       "      <td>high</td>\n",
       "      <td>2021-02-28 22:03:24</td>\n",
       "      <td>2021-03-01 10:30:10</td>\n",
       "      <td>NOS liveblog</td>\n",
       "      <td>NOS nieuws</td>\n",
       "      <td>GroenLinks, SP, D66, Wilders, Zwarte Piet, Fri...</td>\n",
       "      <td>CPB, SGP, CPB, VVD, CDA, D66, GroenLinks, SP, ...</td>\n",
       "      <td>['ronald', 'hilariteit', 'zit', 'westerse', 'm...</td>\n",
       "      <td>['lastenverzwaring', 'doorrekeningen', 'verkie...</td>\n",
       "      <td>3287477_6290557</td>\n",
       "      <td>2606</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>1476</td>\n",
       "      <td>1476</td>\n",
       "      <td>0.756344</td>\n",
       "      <td>Naast groen en digitaal nu ook sociaal; Deze w...</td>\n",
       "      <td>Kaag (D66) wil meer vrijheden toestaan met vac...</td>\n",
       "      <td>high</td>\n",
       "      <td>2021-03-01 00:00:00</td>\n",
       "      <td>2021-03-01 00:00:00</td>\n",
       "      <td>Het Financieele Dagblad</td>\n",
       "      <td>Algemeen Dagblad</td>\n",
       "      <td>Europese Commissie, Ursula von der Leyen, Euro...</td>\n",
       "      <td>D66, Laten, Isra, Europese Commissie</td>\n",
       "      <td>['brexitreferendum', 'baanzekerheid', 'schiffe...</td>\n",
       "      <td>['gevaccineerde', 'vaccinatiebewijs', 'zelftes...</td>\n",
       "      <td>3290586_3286178</td>\n",
       "      <td>2606</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>1479</td>\n",
       "      <td>1479</td>\n",
       "      <td>0.788596</td>\n",
       "      <td>Een sterkere EU graag, maar nu is dat even bij...</td>\n",
       "      <td>Digitale campagne wordt platter én dieper; Ver...</td>\n",
       "      <td>high</td>\n",
       "      <td>2021-03-01 00:00:00</td>\n",
       "      <td>2021-03-01 00:00:00</td>\n",
       "      <td>Trouw</td>\n",
       "      <td>Trouw</td>\n",
       "      <td>PVV, D66, VVD</td>\n",
       "      <td>VVD, SP</td>\n",
       "      <td>['bikkelharde', 'mondkapjes', 'europese', 'opr...</td>\n",
       "      <td>['labradorpuppy', 'internethumor', 'beeldgrapp...</td>\n",
       "      <td>3285325_3285375</td>\n",
       "      <td>2606</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>1482</td>\n",
       "      <td>1482</td>\n",
       "      <td>0.699025</td>\n",
       "      <td>Wekdienst 28/2: Lijsttrekkers in debat • Krake...</td>\n",
       "      <td>Een boer versus D66-leider Kaag over de halver...</td>\n",
       "      <td>medium</td>\n",
       "      <td>2021-02-28 07:53:05</td>\n",
       "      <td>2021-02-28 21:41:40</td>\n",
       "      <td>NOS nieuws</td>\n",
       "      <td>NOS liveblog</td>\n",
       "      <td>VVD, PVV, CDA, D66, SP, GroenLinks, RTL Nieuws...</td>\n",
       "      <td>D66</td>\n",
       "      <td>['waait', 'amsterdam', 'vondelpark', 'goedemor...</td>\n",
       "      <td>['stikstofreductie', 'veestapel', 'langsgaan',...</td>\n",
       "      <td>3287521_3287479</td>\n",
       "      <td>2606</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>990 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0.1  Unnamed: 0  Similarity_Score  \\\n",
       "0               0           0          0.646155   \n",
       "1               3           3          0.760930   \n",
       "2               6           6          0.820325   \n",
       "3               9           9          0.774437   \n",
       "4              12          12          0.731456   \n",
       "..            ...         ...               ...   \n",
       "985          1470        1470          0.631112   \n",
       "986          1473        1473          0.758489   \n",
       "987          1476        1476          0.756344   \n",
       "988          1479        1479          0.788596   \n",
       "989          1482        1482          0.699025   \n",
       "\n",
       "                                                 Text1  \\\n",
       "0    Geweld bij antilockdowndemo in Dublin; Bij een...   \n",
       "1    Stelling 5: gevaccineerde burgers moeten als e...   \n",
       "2    Vraag van de eigenaresse van een couscousbar a...   \n",
       "3    Stelling 4: de rekening van de coronacrisis mo...   \n",
       "4    Stelling 2:  minimaal 10 procent van de bewind...   \n",
       "..                                                 ...   \n",
       "985  Jozef Deleu: ‘Iets onder woorden brengen gaat ...   \n",
       "986  Stelling 2:  minimaal 10 procent van de bewind...   \n",
       "987  Naast groen en digitaal nu ook sociaal; Deze w...   \n",
       "988  Een sterkere EU graag, maar nu is dat even bij...   \n",
       "989  Wekdienst 28/2: Lijsttrekkers in debat • Krake...   \n",
       "\n",
       "                                                 Text2   Group  \\\n",
       "0    Esther Ouwehand had niets met de plek waar ze ...  medium   \n",
       "1    Sportscholen demonstratief open: 'Bewegen is n...    high   \n",
       "2    De uitzending van 1 maart: Gasvrij duurder dan...    high   \n",
       "3    Helft potentiële Forumstemmers vermoedt wereld...    high   \n",
       "4    CPB-doorrekening: risico op maken van uitglije...    high   \n",
       "..                                                 ...     ...   \n",
       "985  Pittig RTL-debat over klimaat, discriminatie e...  medium   \n",
       "986  Partijen willen hogere lasten voor bedrijven, ...    high   \n",
       "987  Kaag (D66) wil meer vrijheden toestaan met vac...    high   \n",
       "988  Digitale campagne wordt platter én dieper; Ver...    high   \n",
       "989  Een boer versus D66-leider Kaag over de halver...  medium   \n",
       "\n",
       "                   Date1                Date2               Publisher1  \\\n",
       "0    2021-02-27 20:30:26  2021-03-01 00:00:00             NOS liveblog   \n",
       "1    2021-02-28 23:18:22  2021-03-01 00:00:00             NOS liveblog   \n",
       "2    2021-02-28 22:43:49  2021-03-01 12:06:47             NOS liveblog   \n",
       "3    2021-02-28 22:48:57  2021-03-01 00:00:00             NOS liveblog   \n",
       "4    2021-02-28 22:03:24  2021-03-01 00:00:00             NOS liveblog   \n",
       "..                   ...                  ...                      ...   \n",
       "985  2021-03-01 00:00:00  2021-03-01 01:19:49          NRC Handelsblad   \n",
       "986  2021-02-28 22:03:24  2021-03-01 10:30:10             NOS liveblog   \n",
       "987  2021-03-01 00:00:00  2021-03-01 00:00:00  Het Financieele Dagblad   \n",
       "988  2021-03-01 00:00:00  2021-03-01 00:00:00                    Trouw   \n",
       "989  2021-02-28 07:53:05  2021-02-28 21:41:40               NOS nieuws   \n",
       "\n",
       "                  Publisher2  \\\n",
       "0           Algemeen Dagblad   \n",
       "1                      Trouw   \n",
       "2                  Nieuwsuur   \n",
       "3              De Volkskrant   \n",
       "4    Het Financieele Dagblad   \n",
       "..                       ...   \n",
       "985               NOS nieuws   \n",
       "986               NOS nieuws   \n",
       "987         Algemeen Dagblad   \n",
       "988                    Trouw   \n",
       "989             NOS liveblog   \n",
       "\n",
       "                                         proper_nouns1  \\\n",
       "0                         Geweld, Dublin, Leo Varadkar   \n",
       "1    Wilders, Marijnissen, Marijnissen, Klaver van ...   \n",
       "2    Wilders, Nadia, Wilders, Wilders bestrijdt, Na...   \n",
       "3                                Marijnissen, CDA, VVD   \n",
       "4    GroenLinks, SP, D66, Wilders, Zwarte Piet, Fri...   \n",
       "..                                                 ...   \n",
       "985  Jozef Deleu, Jozef Deleu, Nederland zelfzuchti...   \n",
       "986  GroenLinks, SP, D66, Wilders, Zwarte Piet, Fri...   \n",
       "987  Europese Commissie, Ursula von der Leyen, Euro...   \n",
       "988                                      PVV, D66, VVD   \n",
       "989  VVD, PVV, CDA, D66, SP, GroenLinks, RTL Nieuws...   \n",
       "\n",
       "                                         proper_nouns2  \\\n",
       "0    Esther Ouwehand, Vinex, Esther Ouwehand, Uranu...   \n",
       "1                             Tino Hoogendijk Sport, J   \n",
       "2    Friese Garijp, Noord-Holland Noord, Jan Nieuwe...   \n",
       "3            Forum voor Democratie, Ipsos, Baudet, Urk   \n",
       "4    Is de invloed, CPB, Jean Dohmen, Centraal Plan...   \n",
       "..                                                 ...   \n",
       "985  Wilders, Zwarte Piet, VVD, Wilders, Marijnisse...   \n",
       "986  CPB, SGP, CPB, VVD, CDA, D66, GroenLinks, SP, ...   \n",
       "987               D66, Laten, Isra, Europese Commissie   \n",
       "988                                            VVD, SP   \n",
       "989                                                D66   \n",
       "\n",
       "                                             keywords1  \\\n",
       "0    ['ongeregeldheden', 'antilockdowndemo', 'wapen...   \n",
       "1    ['sneltesten', 'gevaccineerden', 'gevaccineerd...   \n",
       "2    ['onwenselijk', 'couscousbar', 'couscous', 'ne...   \n",
       "3    ['inkomensongelijkheid', 'marijnissen', 'belas...   \n",
       "4    ['ronald', 'hilariteit', 'zit', 'westerse', 'm...   \n",
       "..                                                 ...   \n",
       "985  ['vlaams', 'zelfzuchtiger', 'bejaard', 'rekkem...   \n",
       "986  ['ronald', 'hilariteit', 'zit', 'westerse', 'm...   \n",
       "987  ['brexitreferendum', 'baanzekerheid', 'schiffe...   \n",
       "988  ['bikkelharde', 'mondkapjes', 'europese', 'opr...   \n",
       "989  ['waait', 'amsterdam', 'vondelpark', 'goedemor...   \n",
       "\n",
       "                                             keywords2          unit_id  \\\n",
       "0    ['hoornespolder', 'neptunus', 'rijtjeswoningen...  3287531_3286186   \n",
       "1    ['instructeur', 'hometrainers', 'housebeat', '...  3287467_3285332   \n",
       "2    ['nieuwenburg', 'gasvrij', 'besmettingen', 'aa...  3287471_6290579   \n",
       "3    ['ipsos', 'forumstemmers', 'kiesgerechtigden',...  3287470_3285229   \n",
       "4    ['doorrekeningen', 'uitglijer', 'berekeningen'...  3287477_3290566   \n",
       "..                                                 ...              ...   \n",
       "985  ['gevaccineerden', 'gamechanger', 'coronamaatr...  3285657_3287465   \n",
       "986  ['lastenverzwaring', 'doorrekeningen', 'verkie...  3287477_6290557   \n",
       "987  ['gevaccineerde', 'vaccinatiebewijs', 'zelftes...  3290586_3286178   \n",
       "988  ['labradorpuppy', 'internethumor', 'beeldgrapp...  3285325_3285375   \n",
       "989  ['stikstofreductie', 'veestapel', 'langsgaan',...  3287521_3287479   \n",
       "\n",
       "     coder_id topic_match event_match  \n",
       "0        2606         Yes          No  \n",
       "1        2606          No          No  \n",
       "2        2606         Yes          No  \n",
       "3        2606         Yes          No  \n",
       "4        2606         Yes          No  \n",
       "..        ...         ...         ...  \n",
       "985      2606          No          No  \n",
       "986      2606         Yes          No  \n",
       "987      2606         Yes          No  \n",
       "988      2606         Yes          No  \n",
       "989      2606         Yes         Yes  \n",
       "\n",
       "[990 rows x 18 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_validated = pd.read_csv('../full_validated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bb0797cd-2fbe-40c7-b34b-cff0331c27c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at GroNLP/bert-base-dutch-cased and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_name = 'GroNLP/bert-base-dutch-cased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertModel.from_pretrained(model_name)\n",
    "\n",
    "Text1 = final_validated['Text1'].to_list()\n",
    "Text2 = final_validated['Text2'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cdb38d1d-0a4f-4fce-a93b-f60f5564b2bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing embeddings: 100%|███████████████████| 990/990 [00:42<00:00, 23.36it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#function to get embeddings with BERTje\n",
    "def get_embeddings(corpus):\n",
    "    embeddings = []\n",
    "    total_articles = len(corpus)\n",
    "\n",
    "    for article in tqdm(corpus, desc='Computing embeddings', ncols=80):\n",
    "        inputs = tokenizer(str(article), return_tensors='pt', padding=True, truncation=True)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        embeddings.append(outputs.pooler_output.squeeze().numpy())\n",
    "\n",
    "    return embeddings\n",
    "text1_embeddings = get_embeddings(Text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6a01e6ca-b489-42cc-a542-d86b4a7dab51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing embeddings: 100%|███████████████████| 990/990 [00:43<00:00, 22.83it/s]\n"
     ]
    }
   ],
   "source": [
    "text2_embeddings = get_embeddings(Text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "69ca365e-1947-4101-aa0a-cc7c57652b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the embeddings to the final_validated DataFrame\n",
    "final_validated['Text1_Embeddings'] = text1_embeddings\n",
    "final_validated['Text2_Embeddings'] = text2_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6dcc111f-1bea-47d5-96a8-17441f391034",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_validated.to_csv('../final_validated_with_embeddings.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cb90e146-e40b-4606-8131-64d9a5b1f56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the columns to keep in the new DataFrame\n",
    "columns_to_keep = ['unit_id', 'Date1', 'Date2', 'Text1_Embeddings', 'Text2_Embeddings', 'topic_match', 'event_match', 'Similarity_Score', 'Publisher1', 'Publisher2']  # Replace with your column names\n",
    "\n",
    "# Create a new DataFrame with only the specified columns\n",
    "gold_standard = final_validated[columns_to_keep].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "14507c4c-07b2-4657-8ae0-4c69366752bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_standard.to_csv('../gold_standard_inf_flows.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df05ae82-2c37-4921-85f1-d34008645767",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python 3.10",
   "language": "python",
   "name": "python_3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
