{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dde61e5e-e9cc-4399-a8d5-048d00697c5a",
   "metadata": {},
   "source": [
    "# Llama 7b for validation task\n",
    "\n",
    "* input: dataframe with text pairs and additional info LLama 2 should use to make informed decision\n",
    "* output: dataframe with additional columns: topic, topic match evalutation, topic match classification, news event, news event match evaluation, news event match classification, final classification on topic-level and news event level matching\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803e94b3-b330-4fd0-a1b4-f551494c0188",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "629e3acb-b512-4f07-bd44-ad67fa7d8e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from torch import cuda, bfloat16\n",
    "import transformers\n",
    "import pandas as pd\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chains import SequentialChain\n",
    "from transformers import pipeline\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd0447c-ca9b-4de2-9492-85c3a244dbe2",
   "metadata": {},
   "source": [
    "## Load model though huggingface pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cec9f8ed-1605-49f4-a9f1-0b4f356301ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/volume_2/python_3.10/lib/python3.10/site-packages/transformers/modeling_utils.py:2193: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4457130e0da24314a21b8cd5d7ce86fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded on cuda:0\n"
     ]
    }
   ],
   "source": [
    "hf_auth_file = '../../analysis/hf_auth.txt'\n",
    "\n",
    "# Read the API token from the file\n",
    "with open(hf_auth_file, \"r\") as file:\n",
    "    hf_auth = file.read().strip()  # Remove leading/trailing whitespaces\n",
    "\n",
    "model_id = 'meta-llama/Llama-2-7b-chat-hf'\n",
    "\n",
    "device = f'cuda:{cuda.current_device()}' if cuda.is_available() else 'cpu'\n",
    "\n",
    "# set quantization configuration to load large model with less GPU memory\n",
    "# this requires the `bitsandbytes` library\n",
    "bnb_config = transformers.BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type='nf4',\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=bfloat16\n",
    ")\n",
    "\n",
    "# begin initializing HF items, need auth token for these\n",
    "model_config = transformers.AutoConfig.from_pretrained(\n",
    "    model_id,\n",
    "    use_auth_token=hf_auth\n",
    ")\n",
    "\n",
    "model = transformers.AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    trust_remote_code=True,\n",
    "    config=model_config,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map='auto',\n",
    "    use_auth_token=hf_auth\n",
    ")\n",
    "model.eval()\n",
    "print(f\"Model loaded on {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bb6d99e-2842-4da6-9032-41f1bc5e37b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/volume_2/python_3.10/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1714: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
    "    model_id,\n",
    "    use_auth_token=hf_auth\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a4c1b09-5715-46e7-88eb-822b2b2fa4ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Name: NVIDIA A10\n",
      "Memory Usage: 1.9429621696472168 GB\n",
      "Max Memory Usage: 1.9639196395874023 GB\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda')\n",
    "print(\"GPU Name:\", torch.cuda.get_device_name(device))\n",
    "print(\"Memory Usage:\", torch.cuda.memory_allocated(device) / 1024 ** 3, \"GB\")\n",
    "print(\"Max Memory Usage:\", torch.cuda.max_memory_allocated(device) / 1024 ** 3, \"GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b54484da-e4b1-457b-8c36-8d50e6ee2bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_text = transformers.pipeline(\n",
    "    model=model, tokenizer=tokenizer,\n",
    "    return_full_text=True,  # langchain expects the full text\n",
    "    task='text-generation',\n",
    "    temperature=0,  # 'randomness' of outputs, 0.0 is the min and 1.0 the max we do not want any randomness here as we want the model to stick to the prompt as closely as possible\n",
    "    max_new_tokens=512,  # max number of tokens to generate in the output\n",
    "    repetition_penalty=1.1  # without this output begins repeating\n",
    ")\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=generate_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f474429-5dd0-4991-9975-352fa8b0d7bc",
   "metadata": {},
   "source": [
    "## Read in data file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "455618db-c310-4aa4-a33c-85f30770ef86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to navigate up 'n' levels\n",
    "def navigate_up(current_directory, levels):\n",
    "    for _ in range(levels):\n",
    "        current_directory = os.path.dirname(current_directory)\n",
    "    return current_directory\n",
    "\n",
    "# Get the current working directory\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# Specify the number of levels to navigate up (4 levels in this case)\n",
    "levels_to_navigate = 4\n",
    "\n",
    "# Navigate up 'levels_to_navigate' folders\n",
    "parent_directory = navigate_up(current_directory, levels_to_navigate)\n",
    "\n",
    "# Define the path to the data file\n",
    "file_path = os.path.join(parent_directory, 'newspaper_data', 'sample_1percent.csv')\n",
    "\n",
    "# Now you can open and read the CSV file using pandas\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f8a58d5f-caf5-44c4-aff5-bd7fbd6e4f7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Similarity_Score</th>\n",
       "      <th>Text1</th>\n",
       "      <th>Text2</th>\n",
       "      <th>Group</th>\n",
       "      <th>Date1</th>\n",
       "      <th>Date2</th>\n",
       "      <th>Publisher1</th>\n",
       "      <th>Publisher2</th>\n",
       "      <th>ID1</th>\n",
       "      <th>ID2</th>\n",
       "      <th>proper_nouns1</th>\n",
       "      <th>proper_nouns2</th>\n",
       "      <th>keywords1</th>\n",
       "      <th>keywords2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.765668</td>\n",
       "      <td>Alle pijlen zijn gericht op Rutte in RTL-debat...</td>\n",
       "      <td>Helft van de Forum-stemmers ziet complot; De h...</td>\n",
       "      <td>high</td>\n",
       "      <td>2021-03-01 00:00:00</td>\n",
       "      <td>2021-03-01 00:00:00</td>\n",
       "      <td>De Volkskrant</td>\n",
       "      <td>Trouw</td>\n",
       "      <td>3285226</td>\n",
       "      <td>3285337</td>\n",
       "      <td>Radio 1, RTL, VVD, kernboodschap gelieve, Sigr...</td>\n",
       "      <td>Forum voor Democratie, Ipsos</td>\n",
       "      <td>['lijsttrekkersdebat', 'premiersdebat', 'paree...</td>\n",
       "      <td>['ipsos', 'coronavirus', 'gefabriceerd', 'comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.683993</td>\n",
       "      <td>Hoogste bestuursrechter liet forse steken vall...</td>\n",
       "      <td>Stelling 3: Om de klimaatdoelen te halen moet ...</td>\n",
       "      <td>medium</td>\n",
       "      <td>2021-02-28 00:00:00</td>\n",
       "      <td>2021-02-28 22:22:56</td>\n",
       "      <td>Het Financieele Dagblad</td>\n",
       "      <td>NOS liveblog</td>\n",
       "      <td>3290695</td>\n",
       "      <td>3287474</td>\n",
       "      <td>Andr Bosman, VVD, Tweede Kamer, Raad van State...</td>\n",
       "      <td>VVD, Poetin</td>\n",
       "      <td>['overheidsinstantie', 'kinderopvangtoeslagen'...</td>\n",
       "      <td>['klimaatdoelen', 'kerncentrales', 'rusland', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.848039</td>\n",
       "      <td>Planbureau: vertrek bedrijven reëel risico bij...</td>\n",
       "      <td>Baudet: corona niet bewust wereld in geslinger...</td>\n",
       "      <td>high</td>\n",
       "      <td>2021-03-01 00:00:00</td>\n",
       "      <td>2021-03-01 10:34:06</td>\n",
       "      <td>Het Financieele Dagblad</td>\n",
       "      <td>NOS nieuws</td>\n",
       "      <td>3290604</td>\n",
       "      <td>6290556</td>\n",
       "      <td>Planbureau, Planbureau voor de Leefomgeving, P...</td>\n",
       "      <td>Baudet, Forum voor Democratie-voorman Thierry ...</td>\n",
       "      <td>['broeikasgasuitstoot', 'klimaatwinst', 'leefo...</td>\n",
       "      <td>['virussen', 'chinees', 'ebolavirus', 'ingesto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.805225</td>\n",
       "      <td>Recht op reparatie van apparatuur komt steeds ...</td>\n",
       "      <td>Niet een lijsttrekker, maar een kiezer brengt ...</td>\n",
       "      <td>high</td>\n",
       "      <td>2021-03-01 00:00:00</td>\n",
       "      <td>2021-03-01 00:00:00</td>\n",
       "      <td>Het Financieele Dagblad</td>\n",
       "      <td>NRC Handelsblad</td>\n",
       "      <td>3290567</td>\n",
       "      <td>3285627</td>\n",
       "      <td>REPAIR, CAF S Jeroen Groot, Philips, Leenman, ...</td>\n",
       "      <td>Mark Rutte, RTL, Mark Rutte, Mark Rutte, Geert...</td>\n",
       "      <td>['verwarmingselement', 'reparateurs', 'koffiez...</td>\n",
       "      <td>['lijsttrekkersdebat', 'toeslagenaffaire', 'on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.631177</td>\n",
       "      <td>Dode en gewonde door zuurstofexplosie corona-a...</td>\n",
       "      <td>Wilders in de schijnwerpers; Wilders in de sch...</td>\n",
       "      <td>medium</td>\n",
       "      <td>2021-02-27 22:39:37</td>\n",
       "      <td>2021-03-01 00:00:00</td>\n",
       "      <td>NOS liveblog</td>\n",
       "      <td>De Telegraaf</td>\n",
       "      <td>3287529</td>\n",
       "      <td>3286364</td>\n",
       "      <td>Oekra, Twintig, Oekra</td>\n",
       "      <td>Wilders, Mark Rutte, Sigrid Kaag D66, Wilders,...</td>\n",
       "      <td>['tsjernivtsi', 'zaporizja', 'zuurstofexplosie...</td>\n",
       "      <td>['diversiteitsquota', 'ronald', 'rtl', 'zit', ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Similarity_Score                                              Text1  \\\n",
       "5          0.765668  Alle pijlen zijn gericht op Rutte in RTL-debat...   \n",
       "6          0.683993  Hoogste bestuursrechter liet forse steken vall...   \n",
       "7          0.848039  Planbureau: vertrek bedrijven reëel risico bij...   \n",
       "8          0.805225  Recht op reparatie van apparatuur komt steeds ...   \n",
       "9          0.631177  Dode en gewonde door zuurstofexplosie corona-a...   \n",
       "\n",
       "                                               Text2   Group  \\\n",
       "5  Helft van de Forum-stemmers ziet complot; De h...    high   \n",
       "6  Stelling 3: Om de klimaatdoelen te halen moet ...  medium   \n",
       "7  Baudet: corona niet bewust wereld in geslinger...    high   \n",
       "8  Niet een lijsttrekker, maar een kiezer brengt ...    high   \n",
       "9  Wilders in de schijnwerpers; Wilders in de sch...  medium   \n",
       "\n",
       "                 Date1                Date2               Publisher1  \\\n",
       "5  2021-03-01 00:00:00  2021-03-01 00:00:00            De Volkskrant   \n",
       "6  2021-02-28 00:00:00  2021-02-28 22:22:56  Het Financieele Dagblad   \n",
       "7  2021-03-01 00:00:00  2021-03-01 10:34:06  Het Financieele Dagblad   \n",
       "8  2021-03-01 00:00:00  2021-03-01 00:00:00  Het Financieele Dagblad   \n",
       "9  2021-02-27 22:39:37  2021-03-01 00:00:00             NOS liveblog   \n",
       "\n",
       "        Publisher2      ID1      ID2  \\\n",
       "5            Trouw  3285226  3285337   \n",
       "6     NOS liveblog  3290695  3287474   \n",
       "7       NOS nieuws  3290604  6290556   \n",
       "8  NRC Handelsblad  3290567  3285627   \n",
       "9     De Telegraaf  3287529  3286364   \n",
       "\n",
       "                                       proper_nouns1  \\\n",
       "5  Radio 1, RTL, VVD, kernboodschap gelieve, Sigr...   \n",
       "6  Andr Bosman, VVD, Tweede Kamer, Raad van State...   \n",
       "7  Planbureau, Planbureau voor de Leefomgeving, P...   \n",
       "8  REPAIR, CAF S Jeroen Groot, Philips, Leenman, ...   \n",
       "9                              Oekra, Twintig, Oekra   \n",
       "\n",
       "                                       proper_nouns2  \\\n",
       "5                       Forum voor Democratie, Ipsos   \n",
       "6                                        VVD, Poetin   \n",
       "7  Baudet, Forum voor Democratie-voorman Thierry ...   \n",
       "8  Mark Rutte, RTL, Mark Rutte, Mark Rutte, Geert...   \n",
       "9  Wilders, Mark Rutte, Sigrid Kaag D66, Wilders,...   \n",
       "\n",
       "                                           keywords1  \\\n",
       "5  ['lijsttrekkersdebat', 'premiersdebat', 'paree...   \n",
       "6  ['overheidsinstantie', 'kinderopvangtoeslagen'...   \n",
       "7  ['broeikasgasuitstoot', 'klimaatwinst', 'leefo...   \n",
       "8  ['verwarmingselement', 'reparateurs', 'koffiez...   \n",
       "9  ['tsjernivtsi', 'zaporizja', 'zuurstofexplosie...   \n",
       "\n",
       "                                           keywords2  \n",
       "5  ['ipsos', 'coronavirus', 'gefabriceerd', 'comp...  \n",
       "6  ['klimaatdoelen', 'kerncentrales', 'rusland', ...  \n",
       "7  ['virussen', 'chinees', 'ebolavirus', 'ingesto...  \n",
       "8  ['lijsttrekkersdebat', 'toeslagenaffaire', 'on...  \n",
       "9  ['diversiteitsquota', 'ronald', 'rtl', 'zit', ...  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the DataFrame into 20 smaller DataFrames for the sake of fast tuning of prompting, each containing 5 rows\n",
    "# Split the DataFrame into 20 smaller DataFrames, each containing 5 rows\n",
    "chunk_size = 5\n",
    "chunks = [df.iloc[i:i+chunk_size] for i in range(0, len(df), chunk_size)]\n",
    "\n",
    "# Create variables for each smaller DataFrame\n",
    "for i, chunk in enumerate(chunks):\n",
    "    globals()[f'df{i + 1}'] = chunk\n",
    "\n",
    "# Now you have variables df1, df2, df3, ... containing the smaller DataFrames\n",
    "# You can access and work with them as needed\n",
    "df2\n",
    "#df2\n",
    "#....\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7223f53a-b58e-4f8b-8288-b7afc0989552",
   "metadata": {},
   "source": [
    "#  Prompting \n",
    "\n",
    "Prompting takes shapes in many sequetial instructions. We divide the prompts themselves into system prompt, example prompt, and main prompt to geenrate a template for each subtask. We begin with the broadest level, topic-level matching task. This task is also divided into three sepearate subtasks: (1) create topic labels for eacg text, (2) compare the topic labels and texts to decide to what extent they match, and (3) based on the explanation create a single classification topic match or no topic match. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0916b9e-02e6-4ed8-9994-f1067cf8f0b2",
   "metadata": {},
   "source": [
    "## Step 1: Extract topics. \n",
    "The prompt template is based on Grootendorst, BERTopic LLama2 implementation with example from our full dataset.\n",
    "* Important to note that for each step we pass in a system prompt, give and example, and provide a main prompt that signifies the variables and content to be considered.\n",
    "* Then we create a chain from the prompt for further sequential chaining with LangChain\n",
    "* Very important here to intially extract main topic and subtopic in order to obtain clear topics. If subtopics are not requested then the model might not understand that a topic that mentions politicians and conspiracy theories belongs to the broader topic of politics and instead it may label it as conspiracy theories alone. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e22ef277-6196-42ed-9f66-562bc5451c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt_1 = \"\"\"\n",
    "<s>[INST] <<SYS>>\n",
    "You are a helpful, respectful and honest assistant for labeling topics. A \"topic\" is a fundamental subject or theme that encompasses all aspects related to a particular area of interest or discussion. \n",
    "A topic serves as the overarching framework for exploring and discussing various facets within that subject. A topic comprises of a main topic and a subtopic. A main topic is an overarching theme, a subtopic is a more specific thematic or content-based divisions within a broader main topic. All main topics are labeled Politics if the documents' keywords and proper nouns relate to politics. For instance if the text discusses the economy but a politician, party, or government is mentioned either in the text or in the keywords then it should be categorized as Politics and not Economy.  \n",
    "Main topic: Politics; Subtopic: Elections and campaigns\n",
    "Main topic: Economy; Subtopic: Interest rates\n",
    "Main topic: Health; Subtopic: Mental health\n",
    "Main topic: Entertainment; Subtopic: Film and Television \\n\n",
    "\n",
    "If a text mentions politics, politicians names functions, parties, policy, or any other politics-related term, the main topic should always be Politics.\\n\n",
    "\n",
    "\n",
    "You must always return a main topic and a subtopic and nothing else in the following format: Main topic1 : Subtopic;, Main topic2: Subtopic\n",
    "Do not return any notes. Only return the label and nothing more for each text.\n",
    "\n",
    "<</SYS>>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7dfff572-4e5d-456c-a487-f3a5709fd042",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_prompt_1 = \"\"\"\n",
    "I have a document pair of the following texts:\\n\n",
    "- Contact met de kiezer; Deze keer zie je geen lijsttrekkers in windjacks rondlopen op markten. Kandidaat-Kamerleden moeten noodgedwongen online contact zoeken met de kiezers. Zoals de lijsttrekker van de ChristenUnie, Gert-Jan Segers, te zien is op de bovenstaande afbeelding terwijl hij vragen beantwoordt die kiezers hem stellen op het online platform Instagram. In plaats van direct met de burgers te praten, spreken politici nu voor de camera's. Livestreams op Facebook zijn ook populair. Zo had Mark Rutte dit weekend een gesprek met horeca-ondernemers en zond de VVD dat uit op Facebook. Naast de online campagne werd er dit weekend ook op de ouderwetse manier geflyerd. Maar de meeste campagnevoerende partijleden gingen niet aanbellen uit angst voor verdere verspreiding van het coronavirus. Forum voor Democratie was de enige partij die de straat op ging om campagne te voeren. Met een vrijheidskaravaan bezocht de partij Nijmegen en Venlo voor een manifestatie. Toen er meer dan tweehonderd mensen kwamen opdagen, moest burgemeester Hubert Bruls de bijeenkomst voortijdig beëindigen, hoewel deze wel was aangekondigd en aangevraagd. Een bezoeker in Venlo twitterde dat het centrale plein voor het eerst sinds carnaval vorig jaar weer vol stond met de komst van Baudet.\n",
    "- Forum voor Democratie op zoek naar extra stemmen; Terwijl andere partijen zich nauwelijks op straat vertonen, reist Forum voor Democratie stad en land af. Deze optredens trekken niet alleen de aandacht van kiezers; het Openbaar Ministerie onderzoekt nu ook of het campagneteam van Baudet de coronaregels op grote schaal heeft overtreden. Volgens getuigen werden bij een bezoek aan Urk honderden handen geschud. En dan was er nog de volmachtrel. In een live-uitzending riep Baudet zijn kijkers op om zoveel mogelijk volmachtstemmen te regelen, aangezien kiezers dit jaar niet twee, maar drie volmachtstemmen mogen uitbrengen om de kans op besmetting te verkleinen. \"Een persoon kan eigenlijk vier keer stemmen, als je maar die volmachten kunt regelen,\" zei Baudet, en dat was een enorme kans. Maar het ministerie van Binnenlandse Zaken zei: \"Ho, dat is niet de bedoeling en is niet toegestaan.\" Het campagneteam van Forum leek daar toen al achter te komen, want de suggestie om stemmen te regelen werd snel uit de video van Baudet geknipt. Baudet houdt echter wel openlijk vast aan zijn standpunt dat er een grote kans is op verkiezingsfraude, maar dan door anderen, uiteraard.\n",
    "\n",
    "The topic of each text is described by the following keywords: 'livesessies', 'vrijheidskaravaan', 'flyerende', 'facebook', 'windjacks'; besmettingskansen', 'volmachtsstemmen', 'schielijk', 'volmachten', 'baudets'\n",
    "The following proper nouns appear in each text: Gert-Jan Segers, Mark Rutte, Forum voor Democratie, Hubert Bruls, Baudet; Forum voor Democratie, Forum voor Democratie, Ministerie kijkt, Urk, Baudet, Baudet, Baudet, Baudet\n",
    "\n",
    "Based on the information about the topic above, please create a short label of the topic for each text. Only return the label and nothing more for each text in the following format:\n",
    "\n",
    "[/INST] Main topic 1: Politics; Subtopic: Elections and campaigns; Main topic 2: Politics; Subtopic: Elections, campaigns and fraud \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c877972-294b-487f-9aac-ff6f219a8f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_prompt_1 = \"\"\"\n",
    "[INST]\n",
    "I have a document pair of the following texts:\n",
    "{text1} and {text2}\n",
    "\n",
    "The topic of each text is described by the following keywords: {keywords1} and {keywords2}\n",
    "The following proper nouns appear in each text: {proper_nouns1}, {proper_nouns2}\n",
    "\n",
    "Based on the information about the topic above, please create a short label of this topic for each text. Only return the label and nothing more for each text in the following format: Main topic 1 : Subtopic ; Main topic 2: Subtopic\n",
    "[/INST]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc436448-e169-4fb8-8074-d545954cda23",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_1 = system_prompt_1 + example_prompt_1 + main_prompt_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db37e1b9-405c-4f3b-b596-f74c31742551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a PromptTemplate instance\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"text1\", \"text2\", 'proper_nouns1', 'proper_nouns2', 'keywords1', 'keywords2'],\n",
    "    template=prompt_1\n",
    ")\n",
    "\n",
    "# Create the LLMChain instance\n",
    "chain_1 = LLMChain(llm = llm, prompt = prompt_template, output_key=\"topics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b27fe3f-2cf4-4b8e-8045-eb12d338dfdd",
   "metadata": {},
   "source": [
    "### Step 1.1: Extract main topic from topics for matching\n",
    "\n",
    "¶This is a must otherwise the chain considers subtopics as the level of match and disregards those that match on a broad level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8493b2e7-1417-4789-9d70-8407fe74c1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt_1_1 = \"\"\"\n",
    "<s>[INST] <<SYS>>\n",
    "You are a helpful, respectful and honest assistant for extracting the main topic from a topic. \n",
    "A topic comprises of a main topic and a subtopic. A main topic is an overarching theme, a subtopic is a more specific thematic or content-based divisions within a broader main topic.\n",
    "Main topic: Economy; Subtopic: Interest rates\n",
    "Main topic: Health; Subtopic: Mental health\n",
    "Main topic: Entertainment; Subtopic: Film and Television \n",
    "\n",
    "A main topic is everything before the word 'Subtopic'\n",
    "Given a topic, you must always return the main topic nothing else in the following format: Main topic1, Main topic2: \n",
    "Only return the main topic label and nothing more for each text.\n",
    "\n",
    "<</SYS>>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce1fc52f-1630-44e0-9293-7710b0b4e2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_prompt_1_1 = \"\"\"\n",
    "I have a pair of topics:\n",
    "Main topic 1: Politics; Subtopic: Elections and campaigns; \\n\n",
    "Main topic 2: Politics; Subtopic: Elections, campaigns and fraud \\n\n",
    "\n",
    "Based on the information about the topic above, please extract the main topic from each topic. A main topic is everything before the word 'Subtopic'. In this case this word is Politics. Only return the label of the main topic and nothing more in the following format:\n",
    "\n",
    "[/INST] Main topic 1: Politics; Main topic 2: Politics\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c5233e73-ba42-403b-92a2-df91a0f3b2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_prompt_1_1 = \"\"\"\n",
    "[INST]\n",
    "I have a pair of topics:\n",
    "{topics}\n",
    "\n",
    "Based on the information about the topic above, please extract the main topic from each topic. Only return the label of the main topic and nothing more in the following format:\n",
    "Main topic 1: ; Main topic 2: \n",
    "[/INST]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bec45d2e-f56a-400f-be92-ed91a4925e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_1_1 = system_prompt_1_1 + example_prompt_1_1 + main_prompt_1_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a51d9dbb-651f-4ee3-8bc8-8910c0baec4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_1 = PromptTemplate(\n",
    "    input_variables=[\"topics\"],\n",
    "    template=prompt_1_1\n",
    ")\n",
    "\n",
    "# Create the LLMChain instance\n",
    "chain_1_1 = LLMChain(llm = llm, prompt = prompt_template_1, output_key=\"main_topic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c1fd05-4d0c-4a6b-a5ba-7d9b640c7ff2",
   "metadata": {},
   "source": [
    "## Step 2: Evaluate topic level match\n",
    "Compare the topics of the text pairs and made eveluation about the match level  \n",
    "\n",
    "* We create a second chain for this task that uses the texts as well as the extrcated topics as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2e9a0db-7285-4a78-a12a-036c4a1f99a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt_2 = \"\"\"\n",
    "<s>[INST] <<SYS>>\n",
    "You are a helpful, respectful, and honest assistant for comparing the main topics of two texts. In this comparison, a match is solely based on the main topic and nothing else.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "711b57fe-e781-4578-8285-40a97fd56803",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_prompt_2 = \"\"\"\n",
    "\n",
    "The main topic of each text is described by the following labels:\n",
    "\n",
    "Main topic 1: Politics;  \n",
    "Main topic 2: Politics; \n",
    "\n",
    "\n",
    "Based on the information about the main topics above, please write a short evaluation about whether the two texts match on a main topic level. Make sure to only return the evaluation and nothing more in the following format:\n",
    "\n",
    "[/INST] Topic Evaluation: Yes, the two texts match on a main topic level because both texts touch upon the broader context of Politics. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6b17947b-70af-4abd-9ba4-0084ea40bac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_prompt_2 = \"\"\"\n",
    "[INST]\n",
    "\n",
    "The main topic of each text is the following: \n",
    "{main_topic}\n",
    "\n",
    "Based on the information about the topics above, please write a short evaluation about whether the two texts match on a main topic level. Make sure to only return the evaluation and nothing more in the following format:\n",
    "Topic Evaluation:\n",
    "[/INST] \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "19600ef7-e635-461f-9e2c-dba231419966",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_2 = system_prompt_2 + example_prompt_2 + main_prompt_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d4dd2a0c-56c3-4d95-b348-b15a00689bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_2 = PromptTemplate(input_variables=[\"main_topic\"], template=prompt_2, batch_size=32, max_iterations = 1)\n",
    "chain_2 = LLMChain(llm = llm, prompt = prompt_template_2, output_key=\"topic_evaluation\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f502d04-13d7-4f17-80b2-dca31ac33ed8",
   "metadata": {},
   "source": [
    "### Step 2.1 extract words used to make topic-level evaluation decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b4a4da73-741e-4598-a5f6-40061a36fb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt_2_1 = \"\"\"\n",
    "<s>[INST] <<SYS>>\n",
    "You are a helpful, respectful, and honest assistant for comparing the main topics of two texts. In this comparison, a match is solely based on the main topic and nothing else.\n",
    "Your task is to provide a list of comma separated keywords for each text that you used to make your evaluation. Only provide a list and nothing more. Avoid notes, thank yous and any other filler information. \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6ecf5f27-0c78-4ebc-8aac-2f136e7a681c",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_prompt_2_1 = \"\"\"\n",
    "\n",
    "I have a document pair of the following texts:\\n\n",
    "- Contact met de kiezer; Deze keer zie je geen lijsttrekkers in windjacks rondlopen op markten. Kandidaat-Kamerleden moeten noodgedwongen online contact zoeken met de kiezers. Zoals de lijsttrekker van de ChristenUnie, Gert-Jan Segers, te zien is op de bovenstaande afbeelding terwijl hij vragen beantwoordt die kiezers hem stellen op het online platform Instagram. In plaats van direct met de burgers te praten, spreken politici nu voor de camera's. Livestreams op Facebook zijn ook populair. Zo had Mark Rutte dit weekend een gesprek met horeca-ondernemers en zond de VVD dat uit op Facebook. Naast de online campagne werd er dit weekend ook op de ouderwetse manier geflyerd. Maar de meeste campagnevoerende partijleden gingen niet aanbellen uit angst voor verdere verspreiding van het coronavirus. Forum voor Democratie was de enige partij die de straat op ging om campagne te voeren. Met een vrijheidskaravaan bezocht de partij Nijmegen en Venlo voor een manifestatie. Toen er meer dan tweehonderd mensen kwamen opdagen, moest burgemeester Hubert Bruls de bijeenkomst voortijdig beëindigen, hoewel deze wel was aangekondigd en aangevraagd. Een bezoeker in Venlo twitterde dat het centrale plein voor het eerst sinds carnaval vorig jaar weer vol stond met de komst van Baudet.\n",
    "- Forum voor Democratie op zoek naar extra stemmen; Terwijl andere partijen zich nauwelijks op straat vertonen, reist Forum voor Democratie stad en land af. Deze optredens trekken niet alleen de aandacht van kiezers; het Openbaar Ministerie onderzoekt nu ook of het campagneteam van Baudet de coronaregels op grote schaal heeft overtreden. Volgens getuigen werden bij een bezoek aan Urk honderden handen geschud. En dan was er nog de volmachtrel. In een live-uitzending riep Baudet zijn kijkers op om zoveel mogelijk volmachtstemmen te regelen, aangezien kiezers dit jaar niet twee, maar drie volmachtstemmen mogen uitbrengen om de kans op besmetting te verkleinen. \"Een persoon kan eigenlijk vier keer stemmen, als je maar die volmachten kunt regelen,\" zei Baudet, en dat was een enorme kans. Maar het ministerie van Binnenlandse Zaken zei: \"Ho, dat is niet de bedoeling en is niet toegestaan.\" Het campagneteam van Forum leek daar toen al achter te komen, want de suggestie om stemmen te regelen werd snel uit de video van Baudet geknipt. Baudet houdt echter wel openlijk vast aan zijn standpunt dat er een grote kans is op verkiezingsfraude, maar dan door anderen, uiteraard.\n",
    "\n",
    "The main topic of each text is described by the following labels:\n",
    "\n",
    "- Main topic 1: Politics;  \n",
    "- Main topic 2: Politics; \n",
    "\n",
    "The following evaluation describes whether the two texts match on a main topic level:\n",
    "- Topic Evaluation: Yes, the two texts match on a main topic level because both texts touch upon the broader context of Politics as seen by their main Topic. \n",
    "\n",
    "\n",
    "Based on the information above please provide a list of comma separated words that indicate the words that best describe the topic of each text. Make sure to only return the comma separated list of words and nothing else in the following format:\n",
    "[/INST] Contact met de kiezer, Kandidaat-Kamerleden, Online contact, Instagram, Politici voor de camera's, Livestreams op Facebook, Flyeren, Angst voor verspreiding van het coronavirus, Forum voor Democratie, Vrijheidskaravaan, Burgemeester Hubert Bruls, Bezoeker in Venlo, Centrale plein, Baudet; Forum voor Democratie, Optredens, Openbaar Ministerie, Coronaregels overtreden, Bezoek aan Urk, Handen schudden, Volmachtrel, Volmachtstemmen regelen, Ministerie van Binnenlandse Zaken, Verkiezingsfraude\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e8f18193-5e2c-41e7-aae6-4986a7314138",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_prompt_2_1 = \"\"\"\n",
    "[INST]\n",
    "\n",
    "I have a document pair of the following texts:\n",
    "{text1} and {text2}\n",
    "\n",
    "The main topic of each text is the following: \n",
    "{main_topic}\n",
    "\n",
    "The following evaluation describes whether the two texts match on a main topic level:\n",
    "{topic_evaluation}\n",
    "\n",
    "Based on the information above please provide a list of comma separated words that you used to make this evaluation. Make sure to only return the comma separated list of words and nothing else in the following format:\n",
    "[/INST]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "13747a28-ab02-4186-bfc2-f4789b86d71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_2_1 = system_prompt_2_1 + example_prompt_2_1 + main_prompt_2_1\n",
    "prompt_template_2_1 = PromptTemplate(input_variables=[\"text1\", \"text2\", \"main_topic\", \"topic_evaluation\" ], template=prompt_2_1, batch_size=32, max_iterations = 1)\n",
    "chain_2_1 = LLMChain(llm = llm, prompt = prompt_template_2_1, output_key=\"topic_words\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "629cde3c-0a78-402e-afad-dba7e2d053c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_chain = SequentialChain(\n",
    "    chains=[chain_1, chain_1_1, chain_2, chain_2_1], input_variables = [\"text1\", \"text2\", \"proper_nouns1\", \"proper_nouns2\", 'keywords1', 'keywords2'],output_variables=[\"topics\", \"main_topic\", \"topic_evaluation\", \"topic_words\"],\n",
    "    verbose=True )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85d56a4-48e0-46fb-8d0d-d2b625b7b758",
   "metadata": {},
   "source": [
    "# Test if it works\n",
    "for index, row in df2.iterrows():\n",
    "    full_text1 = row['Text1']  \n",
    "    full_text2 = row['Text2']  \n",
    "\n",
    "    input_variables = {\n",
    "        \"text1\": full_text1,\n",
    "        \"text2\": full_text2,\n",
    "        \"proper_nouns1\": row['proper_nouns1'],\n",
    "        \"proper_nouns2\": row['proper_nouns2'],\n",
    "        \"keywords1\": row['keywords1'],\n",
    "        \"keywords2\": row['keywords2'],\n",
    "    }\n",
    "\n",
    "    # Generate text using the chain\n",
    "    generated_text = overall_chain(input_variables)\n",
    "    \n",
    "    print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5940ddc7-73c3-41f7-a3d4-0dbdaf8dc334",
   "metadata": {},
   "source": [
    "## Step 3: Create classification label based on evaluation\n",
    "Provide single label for the match level\n",
    "\n",
    "* We create a third chain for this task that uses the texts as well as the extracted topics and evaluation as input.\n",
    "* Labels: topic match, not topic match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fecbc38c-b157-441f-a6f6-b682ef673a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt_3 = \"\"\"\n",
    "<s>[INST] <<SYS>>\n",
    "You are a helpful, respectful and honest assistant for classifying whether two texts match on a main topic level based on an evaluation provided. \n",
    "\n",
    "At each request excplicitly assign one of the two labels below. \n",
    "0 - no match\n",
    "1 - topic match\n",
    "\n",
    "Make sure you to only return the label and nothing else.\n",
    "<</SYS>>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "28398820-cab0-4adb-b95d-be13c983f317",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_prompt_3 = \"\"\"\n",
    "\n",
    "The following evaluation describes the topic match level:\n",
    "Yes, the two texts match on a main topic level. Both texts touch upon the broader context of Politics. \n",
    "Based on this information, please assign either '0' for no match or '1' for topic match'. Return 0 for no match, and 1 for match. Make sure to only return the label and nothing more in the following format:\n",
    "\n",
    "[/INST]: 1 \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ea469ecd-17db-422d-ae07-f82c7b2cdf94",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_prompt_3 = \"\"\"\n",
    "[INST]\n",
    "\n",
    "The following evaluation describes the topic match level:\n",
    "{topic_evaluation}\n",
    "\n",
    "Based on this information, please assign either '0' for no match or '1' for topic match'. Return 0 for no match, and 1 for match. Make sure to only return the label and nothing more in the following format:\n",
    "\n",
    "[/INST] \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7b78d994-404d-43de-a5e2-12278ec47538",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_3 = system_prompt_3 + example_prompt_3 + main_prompt_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "83565f57-c842-4cb5-8be7-481b82c8cb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_3 = PromptTemplate(input_variables=[ \"topic_evaluation\"], template=prompt_3, batch_size=32, max_iterations = 1)\n",
    "chain_3 = LLMChain(llm = llm, prompt = prompt_template_3, output_key=\"match_topic\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334a661c-8dac-4a55-8cea-985a6172e43f",
   "metadata": {},
   "source": [
    "## Step 4: Identify news events\n",
    "* we ask the model the identify the news event described in each text\n",
    "* input data remains the same\n",
    "* this is in preparation of assessing news event level matching similar to topic level matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8ab4b2cc-a97a-4c4f-be0d-401b552e2126",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt_4 = \"\"\"\n",
    "<s>[INST] <<SYS>>\n",
    "You are a helpful, respectful and honest assistant for idenitifying the news event described in a pair of documents. \n",
    "News events are specific events that lead to news coverage, such as a specific debate on a specific day in a specific parliament, a specific accident, or a specific football match. They can be covered by one or more articles in one or more outlets, but relate to one specific and identifiable event and are thus much more fine-grained than news topics, issues, or news categories.\n",
    "News events can span over multiple days but not more than 10 days. Therefore articles that cover the same news event are published within the same few hours and in the course of a few days. \n",
    "\n",
    "Provide your answer as an explanation in maximum 100 tokens. Make sure you to only return the news evene tidentiief and nothing else.\n",
    "<</SYS>>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fd766de4-6396-49c6-aec1-0c9695528c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_prompt_4 = \"\"\"\n",
    "I have a document pair of the following texts:\n",
    "- Contact met de kiezer; Geen flyerende lijsttrekkers in windjacks op markten deze keer. Kandidaat-Kamerleden zoeken noodgedwongen hun contact met de kiezer online. Zoals ChristenUnie-lijsttrekker Gert-Jan Segers, hierboven afgebeeld terwijl hij vragen beantwoordt die kiezers hem op online platform Instagram stellen. Anders dan praten met de burgers zelf, praten de politici nu tegen camera's. Populair zijn ook livesessies op Facebook. Zo ging Mark Rutte dit weekend in gesprek met horeca-ondernemers en zond de VVD dat uit op Facebook. Naast de online campagne, werd er dit weekend ook ouderwets geflyerd. Maar aanbellen, dat deden de meeste campagnevoerende partijleden niet, uit angst voor verdere verspreiding van het coronavirus. Forum voor Democratie ging er als enige partij wel op uit om campagne te voeren. Met een vrijheidskaravaan deed de partij Nijmegen en Venlo aan voor een manifestatie. Toen er meer dan tweehonderd mensen langskwamen, moest burgemeester Hubert Bruls de bijeenkomst, die wel aangekondigd en aangevraagd was, voortijdig afbreken. Een bezoeker in Venlo twitterde dat met de komst van Baudet het centrale plein voor het eerst sinds carnaval vorig jaar weer vol stond.\n",
    "- Forum voor Democratie Jacht op extra stemmen; Waar andere partijen zich nauwelijks op straat wagen toert Forum voor Democratie stad en land af. Die optredens trekken niet alleen de aandacht van kiezers het Openbaar Ministerie kijkt inmiddels of Baudets campagneteam niet op grote schaal de coronaregels geschonden heeft. Zo werden bij een bezoek aan Urk volgens getuigen honderden handen geschud. En dan was er nog de volmacht-rel. In een live-uitzending riep Baudet donderdag zijn kijkers op zoveel mogelijk stemmen per volmacht te regelen. Om de besmettingskansen te verkleinen mogen kiezers dit jaar niet twee maar drie volmachtsstemmen uitbrengen. Een persoon kan vier keer stemmen eigenlijk, als je maar die volmachten kunt regelen, aldus Baudet, en dat was een enorme kans. Ho, zei het ministerie van Binnenlandse Zaken dat is niet de bedoeling en mag helemaal niet. Daar leek het campagneteam van Forum toen al achter gekomen de suggestie om stemmen te regelen was door de partij schielijk uit het filmpje van Baudet geknipt. Aan een ander standpunt houdt Baudet wel openlijk vast de grote kans op verkiezingsfraude. Door anderen, uiteraard.\n",
    "\n",
    "The following keywords appear in each text: 'livesessies', 'vrijheidskaravaan', 'flyerende', 'facebook', 'windjacks'; besmettingskansen', 'volmachtsstemmen', 'schielijk', 'volmachten', 'baudets'\n",
    "The following proper nouns appear in each text: Gert-Jan Segers, Mark Rutte, Forum voor Democratie, Hubert Bruls, Baudet; Forum voor Democratie, Forum voor Democratie, Ministerie kijkt, Urk, Baudet, Baudet, Baudet, Baudet\n",
    "\n",
    "The topic of each text is the following:\n",
    "Main topic 1: Politics; Subtopic: Elections and campaigns; \\n\n",
    "Main topic 2: Politics; Subtopic: Elections, campaigns and fraud \\n\n",
    "\n",
    "Based on the information above, please identify the news events that describe each document. Make sure to only return the news events and nothing more in the following format:\n",
    "\n",
    "[/INST] Event 1: Most political parties are shifting their campaign activity stategies due to the COVID-19 pandemic; Event 2: Forum voor Democratie party's campaign activities violate COVID-19 regulations while other parties have more pandemic-proof startegies. \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "728dc550-3900-44bd-8060-4f2596dfb925",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_prompt_4 = \"\"\"\n",
    "\n",
    "I have a document pair of the following texts:\n",
    "{text1} and {text2}\n",
    "\n",
    "The following keywords appear in each text: {keywords1} and {keywords2}\n",
    "The following proper nouns appear in each text: {proper_nouns1}, {proper_nouns2}\n",
    "\n",
    "The topic of each text is the following:\n",
    "{topics}\n",
    "\n",
    "Based on the information above, please identify the news events that describe each document. Make sure to only return the news events and nothing more in the following format:\n",
    "[/INST] \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2c2242af-37bc-4482-8748-f315ed60910b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_4 = system_prompt_4 + example_prompt_4 + main_prompt_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "96a71cb9-c328-48bb-b2d0-76fc214cab26",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_4 = PromptTemplate(input_variables=[\"text1\", \"text2\", \"proper_nouns1\", \"proper_nouns2\", 'keywords1', 'keywords2', \"topics\" ], template=prompt_4, batch_size=32, max_iterations = 1)\n",
    "chain_4 = LLMChain(llm = llm, prompt = prompt_template_4, output_key=\"news_events\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570ed895-7395-45da-86ee-57d2937d2a67",
   "metadata": {},
   "source": [
    "## Step 5: Evaluate news event level match\n",
    "\n",
    "* we ask the model to compare the news events identified on whether they match \n",
    "* input data remains the same plus the dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "285193cb-5e60-497a-8e52-04a74365da07",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt_5 = \"\"\"\n",
    "<s>[INST] <<SYS>>\n",
    "You are a helpful, respectful and honest assistant for evaluating whether two texts pertain to the same news event.\n",
    "News events are comprised of specific events that lead to news coverage around a news story, such as a specific debate on a specific day in a specific parliament, a specific accident, or a specific football match. \\n\n",
    "They can be covered by one or more articles in one or more outlets, but relate to one specific and identifiable event and are thus much more fine-grained than news topics, issues, or news categories.\\n\n",
    "News events can span over multiple days but not more than 10 days. Therefore articles that cover the same news event are published very close in time, a matter of hours or maximum a few days. \n",
    "Different news events can also be published on the same date or on a very close date. \\n\n",
    "The most important criteria for determining whether the two texts pertain to the same news event are the events mentioned in the text. The date overlap is a secondary objective. \\n\n",
    "\n",
    "An event within a news event must refer to a specific event or related developments around the event. A news event can include various articles, reports, and updates from news outlets, all contributing to the coverage of that specific event or issue and its sorrounding aspects. \\n\n",
    "For example, the news event might revolve around the presidential election of a specific year, detailing campaign events, candidate profiles, polling data, and key issues.\n",
    "Provide your answer as an explanation in maximum 100 tokens. Make sure to only return the evaluation and nothing else.\n",
    "<</SYS>>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2e7ade21-4985-470e-aa5d-d4e846854185",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_prompt_5 = \"\"\"\n",
    "\n",
    "The news events of each text is the following:\n",
    "Event 1: Most political parties are shifting their campaign activity stategies due to the COVID-19 pandemic.\\n\n",
    "Event 2: Forum voor Democratie party's campaign activities violate COVID-19 regulations while other parties have more pandemic-proof startegies. \\n\n",
    "\n",
    "\n",
    "The pubishing dates of the texts is the following:\\n\n",
    "date1: 01/03/2021; date2: 01/03/2021  \\n\n",
    "\n",
    "Based on the information above, please write a short evaluation about whether the two texts match on a news event level. Make sure to only return the evaluation and nothing more in the following format:\\n\n",
    "\n",
    "[/INST] Event Evaluation: Both texts focus on one particular news event, the election campaign and party campaign activities amid the COVID-19 pandemic which is distintive event. Both texts discuss aspects of the same election campaign, political parties and campaign strategies during the pandemic indicating that they pertain to the same news event.\n",
    "The texts were also published at a similar time and date which further indicates that they belong to the same news event. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "53c114e2-b556-4280-aecf-b755377b6532",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_prompt_5 = \"\"\"\n",
    "\n",
    "The news events of each text is the following:\n",
    "{news_events}\n",
    "\n",
    "The pubishing dates of the texts is the following:\n",
    "{date1} and {date2}\n",
    "\n",
    "Based on the information above, please write a short evaluation about whether the two texts match on a news event level. Make sure to only return the evaluation and nothing more in the following format:\n",
    "Event Evaluation:\n",
    "[/INST] \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "91199987-0633-49a5-8335-34d85c093628",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_5 = system_prompt_5 + example_prompt_5 + main_prompt_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5e77640b-d2e2-408c-81e7-1bae8c728739",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_5 = PromptTemplate(input_variables=[\"news_events\", \"date1\", \"date2\"], template=prompt_5, batch_size=32, max_iterations = 1)\n",
    "chain_5 = LLMChain(llm = llm, prompt = prompt_template_5, output_key=\"event_evaluation\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931192bc-c7f1-43f6-baa8-bd2bafb2f02d",
   "metadata": {},
   "source": [
    "## Step 6: Create classification label based on evaluation \n",
    "\n",
    "Similar to what we do for the topic level match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "600eeab7-5f7b-494c-bd2a-438bb0df15c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt_6 = \"\"\"\n",
    "<s>[INST] <<SYS>>\n",
    "You are a helpful, respectful and honest assistant for classifying whether two texts match on a news events level based on an evaluation provided. \n",
    "\n",
    "At each request excplicitly assign one of the two labels below. \n",
    "0 - no match\n",
    "1 - event match\n",
    "\n",
    "Make sure you to only return the label and nothing else.\n",
    "<</SYS>>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "89be94e9-e550-4b54-9783-e82eea138036",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_prompt_6 = \"\"\"\n",
    "\n",
    "The following evaluation describes the news event match level:\n",
    "\n",
    "Both texts focus on one particular news event, the election campaign which is distintive event. Both texts discuss aspects of the same election campaign.\\n\n",
    "The texts were also published at a similar time date which further indicates that they belong to the same news event. \n",
    "\n",
    "Based on this information, please assign either '0' for no match or '1' for news event match. Return 0 for no match, and 1 for match. Make sure to only return the label and nothing more in the following format:\n",
    "\n",
    "[/INST]: 1 \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d45b2dea-6344-4ba1-8ff5-0e485678a308",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_prompt_6 = \"\"\"\n",
    "[INST]\n",
    "\n",
    "The following evaluation describes the news event match level:\n",
    "{event_evaluation}\n",
    "\n",
    "Based on this information, please assign either '0' for no match or '1' for news event match'. Return 0 for no match, and 1 for match. Make sure to only return the label and nothing more in the following format:\n",
    "[/INST] \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c9d982ff-46a9-42ad-8cbf-b619ca15a18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_6 = system_prompt_6 + example_prompt_6 + main_prompt_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b24171f8-b076-4f81-ab47-f23e31eb0839",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_6 = PromptTemplate(input_variables=[\"event_evaluation\"], template=prompt_6, batch_size=32, max_iterations = 1)\n",
    "chain_6 = LLMChain(llm = llm, prompt = prompt_template_6, output_key=\"match_event\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d46bba-ffa5-4d1b-9365-4615cb191e19",
   "metadata": {},
   "source": [
    "## Run the overall chain and save the results into the final df \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dbc0f1f3-27ec-4727-8aab-15ac66acae34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to navigate up 'n' levels\n",
    "def navigate_up(current_directory, levels):\n",
    "    for _ in range(levels):\n",
    "        current_directory = os.path.dirname(current_directory)\n",
    "    return current_directory\n",
    "\n",
    "# Get the current working directory\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# Specify the number of levels to navigate up (4 levels in this case)\n",
    "levels_to_navigate = 4\n",
    "\n",
    "# Navigate up 'levels_to_navigate' folders\n",
    "parent_directory = navigate_up(current_directory, levels_to_navigate)\n",
    "\n",
    "# Define the path to the data file\n",
    "file_path = os.path.join(parent_directory, 'newspaper_data', 'final_2.csv')\n",
    "\n",
    "# Now you can open and read the CSV file using pandas\n",
    "\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2ad22783-a721-47f9-92bb-d6008f68649a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Similarity_Score</th>\n",
       "      <th>Text1</th>\n",
       "      <th>Text2</th>\n",
       "      <th>Group</th>\n",
       "      <th>Date1</th>\n",
       "      <th>Date2</th>\n",
       "      <th>Publisher1</th>\n",
       "      <th>Publisher2</th>\n",
       "      <th>ID1</th>\n",
       "      <th>ID2</th>\n",
       "      <th>proper_nouns1</th>\n",
       "      <th>proper_nouns2</th>\n",
       "      <th>keywords1</th>\n",
       "      <th>keywords2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.646155</td>\n",
       "      <td>Geweld bij antilockdowndemo in Dublin; Bij een...</td>\n",
       "      <td>Esther Ouwehand had niets met de plek waar ze ...</td>\n",
       "      <td>medium</td>\n",
       "      <td>2021-02-27 20:30:26</td>\n",
       "      <td>2021-03-01 00:00:00</td>\n",
       "      <td>NOS liveblog</td>\n",
       "      <td>Algemeen Dagblad</td>\n",
       "      <td>3287531</td>\n",
       "      <td>3286186</td>\n",
       "      <td>Geweld, Dublin, Leo Varadkar</td>\n",
       "      <td>Esther Ouwehand, Vinex, Esther Ouwehand, Uranu...</td>\n",
       "      <td>['ongeregeldheden', 'antilockdowndemo', 'wapen...</td>\n",
       "      <td>['hoornespolder', 'neptunus', 'rijtjeswoningen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.760930</td>\n",
       "      <td>Stelling 5: gevaccineerde burgers moeten als e...</td>\n",
       "      <td>Sportscholen demonstratief open: 'Bewegen is n...</td>\n",
       "      <td>high</td>\n",
       "      <td>2021-02-28 23:18:22</td>\n",
       "      <td>2021-03-01 00:00:00</td>\n",
       "      <td>NOS liveblog</td>\n",
       "      <td>Trouw</td>\n",
       "      <td>3287467</td>\n",
       "      <td>3285332</td>\n",
       "      <td>Wilders, Marijnissen, Marijnissen, Klaver van ...</td>\n",
       "      <td>Tino Hoogendijk Sport, J</td>\n",
       "      <td>['sneltesten', 'gevaccineerden', 'gevaccineerd...</td>\n",
       "      <td>['instructeur', 'hometrainers', 'housebeat', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.820325</td>\n",
       "      <td>Vraag van de eigenaresse van een couscousbar a...</td>\n",
       "      <td>De uitzending van 1 maart: Gasvrij duurder dan...</td>\n",
       "      <td>high</td>\n",
       "      <td>2021-02-28 22:43:49</td>\n",
       "      <td>2021-03-01 12:06:47</td>\n",
       "      <td>NOS liveblog</td>\n",
       "      <td>Nieuwsuur</td>\n",
       "      <td>3287471</td>\n",
       "      <td>6290579</td>\n",
       "      <td>Wilders, Nadia, Wilders, Wilders bestrijdt, Na...</td>\n",
       "      <td>Friese Garijp, Noord-Holland Noord, Jan Nieuwe...</td>\n",
       "      <td>['onwenselijk', 'couscousbar', 'couscous', 'ne...</td>\n",
       "      <td>['nieuwenburg', 'gasvrij', 'besmettingen', 'aa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.774437</td>\n",
       "      <td>Stelling 4: de rekening van de coronacrisis mo...</td>\n",
       "      <td>Helft potentiële Forumstemmers vermoedt wereld...</td>\n",
       "      <td>high</td>\n",
       "      <td>2021-02-28 22:48:57</td>\n",
       "      <td>2021-03-01 00:00:00</td>\n",
       "      <td>NOS liveblog</td>\n",
       "      <td>De Volkskrant</td>\n",
       "      <td>3287470</td>\n",
       "      <td>3285229</td>\n",
       "      <td>Marijnissen, CDA, VVD</td>\n",
       "      <td>Forum voor Democratie, Ipsos, Baudet, Urk</td>\n",
       "      <td>['inkomensongelijkheid', 'marijnissen', 'belas...</td>\n",
       "      <td>['ipsos', 'forumstemmers', 'kiesgerechtigden',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.731456</td>\n",
       "      <td>Stelling 2:  minimaal 10 procent van de bewind...</td>\n",
       "      <td>CPB-doorrekening: risico op maken van uitglije...</td>\n",
       "      <td>high</td>\n",
       "      <td>2021-02-28 22:03:24</td>\n",
       "      <td>2021-03-01 00:00:00</td>\n",
       "      <td>NOS liveblog</td>\n",
       "      <td>Het Financieele Dagblad</td>\n",
       "      <td>3287477</td>\n",
       "      <td>3290566</td>\n",
       "      <td>GroenLinks, SP, D66, Wilders, Zwarte Piet, Fri...</td>\n",
       "      <td>Is de invloed, CPB, Jean Dohmen, Centraal Plan...</td>\n",
       "      <td>['ronald', 'hilariteit', 'zit', 'westerse', 'm...</td>\n",
       "      <td>['doorrekeningen', 'uitglijer', 'berekeningen'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>0.774394</td>\n",
       "      <td>Gods politiek; Stevo Akkerman Zonder enige waa...</td>\n",
       "      <td>Milieuclubs niet echt blij met doorrekeningen;...</td>\n",
       "      <td>high</td>\n",
       "      <td>2021-03-01 00:00:00</td>\n",
       "      <td>2021-03-01 12:57:21</td>\n",
       "      <td>Trouw</td>\n",
       "      <td>NOS liveblog</td>\n",
       "      <td>3285316</td>\n",
       "      <td>6290507</td>\n",
       "      <td>Stevo Akkerman Zonder, ChristenUnie, GPV, Albe...</td>\n",
       "      <td>Milieuclubs, Kamers, CDA, GroenLinks, D66, Pvd...</td>\n",
       "      <td>['verkiezingsaffiche', 'albertus', 'heilloze',...</td>\n",
       "      <td>['greenpeace', 'nagestreefde', 'doorrekeningen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>0.844178</td>\n",
       "      <td>Loonkloof is nog altijd niet gedicht; Stond he...</td>\n",
       "      <td>De doorrekening van de verkiezingsprogramma's,...</td>\n",
       "      <td>high</td>\n",
       "      <td>2021-03-01 00:00:00</td>\n",
       "      <td>2021-03-01 07:12:10</td>\n",
       "      <td>Algemeen Dagblad</td>\n",
       "      <td>NOS nieuws</td>\n",
       "      <td>3286188</td>\n",
       "      <td>6290567</td>\n",
       "      <td>Loonkloof, VVD, CDA, D66, GroenLinks, euro, SP</td>\n",
       "      <td>Planbureau</td>\n",
       "      <td>['loonkloof', 'eindsalaris', 'salarissen', 'st...</td>\n",
       "      <td>['klimaatdoelen', 'doorrekeningen', 'verkiezin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>0.682143</td>\n",
       "      <td>Laatste coronanieuws: 4729 nieuwe besmettingen...</td>\n",
       "      <td>Manifestatie FvD afgebroken, aanhangers bekeur...</td>\n",
       "      <td>medium</td>\n",
       "      <td>2021-02-28 00:00:00</td>\n",
       "      <td>2021-02-28 13:43:06</td>\n",
       "      <td>Het Financieele Dagblad</td>\n",
       "      <td>NOS liveblog</td>\n",
       "      <td>3290679</td>\n",
       "      <td>3287500</td>\n",
       "      <td>RIVM, RIVM, Pati, RIVM, RIVM, RIVM mede bepaald</td>\n",
       "      <td>Forum voor Democratie, Thierry Baudet</td>\n",
       "      <td>['meldt', '4605', 'coronabesmettingen', 'besme...</td>\n",
       "      <td>['meldt', 'tegendemonstranten', 'opruiing', 'b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>0.845664</td>\n",
       "      <td>Een boer versus D66-leider Kaag over de halver...</td>\n",
       "      <td>Scholen vragen zich af: waar blijven de snelte...</td>\n",
       "      <td>high</td>\n",
       "      <td>2021-02-28 21:41:40</td>\n",
       "      <td>2021-03-01 00:00:00</td>\n",
       "      <td>NOS liveblog</td>\n",
       "      <td>Trouw</td>\n",
       "      <td>3287479</td>\n",
       "      <td>3285335</td>\n",
       "      <td>D66</td>\n",
       "      <td>CNV, Kleuters, CNV, AOb, Algemene Vereniging S...</td>\n",
       "      <td>['stikstofreductie', 'veestapel', 'langsgaan',...</td>\n",
       "      <td>['sneltesten', 'sneltests', 'amsterdamse', 'sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>0.774585</td>\n",
       "      <td>Start met corona; Lien van der Leij Moet de re...</td>\n",
       "      <td>Meeste partijen maken vliegen paar honderd mil...</td>\n",
       "      <td>high</td>\n",
       "      <td>2021-03-01 00:00:00</td>\n",
       "      <td>2021-03-01 00:00:00</td>\n",
       "      <td>Het Financieele Dagblad</td>\n",
       "      <td>Het Financieele Dagblad</td>\n",
       "      <td>3290656</td>\n",
       "      <td>3290589</td>\n",
       "      <td>Lien van der Leij, Sigrid Kaag, Wopke Hoekstra...</td>\n",
       "      <td>miljoen euro duurder, Centraal Planbureau CPB,...</td>\n",
       "      <td>['melkveehouder', 'coronarestricties', 'toesla...</td>\n",
       "      <td>['lastenverzwaring', 'autobelastingen', 'kilom...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>495 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Similarity_Score                                              Text1  \\\n",
       "0            0.646155  Geweld bij antilockdowndemo in Dublin; Bij een...   \n",
       "1            0.760930  Stelling 5: gevaccineerde burgers moeten als e...   \n",
       "2            0.820325  Vraag van de eigenaresse van een couscousbar a...   \n",
       "3            0.774437  Stelling 4: de rekening van de coronacrisis mo...   \n",
       "4            0.731456  Stelling 2:  minimaal 10 procent van de bewind...   \n",
       "..                ...                                                ...   \n",
       "490          0.774394  Gods politiek; Stevo Akkerman Zonder enige waa...   \n",
       "491          0.844178  Loonkloof is nog altijd niet gedicht; Stond he...   \n",
       "492          0.682143  Laatste coronanieuws: 4729 nieuwe besmettingen...   \n",
       "493          0.845664  Een boer versus D66-leider Kaag over de halver...   \n",
       "494          0.774585  Start met corona; Lien van der Leij Moet de re...   \n",
       "\n",
       "                                                 Text2   Group  \\\n",
       "0    Esther Ouwehand had niets met de plek waar ze ...  medium   \n",
       "1    Sportscholen demonstratief open: 'Bewegen is n...    high   \n",
       "2    De uitzending van 1 maart: Gasvrij duurder dan...    high   \n",
       "3    Helft potentiële Forumstemmers vermoedt wereld...    high   \n",
       "4    CPB-doorrekening: risico op maken van uitglije...    high   \n",
       "..                                                 ...     ...   \n",
       "490  Milieuclubs niet echt blij met doorrekeningen;...    high   \n",
       "491  De doorrekening van de verkiezingsprogramma's,...    high   \n",
       "492  Manifestatie FvD afgebroken, aanhangers bekeur...  medium   \n",
       "493  Scholen vragen zich af: waar blijven de snelte...    high   \n",
       "494  Meeste partijen maken vliegen paar honderd mil...    high   \n",
       "\n",
       "                   Date1                Date2               Publisher1  \\\n",
       "0    2021-02-27 20:30:26  2021-03-01 00:00:00             NOS liveblog   \n",
       "1    2021-02-28 23:18:22  2021-03-01 00:00:00             NOS liveblog   \n",
       "2    2021-02-28 22:43:49  2021-03-01 12:06:47             NOS liveblog   \n",
       "3    2021-02-28 22:48:57  2021-03-01 00:00:00             NOS liveblog   \n",
       "4    2021-02-28 22:03:24  2021-03-01 00:00:00             NOS liveblog   \n",
       "..                   ...                  ...                      ...   \n",
       "490  2021-03-01 00:00:00  2021-03-01 12:57:21                    Trouw   \n",
       "491  2021-03-01 00:00:00  2021-03-01 07:12:10         Algemeen Dagblad   \n",
       "492  2021-02-28 00:00:00  2021-02-28 13:43:06  Het Financieele Dagblad   \n",
       "493  2021-02-28 21:41:40  2021-03-01 00:00:00             NOS liveblog   \n",
       "494  2021-03-01 00:00:00  2021-03-01 00:00:00  Het Financieele Dagblad   \n",
       "\n",
       "                  Publisher2      ID1      ID2  \\\n",
       "0           Algemeen Dagblad  3287531  3286186   \n",
       "1                      Trouw  3287467  3285332   \n",
       "2                  Nieuwsuur  3287471  6290579   \n",
       "3              De Volkskrant  3287470  3285229   \n",
       "4    Het Financieele Dagblad  3287477  3290566   \n",
       "..                       ...      ...      ...   \n",
       "490             NOS liveblog  3285316  6290507   \n",
       "491               NOS nieuws  3286188  6290567   \n",
       "492             NOS liveblog  3290679  3287500   \n",
       "493                    Trouw  3287479  3285335   \n",
       "494  Het Financieele Dagblad  3290656  3290589   \n",
       "\n",
       "                                         proper_nouns1  \\\n",
       "0                         Geweld, Dublin, Leo Varadkar   \n",
       "1    Wilders, Marijnissen, Marijnissen, Klaver van ...   \n",
       "2    Wilders, Nadia, Wilders, Wilders bestrijdt, Na...   \n",
       "3                                Marijnissen, CDA, VVD   \n",
       "4    GroenLinks, SP, D66, Wilders, Zwarte Piet, Fri...   \n",
       "..                                                 ...   \n",
       "490  Stevo Akkerman Zonder, ChristenUnie, GPV, Albe...   \n",
       "491     Loonkloof, VVD, CDA, D66, GroenLinks, euro, SP   \n",
       "492    RIVM, RIVM, Pati, RIVM, RIVM, RIVM mede bepaald   \n",
       "493                                                D66   \n",
       "494  Lien van der Leij, Sigrid Kaag, Wopke Hoekstra...   \n",
       "\n",
       "                                         proper_nouns2  \\\n",
       "0    Esther Ouwehand, Vinex, Esther Ouwehand, Uranu...   \n",
       "1                             Tino Hoogendijk Sport, J   \n",
       "2    Friese Garijp, Noord-Holland Noord, Jan Nieuwe...   \n",
       "3            Forum voor Democratie, Ipsos, Baudet, Urk   \n",
       "4    Is de invloed, CPB, Jean Dohmen, Centraal Plan...   \n",
       "..                                                 ...   \n",
       "490  Milieuclubs, Kamers, CDA, GroenLinks, D66, Pvd...   \n",
       "491                                         Planbureau   \n",
       "492              Forum voor Democratie, Thierry Baudet   \n",
       "493  CNV, Kleuters, CNV, AOb, Algemene Vereniging S...   \n",
       "494  miljoen euro duurder, Centraal Planbureau CPB,...   \n",
       "\n",
       "                                             keywords1  \\\n",
       "0    ['ongeregeldheden', 'antilockdowndemo', 'wapen...   \n",
       "1    ['sneltesten', 'gevaccineerden', 'gevaccineerd...   \n",
       "2    ['onwenselijk', 'couscousbar', 'couscous', 'ne...   \n",
       "3    ['inkomensongelijkheid', 'marijnissen', 'belas...   \n",
       "4    ['ronald', 'hilariteit', 'zit', 'westerse', 'm...   \n",
       "..                                                 ...   \n",
       "490  ['verkiezingsaffiche', 'albertus', 'heilloze',...   \n",
       "491  ['loonkloof', 'eindsalaris', 'salarissen', 'st...   \n",
       "492  ['meldt', '4605', 'coronabesmettingen', 'besme...   \n",
       "493  ['stikstofreductie', 'veestapel', 'langsgaan',...   \n",
       "494  ['melkveehouder', 'coronarestricties', 'toesla...   \n",
       "\n",
       "                                             keywords2  \n",
       "0    ['hoornespolder', 'neptunus', 'rijtjeswoningen...  \n",
       "1    ['instructeur', 'hometrainers', 'housebeat', '...  \n",
       "2    ['nieuwenburg', 'gasvrij', 'besmettingen', 'aa...  \n",
       "3    ['ipsos', 'forumstemmers', 'kiesgerechtigden',...  \n",
       "4    ['doorrekeningen', 'uitglijer', 'berekeningen'...  \n",
       "..                                                 ...  \n",
       "490  ['greenpeace', 'nagestreefde', 'doorrekeningen...  \n",
       "491  ['klimaatdoelen', 'doorrekeningen', 'verkiezin...  \n",
       "492  ['meldt', 'tegendemonstranten', 'opruiing', 'b...  \n",
       "493  ['sneltesten', 'sneltests', 'amsterdamse', 'sc...  \n",
       "494  ['lastenverzwaring', 'autobelastingen', 'kilom...  \n",
       "\n",
       "[495 rows x 14 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8461c9d0-f066-49d0-b425-33710ef419f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 0 in 15.56 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/volume_2/python_3.10/lib/python3.10/site-packages/transformers/pipelines/base.py:1083: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 1 in 13.28 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 2 in 18.72 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 3 in 17.16 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 4 in 17.09 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 5 in 15.01 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 6 in 17.56 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 7 in 17.41 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 8 in 16.04 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 9 in 15.49 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 10 in 13.92 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 11 in 16.31 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 12 in 15.86 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 13 in 16.95 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 14 in 22.93 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 15 in 20.41 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 16 in 16.24 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 17 in 18.48 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 18 in 18.95 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 19 in 16.38 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 20 in 14.90 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 21 in 15.94 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 22 in 18.94 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 23 in 14.85 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 24 in 14.46 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 25 in 15.93 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 26 in 19.10 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 27 in 17.70 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 28 in 15.45 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 29 in 21.37 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 30 in 17.15 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 31 in 13.29 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 32 in 15.24 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 33 in 13.32 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 34 in 17.52 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 35 in 20.31 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 36 in 17.08 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 37 in 16.35 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 38 in 17.67 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 39 in 19.56 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 40 in 19.09 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 41 in 16.91 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 42 in 17.59 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 43 in 19.68 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 44 in 16.58 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 45 in 14.41 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 46 in 18.44 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 47 in 18.69 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 48 in 19.61 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 49 in 14.43 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 50 in 22.07 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 51 in 19.12 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 52 in 15.79 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 53 in 20.71 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 54 in 39.05 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 55 in 16.27 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 56 in 15.21 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 57 in 23.74 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 58 in 15.90 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 59 in 16.56 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 60 in 16.27 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 61 in 19.77 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 62 in 15.84 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 63 in 17.72 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 64 in 22.15 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 65 in 16.10 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 66 in 22.20 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 67 in 18.86 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 68 in 13.92 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 69 in 17.57 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 70 in 17.32 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 71 in 19.53 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 72 in 15.41 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 73 in 17.32 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 74 in 35.89 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 75 in 16.81 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 76 in 13.69 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 77 in 13.53 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 78 in 19.18 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 79 in 19.86 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "# Create empty lists to collect the results\n",
    "pd.options.mode.chained_assignment = None  # Disable the warning (not recommended)\n",
    "\n",
    "topics = []\n",
    "topic_eval = []\n",
    "match_topic = []\n",
    "topic_words = []\n",
    "news_events = []\n",
    "event_eval = []\n",
    "match_event = []\n",
    "\n",
    "# Iterating over the DataFrame\n",
    "for index, row in df.iterrows():\n",
    "    full_text1 = str(row['Text1'])  \n",
    "    full_text2 = str(row['Text2'])  \n",
    "\n",
    "    input_variables = {\n",
    "        \"text1\": full_text1,\n",
    "        \"text2\": full_text2,\n",
    "        \"proper_nouns1\": row['proper_nouns1'],\n",
    "        \"proper_nouns2\": row['proper_nouns2'],\n",
    "        \"keywords1\": row['keywords1'],\n",
    "        \"keywords2\": row['keywords2'],\n",
    "        \"date1\": row['Date1'],\n",
    "        \"date2\": row['Date2']\n",
    "    }\n",
    "\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Process the input_variables and get the results\n",
    "    #create overall chain to combine previous chains into one big sequential chain\n",
    "    overall_chain = SequentialChain(\n",
    "                  chains=[chain_1, chain_1_1, chain_2, chain_2_1, chain_3, chain_4, chain_5, chain_6], input_variables = [\"text1\", \"text2\", \"proper_nouns1\", \"proper_nouns2\", 'keywords1', 'keywords2', 'date1', 'date2'],output_variables=[\"topics\", \"main_topic\", \"topic_evaluation\", \"topic_words\",\"match_topic\",\"news_events\",\"event_evaluation\", \"match_event\"],\n",
    "                  verbose=True )\n",
    "    \n",
    "    results = overall_chain(input_variables)\n",
    "    # Stop the timer\n",
    "    end_time = time.time()\n",
    "\n",
    "\n",
    "    # Append results to respective lists\n",
    "    topics.append(results['topics'].strip())\n",
    "    match_topic.append(results['match_topic'].strip())\n",
    "    topic_words.append(results['topic_words'].strip())\n",
    "    topic_eval.append(results['topic_evaluation'].strip())\n",
    "    news_events.append(results['news_events'].strip())\n",
    "    event_eval.append(results['event_evaluation'].strip())\n",
    "    match_event.append(results['match_event'].strip())\n",
    "\n",
    "    # Calculate and print the time taken for processing this row\n",
    "    row_processing_time = end_time - start_time\n",
    "    print(f\"Processed row {index} in {row_processing_time:.2f} seconds\")\n",
    "\n",
    "# Add new columns to the DataFrame\n",
    "df.loc[:,'Topic'] = topics\n",
    "df.loc[:,'Topic_eval'] = topic_eval\n",
    "df.loc[:,'Topic_match'] = match_topic\n",
    "df.loc[:,'Topic_words'] = topic_words\n",
    "df.loc[:,'News_events'] = news_events\n",
    "df.loc[:,'Event_eval'] = event_eval\n",
    "df.loc[:,'Event_match'] = match_event\n",
    "\n",
    "# Add a short pause before moving on to the next iteration\n",
    "#time.sleep(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea0cc9b-b47a-40ce-8b16-524d615a74f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the folder 4 levels up where you want to save the DataFrame\n",
    "save_folder_path = os.path.join(parent_directory, 'initial_out')\n",
    "\n",
    "# Create the folder if it doesn't exist\n",
    "os.makedirs(save_folder_path, exist_ok=True)\n",
    "\n",
    "# Define the full path to save the DataFrame\n",
    "save_file_path = os.path.join(save_folder_path, '7b_assisted.csv')\n",
    "# Save the DataFrame to the specified path\n",
    "df.to_csv(save_file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925a57ca-e7d0-4c34-b781-edd8b3d83562",
   "metadata": {},
   "source": [
    "df['Topic_words'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ef7f3c-2dc0-439d-bb65-66d939cb3221",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python 3.10",
   "language": "python",
   "name": "python_3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
