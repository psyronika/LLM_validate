{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dde61e5e-e9cc-4399-a8d5-048d00697c5a",
   "metadata": {},
   "source": [
    "# Llama 13b for validation task\n",
    "\n",
    "* input: dataframe with text pairs and additional info LLama 2 should use to make informed decision\n",
    "* output: dataframe with additional columns: topic, topic match evalutation, topic match classification, news event, news event match evaluation, news event match classification, final classification on topic-level and news event level matching\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c86ae2-8644-451b-855d-9a4625b6b94d",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "629e3acb-b512-4f07-bd44-ad67fa7d8e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from torch import cuda, bfloat16\n",
    "import transformers\n",
    "import pandas as pd\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chains import SequentialChain\n",
    "from transformers import pipeline\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96555da-98cc-426b-b3a6-517a3e6abe8f",
   "metadata": {},
   "source": [
    "## Load model through Huggingface pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cec9f8ed-1605-49f4-a9f1-0b4f356301ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/volume_2/python_3.10/lib/python3.10/site-packages/transformers/modeling_utils.py:2193: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5bfefd911834f20811c839af7d6c0bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded on cuda:0\n"
     ]
    }
   ],
   "source": [
    "hf_auth_file = '../../analysis/hf_auth.txt'\n",
    "\n",
    "# Read the API token from the file\n",
    "with open(hf_auth_file, \"r\") as file:\n",
    "    hf_auth = file.read().strip()  # Remove leading/trailing whitespaces\n",
    "\n",
    "\n",
    "model_id = 'meta-llama/Llama-2-13b-chat-hf'\n",
    "\n",
    "device = f'cuda:{cuda.current_device()}' if cuda.is_available() else 'cpu'\n",
    "\n",
    "# set quantization configuration to load large model with less GPU memory\n",
    "# this requires the `bitsandbytes` library\n",
    "bnb_config = transformers.BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type='nf4',\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=bfloat16\n",
    ")\n",
    "\n",
    "# begin initializing HF items, need auth token for these\n",
    "model_config = transformers.AutoConfig.from_pretrained(\n",
    "    model_id,\n",
    "    use_auth_token=hf_auth\n",
    ")\n",
    "\n",
    "model = transformers.AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    trust_remote_code=True,\n",
    "    config=model_config,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map='auto',\n",
    "    use_auth_token=hf_auth\n",
    ")\n",
    "model.eval()\n",
    "print(f\"Model loaded on {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "799a7a2f-9784-403d-9e23-71e6b2d1f7ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/volume_2/python_3.10/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1714: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
    "    model_id,\n",
    "    use_auth_token=hf_auth\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a4c1b09-5715-46e7-88eb-822b2b2fa4ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Name: NVIDIA A10\n",
      "Memory Usage: 3.559241771697998 GB\n",
      "Max Memory Usage: 3.604752540588379 GB\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda')\n",
    "print(\"GPU Name:\", torch.cuda.get_device_name(device))\n",
    "print(\"Memory Usage:\", torch.cuda.memory_allocated(device) / 1024 ** 3, \"GB\")\n",
    "print(\"Max Memory Usage:\", torch.cuda.max_memory_allocated(device) / 1024 ** 3, \"GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4c404a3-5ee9-429e-9b64-1e1b4d60f72f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function torch.clear_autocast_cache>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.clear_autocast_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b54484da-e4b1-457b-8c36-8d50e6ee2bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_text = transformers.pipeline(\n",
    "    model=model, tokenizer=tokenizer,\n",
    "    return_full_text=True,  # langchain expects the full text\n",
    "    task='text-generation',\n",
    "    # we pass model parameters here too\n",
    "    temperature=0.0,  # 'randomness' of outputs, 0.0 is the min and 1.0 the max we do not want any randomness here as we want the model to stick to the prompt as closely as possible\n",
    "    max_new_tokens=512,  # max number of tokens to generate in the output\n",
    "    repetition_penalty=1.1  # without this output begins repeating\n",
    ")\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=generate_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f474429-5dd0-4991-9975-352fa8b0d7bc",
   "metadata": {},
   "source": [
    "### Read in file\n",
    "\n",
    "This is a file for prompt engineering that we devide into smaller samples for tuning our prompts. There are 100 rows in this data and we split them up into 20, 5 row dfs for quick testing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "455618db-c310-4aa4-a33c-85f30770ef86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to navigate up 'n' levels\n",
    "def navigate_up(current_directory, levels):\n",
    "    for _ in range(levels):\n",
    "        current_directory = os.path.dirname(current_directory)\n",
    "    return current_directory\n",
    "\n",
    "# Get the current working directory\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# Specify the number of levels to navigate up (4 levels in this case)\n",
    "levels_to_navigate = 4\n",
    "\n",
    "# Navigate up 'levels_to_navigate' folders\n",
    "parent_directory = navigate_up(current_directory, levels_to_navigate)\n",
    "\n",
    "# Define the path to the data file\n",
    "file_path = os.path.join(parent_directory, 'newspaper_data', 'sample_1percent.csv')\n",
    "\n",
    "# Now you can open and read the CSV file using pandas\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8a58d5f-caf5-44c4-aff5-bd7fbd6e4f7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Similarity_Score</th>\n",
       "      <th>Text1</th>\n",
       "      <th>Text2</th>\n",
       "      <th>Group</th>\n",
       "      <th>Date1</th>\n",
       "      <th>Date2</th>\n",
       "      <th>Publisher1</th>\n",
       "      <th>Publisher2</th>\n",
       "      <th>ID1</th>\n",
       "      <th>ID2</th>\n",
       "      <th>proper_nouns1</th>\n",
       "      <th>proper_nouns2</th>\n",
       "      <th>keywords1</th>\n",
       "      <th>keywords2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.765668</td>\n",
       "      <td>Alle pijlen zijn gericht op Rutte in RTL-debat...</td>\n",
       "      <td>Helft van de Forum-stemmers ziet complot; De h...</td>\n",
       "      <td>high</td>\n",
       "      <td>2021-03-01 00:00:00</td>\n",
       "      <td>2021-03-01 00:00:00</td>\n",
       "      <td>De Volkskrant</td>\n",
       "      <td>Trouw</td>\n",
       "      <td>3285226</td>\n",
       "      <td>3285337</td>\n",
       "      <td>Radio 1, RTL, VVD, kernboodschap gelieve, Sigr...</td>\n",
       "      <td>Forum voor Democratie, Ipsos</td>\n",
       "      <td>['lijsttrekkersdebat', 'premiersdebat', 'paree...</td>\n",
       "      <td>['ipsos', 'coronavirus', 'gefabriceerd', 'comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.683993</td>\n",
       "      <td>Hoogste bestuursrechter liet forse steken vall...</td>\n",
       "      <td>Stelling 3: Om de klimaatdoelen te halen moet ...</td>\n",
       "      <td>medium</td>\n",
       "      <td>2021-02-28 00:00:00</td>\n",
       "      <td>2021-02-28 22:22:56</td>\n",
       "      <td>Het Financieele Dagblad</td>\n",
       "      <td>NOS liveblog</td>\n",
       "      <td>3290695</td>\n",
       "      <td>3287474</td>\n",
       "      <td>Andr Bosman, VVD, Tweede Kamer, Raad van State...</td>\n",
       "      <td>VVD, Poetin</td>\n",
       "      <td>['overheidsinstantie', 'kinderopvangtoeslagen'...</td>\n",
       "      <td>['klimaatdoelen', 'kerncentrales', 'rusland', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.848039</td>\n",
       "      <td>Planbureau: vertrek bedrijven reëel risico bij...</td>\n",
       "      <td>Baudet: corona niet bewust wereld in geslinger...</td>\n",
       "      <td>high</td>\n",
       "      <td>2021-03-01 00:00:00</td>\n",
       "      <td>2021-03-01 10:34:06</td>\n",
       "      <td>Het Financieele Dagblad</td>\n",
       "      <td>NOS nieuws</td>\n",
       "      <td>3290604</td>\n",
       "      <td>6290556</td>\n",
       "      <td>Planbureau, Planbureau voor de Leefomgeving, P...</td>\n",
       "      <td>Baudet, Forum voor Democratie-voorman Thierry ...</td>\n",
       "      <td>['broeikasgasuitstoot', 'klimaatwinst', 'leefo...</td>\n",
       "      <td>['virussen', 'chinees', 'ebolavirus', 'ingesto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.805225</td>\n",
       "      <td>Recht op reparatie van apparatuur komt steeds ...</td>\n",
       "      <td>Niet een lijsttrekker, maar een kiezer brengt ...</td>\n",
       "      <td>high</td>\n",
       "      <td>2021-03-01 00:00:00</td>\n",
       "      <td>2021-03-01 00:00:00</td>\n",
       "      <td>Het Financieele Dagblad</td>\n",
       "      <td>NRC Handelsblad</td>\n",
       "      <td>3290567</td>\n",
       "      <td>3285627</td>\n",
       "      <td>REPAIR, CAF S Jeroen Groot, Philips, Leenman, ...</td>\n",
       "      <td>Mark Rutte, RTL, Mark Rutte, Mark Rutte, Geert...</td>\n",
       "      <td>['verwarmingselement', 'reparateurs', 'koffiez...</td>\n",
       "      <td>['lijsttrekkersdebat', 'toeslagenaffaire', 'on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.631177</td>\n",
       "      <td>Dode en gewonde door zuurstofexplosie corona-a...</td>\n",
       "      <td>Wilders in de schijnwerpers; Wilders in de sch...</td>\n",
       "      <td>medium</td>\n",
       "      <td>2021-02-27 22:39:37</td>\n",
       "      <td>2021-03-01 00:00:00</td>\n",
       "      <td>NOS liveblog</td>\n",
       "      <td>De Telegraaf</td>\n",
       "      <td>3287529</td>\n",
       "      <td>3286364</td>\n",
       "      <td>Oekra, Twintig, Oekra</td>\n",
       "      <td>Wilders, Mark Rutte, Sigrid Kaag D66, Wilders,...</td>\n",
       "      <td>['tsjernivtsi', 'zaporizja', 'zuurstofexplosie...</td>\n",
       "      <td>['diversiteitsquota', 'ronald', 'rtl', 'zit', ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Similarity_Score                                              Text1  \\\n",
       "5          0.765668  Alle pijlen zijn gericht op Rutte in RTL-debat...   \n",
       "6          0.683993  Hoogste bestuursrechter liet forse steken vall...   \n",
       "7          0.848039  Planbureau: vertrek bedrijven reëel risico bij...   \n",
       "8          0.805225  Recht op reparatie van apparatuur komt steeds ...   \n",
       "9          0.631177  Dode en gewonde door zuurstofexplosie corona-a...   \n",
       "\n",
       "                                               Text2   Group  \\\n",
       "5  Helft van de Forum-stemmers ziet complot; De h...    high   \n",
       "6  Stelling 3: Om de klimaatdoelen te halen moet ...  medium   \n",
       "7  Baudet: corona niet bewust wereld in geslinger...    high   \n",
       "8  Niet een lijsttrekker, maar een kiezer brengt ...    high   \n",
       "9  Wilders in de schijnwerpers; Wilders in de sch...  medium   \n",
       "\n",
       "                 Date1                Date2               Publisher1  \\\n",
       "5  2021-03-01 00:00:00  2021-03-01 00:00:00            De Volkskrant   \n",
       "6  2021-02-28 00:00:00  2021-02-28 22:22:56  Het Financieele Dagblad   \n",
       "7  2021-03-01 00:00:00  2021-03-01 10:34:06  Het Financieele Dagblad   \n",
       "8  2021-03-01 00:00:00  2021-03-01 00:00:00  Het Financieele Dagblad   \n",
       "9  2021-02-27 22:39:37  2021-03-01 00:00:00             NOS liveblog   \n",
       "\n",
       "        Publisher2      ID1      ID2  \\\n",
       "5            Trouw  3285226  3285337   \n",
       "6     NOS liveblog  3290695  3287474   \n",
       "7       NOS nieuws  3290604  6290556   \n",
       "8  NRC Handelsblad  3290567  3285627   \n",
       "9     De Telegraaf  3287529  3286364   \n",
       "\n",
       "                                       proper_nouns1  \\\n",
       "5  Radio 1, RTL, VVD, kernboodschap gelieve, Sigr...   \n",
       "6  Andr Bosman, VVD, Tweede Kamer, Raad van State...   \n",
       "7  Planbureau, Planbureau voor de Leefomgeving, P...   \n",
       "8  REPAIR, CAF S Jeroen Groot, Philips, Leenman, ...   \n",
       "9                              Oekra, Twintig, Oekra   \n",
       "\n",
       "                                       proper_nouns2  \\\n",
       "5                       Forum voor Democratie, Ipsos   \n",
       "6                                        VVD, Poetin   \n",
       "7  Baudet, Forum voor Democratie-voorman Thierry ...   \n",
       "8  Mark Rutte, RTL, Mark Rutte, Mark Rutte, Geert...   \n",
       "9  Wilders, Mark Rutte, Sigrid Kaag D66, Wilders,...   \n",
       "\n",
       "                                           keywords1  \\\n",
       "5  ['lijsttrekkersdebat', 'premiersdebat', 'paree...   \n",
       "6  ['overheidsinstantie', 'kinderopvangtoeslagen'...   \n",
       "7  ['broeikasgasuitstoot', 'klimaatwinst', 'leefo...   \n",
       "8  ['verwarmingselement', 'reparateurs', 'koffiez...   \n",
       "9  ['tsjernivtsi', 'zaporizja', 'zuurstofexplosie...   \n",
       "\n",
       "                                           keywords2  \n",
       "5  ['ipsos', 'coronavirus', 'gefabriceerd', 'comp...  \n",
       "6  ['klimaatdoelen', 'kerncentrales', 'rusland', ...  \n",
       "7  ['virussen', 'chinees', 'ebolavirus', 'ingesto...  \n",
       "8  ['lijsttrekkersdebat', 'toeslagenaffaire', 'on...  \n",
       "9  ['diversiteitsquota', 'ronald', 'rtl', 'zit', ...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the DataFrame into 20 smaller DataFrames for the sake of fast tuning of prompting, each containing 5 rows\n",
    "chunk_size = 5\n",
    "chunks = [df.iloc[i:i+chunk_size] for i in range(0, len(df), chunk_size)]\n",
    "\n",
    "# Create variables for each smaller DataFrame\n",
    "for i, chunk in enumerate(chunks):\n",
    "    globals()[f'df{i + 1}'] = chunk\n",
    "\n",
    "# Now you have variables df1, df2, df3, ... containing the smaller DataFrames\n",
    "# You can access and work with them as needed\n",
    "df2\n",
    "#df2\n",
    "#....\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7223f53a-b58e-4f8b-8288-b7afc0989552",
   "metadata": {},
   "source": [
    "#  Prompting \n",
    "\n",
    "Prompting takes shapes in many sequetial instructions. We divide the prompts themselves into system prompt, example prompt, and main prompt to geenrate a template for each subtask. We begin with the broadest level, topic-level matching task. This task is also divided into three sepearate subtasks: (1) create topic labels for eacg text, (2) compare the topic labels and texts to decide to what extent they match, and (3) based on the explanation create a single classification topic match or no topic match. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0916b9e-02e6-4ed8-9994-f1067cf8f0b2",
   "metadata": {},
   "source": [
    "## Step 1: Extract topics. \n",
    "The prompt template is based on Grootendorst, BERTopic LLama2 implementation with example from our full dataset.\n",
    "* Important to note that for each step we pass in a system prompt, give and example, and provide a main prompt that signifies the variables and content to be considered.\n",
    "* Then we create a chain from the prompt for further sequential chaining with LangChain\n",
    "* Very important here to intially extract main topic and subtopic in order to obtain clear topics. If subtopics are not requested then the model might not understand that a topic that mentions politicians and conspiracy theories belongs to the broader topic of politics and instead it may label it as conspiracy theories alone. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea5a1bf4-2c8c-4052-ba85-e37802f96cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of file names\n",
    "file_names = ['system_1.txt', 'main_1.txt', 'example_1.txt']\n",
    "\n",
    "# Initialize a dictionary to store the prompts\n",
    "prompts = {}\n",
    "\n",
    "# Read and store the prompts from the files\n",
    "for file_name in file_names:\n",
    "    with open(f'prompts/{file_name}', \"r\") as file:\n",
    "        prompt = file.read().strip()  # Remove leading/trailing whitespaces\n",
    "        prompts[file_name] = prompt\n",
    "\n",
    "# Combine the prompts\n",
    "prompt_1 = prompts['system_1.txt'] + prompts['example_1.txt'] + prompts['main_1.txt']\n",
    "\n",
    "# Create a PromptTemplate instance\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"text1\", \"text2\", 'proper_nouns1', 'proper_nouns2', 'keywords1', 'keywords2'],\n",
    "    template=prompt_1\n",
    ")\n",
    "\n",
    "# Create the LLMChain instance\n",
    "chain_1 = LLMChain(llm=llm, prompt=prompt_template, output_key=\"topics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "e22ef277-6196-42ed-9f66-562bc5451c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the system prompt. It describes information given to all conversations\n",
    "# This system prompt will be\n",
    "system_prompt_1 = \"\"\"\n",
    "<s>[INST] <<SYS>>\n",
    "You are a helpful, respectful and honest assistant for labeling topics. A \"topic\" is a fundamental subject or theme that encompasses all aspects related to a particular area of interest or discussion. \n",
    "A topic serves as the overarching framework for exploring and discussing various facets within that subject. A topic comprises of a main topic and a subtopic. A main topic is an overarching theme, a subtopic is a more specific thematic or content-based divisions within a broader main topic. All main topics are labeled Politics if the documents' keywords and proper nouns relate to politics. For instance if the text discusses the economy but a politician, party, or government is mentioned either in the text or in the keywords then it should be categorized as Politics and not Economy. \\n\n",
    "Main topic: Politics; Subtopic: Elections and campaigns\n",
    "Main topic: Economy; Subtopic: Interest rates\n",
    "Main topic: Health; Subtopic: Mental health\n",
    "Main topic: Entertainment; Subtopic: Film and Television \\n\n",
    "\n",
    "If a text mentions politics, politicians names functions, partirs, policy, or any other politics-related term, the main topic should always be Politics.\\n\n",
    "\n",
    "\n",
    "You must always return a main topic and a subtopic and nothing else in the following format: Main topic1 : Subtopic1:;, Main topic2: Subtopic2: \\n\n",
    "Do not return any notes. Only return the label and nothing more for each text.\n",
    "\n",
    "<</SYS>>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "7dfff572-4e5d-456c-a487-f3a5709fd042",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_prompt_1 = \"\"\"\n",
    "I have a document pair of the following texts:\\n\n",
    "- Contact met de kiezer; Deze keer zie je geen lijsttrekkers in windjacks rondlopen op markten. Kandidaat-Kamerleden moeten noodgedwongen online contact zoeken met de kiezers. Zoals de lijsttrekker van de ChristenUnie, Gert-Jan Segers, te zien is op de bovenstaande afbeelding terwijl hij vragen beantwoordt die kiezers hem stellen op het online platform Instagram. In plaats van direct met de burgers te praten, spreken politici nu voor de camera's. Livestreams op Facebook zijn ook populair. Zo had Mark Rutte dit weekend een gesprek met horeca-ondernemers en zond de VVD dat uit op Facebook. Naast de online campagne werd er dit weekend ook op de ouderwetse manier geflyerd. Maar de meeste campagnevoerende partijleden gingen niet aanbellen uit angst voor verdere verspreiding van het coronavirus. Forum voor Democratie was de enige partij die de straat op ging om campagne te voeren. Met een vrijheidskaravaan bezocht de partij Nijmegen en Venlo voor een manifestatie. Toen er meer dan tweehonderd mensen kwamen opdagen, moest burgemeester Hubert Bruls de bijeenkomst voortijdig beëindigen, hoewel deze wel was aangekondigd en aangevraagd. Een bezoeker in Venlo twitterde dat het centrale plein voor het eerst sinds carnaval vorig jaar weer vol stond met de komst van Baudet.\n",
    "- Forum voor Democratie op zoek naar extra stemmen; Terwijl andere partijen zich nauwelijks op straat vertonen, reist Forum voor Democratie stad en land af. Deze optredens trekken niet alleen de aandacht van kiezers; het Openbaar Ministerie onderzoekt nu ook of het campagneteam van Baudet de coronaregels op grote schaal heeft overtreden. Volgens getuigen werden bij een bezoek aan Urk honderden handen geschud. En dan was er nog de volmachtrel. In een live-uitzending riep Baudet zijn kijkers op om zoveel mogelijk volmachtstemmen te regelen, aangezien kiezers dit jaar niet twee, maar drie volmachtstemmen mogen uitbrengen om de kans op besmetting te verkleinen. \"Een persoon kan eigenlijk vier keer stemmen, als je maar die volmachten kunt regelen,\" zei Baudet, en dat was een enorme kans. Maar het ministerie van Binnenlandse Zaken zei: \"Ho, dat is niet de bedoeling en is niet toegestaan.\" Het campagneteam van Forum leek daar toen al achter te komen, want de suggestie om stemmen te regelen werd snel uit de video van Baudet geknipt. Baudet houdt echter wel openlijk vast aan zijn standpunt dat er een grote kans is op verkiezingsfraude, maar dan door anderen, uiteraard.\n",
    "\n",
    "The topic of each text is described by the following keywords: 'livesessies', 'vrijheidskaravaan', 'flyerende', 'facebook', 'windjacks'; besmettingskansen', 'volmachtsstemmen', 'schielijk', 'volmachten', 'baudets'\n",
    "The following proper nouns appear in each text: Gert-Jan Segers, Mark Rutte, Forum voor Democratie, Hubert Bruls, Baudet; Forum voor Democratie, Forum voor Democratie, Ministerie kijkt, Urk, Baudet, Baudet, Baudet, Baudet\n",
    "\n",
    "Based on the information about the topic above, please create a short label of the topic for each text. Only return the label and nothing more for each text in the following format:\n",
    "\n",
    "[/INST] Main topic 1: Politics; Subtopic1: Elections and campaigns; Main topic 2: Politics; Subtopic2: Elections, campaigns and fraud \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "7c877972-294b-487f-9aac-ff6f219a8f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_prompt_1 = \"\"\"\n",
    "[INST]\n",
    "I have a document pair of the following texts:\n",
    "{text1} and {text2}\n",
    "\n",
    "The topic of each text is described by the following keywords: {keywords1} and {keywords2}\n",
    "The following proper nouns appear in each text: {proper_nouns1}, {proper_nouns2}\n",
    "\n",
    "Based on the information about the topic above, please create a short label of this topic for each text. Only return the label and nothing more for each text in the following format: Main topic 1 : Subtopic1: ; Main topic 2: Subtopic2:\n",
    "[/INST]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "fc436448-e169-4fb8-8074-d545954cda23",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_1 = system_prompt_1 + example_prompt_1 + main_prompt_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "db37e1b9-405c-4f3b-b596-f74c31742551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a PromptTemplate instance\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"text1\", \"text2\", 'proper_nouns1', 'proper_nouns2', 'keywords1', 'keywords2'],\n",
    "    template=prompt_1\n",
    ")\n",
    "\n",
    "# Create the LLMChain instance\n",
    "chain_1 = LLMChain(llm = llm, prompt = prompt_template, output_key=\"topics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "285bb7a1-afcc-4801-84cb-34432459df81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Main topic 1: Politics; Subtopic 1: Elections and campaigns; Main topic 2: Politics; Subtopic 2: Conspiracy theories and misinformation regarding the COVID-19 pandemic\n",
      "\n",
      "Main topic 1: Politics; Subtopic1: Government scandals and investigations; Main topic 2: Energy and Environment; Subtopic2: Climate goals and nuclear energy\n",
      "\n",
      "Main topic 1: Politics; Subtopic 1: Climate change and environmental policies; Main topic 2: Politics; Subtopic 2: Conspiracy theories and misinformation about the COVID-19 pandemic\n",
      "\n",
      "Main topic 1: Politics; Subtopic 1: Elections and campaigns\n",
      "Main topic 2: Economy; Subtopic 2: Consumer issues and rights\n",
      "\n",
      "Main topic 1: Politics; Subtopic1: Elections and campaigns; Main topic 2: Politics; Subtopic2: Extremism and controversial issues\n",
      "\n",
      "\n",
      "\n",
      "Please note that I have only returned the labels and not any additional notes or information.\n"
     ]
    }
   ],
   "source": [
    "# Test if it works\n",
    "for index, row in df2.iterrows():\n",
    "    full_text1 = row['Text1']  \n",
    "    full_text2 = row['Text2']  \n",
    "\n",
    "    input_variables = {\n",
    "        \"text1\": full_text1,\n",
    "        \"text2\": full_text2,\n",
    "        \"proper_nouns1\": row['proper_nouns1'],\n",
    "        \"proper_nouns2\": row['proper_nouns2'],\n",
    "        \"keywords1\": row['keywords1'],\n",
    "        \"keywords2\": row['keywords2'],\n",
    "    }\n",
    "\n",
    "    # Generate text using the chain\n",
    "    generated_text = chain_1.run(input_variables)\n",
    "    \n",
    "    print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b27fe3f-2cf4-4b8e-8045-eb12d338dfdd",
   "metadata": {},
   "source": [
    "### Step 1.1: Extract main topic from topics for matching\n",
    "\n",
    "¶This is a must otherwise the chain considers subtopics as the level of match and disregards those that match on a broad level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "8493b2e7-1417-4789-9d70-8407fe74c1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt_1_1 = \"\"\"\n",
    "<s>[INST] <<SYS>>\n",
    "You are a helpful, respectful and honest assistant for extracting the main topic from a topic. \n",
    "A topic comprises of a main topic and a subtopic. A main topic is an overarching theme, a subtopic is a more specific thematic or content-based divisions within a broader main topic.\n",
    "Main topic: Business; Subtopic: Interest rates\n",
    "Main topic: Health; Subtopic: Mental health\n",
    "Main topic: Entertainment; Subtopic: Film and Television \n",
    "Main topic: Politics; Subtopic: Elections\n",
    "\n",
    "A main topic is everything before the word 'Subtopic'.\n",
    "Given a topic, you must always return the main topic nothing else in the following format: Main topic1:, Main topic2: \n",
    "Only return the main topic label and nothing more for each text.\n",
    "\n",
    "<</SYS>>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "ce1fc52f-1630-44e0-9293-7710b0b4e2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_prompt_1_1 = \"\"\"\n",
    "I have a pair of topics:\n",
    "Main topic 1: Politics; Subtopic: Elections and campaigns; \\n\n",
    "Main topic 2: Politics; Subtopic: Elections, campaigns and fraud \\n\n",
    "\n",
    "Based on the information about the topic above, please extract the main topic from each topic. A main topic is everything before the word 'Subtopic'. In this case this word is Politics. Only return the label of the main topic and nothing more in the following format:\n",
    "\n",
    "[/INST] Main topic 1: Politics; Main topic 2: Politics\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "c5233e73-ba42-403b-92a2-df91a0f3b2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_prompt_1_1 = \"\"\"\n",
    "[INST]\n",
    "I have a pair of topics:\n",
    "{topics}\n",
    "\n",
    "Based on the information about the topic above, please extract the main topic from each topic. Only return the label of the main topic and nothing more in the following format:\n",
    "Main topic 1: ; Main topic 2: \n",
    "[/INST]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "bec45d2e-f56a-400f-be92-ed91a4925e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_1_1 = system_prompt_1_1 + example_prompt_1_1 + main_prompt_1_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "a51d9dbb-651f-4ee3-8bc8-8910c0baec4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a PromptTemplate instance\n",
    "prompt_template_1 = PromptTemplate(\n",
    "    input_variables=[\"topics\"],\n",
    "    template=prompt_1_1\n",
    ")\n",
    "\n",
    "# Create the LLMChain instance\n",
    "chain_1_1 = LLMChain(llm = llm, prompt = prompt_template_1, output_key=\"main_topic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66039a6-b152-48c2-8b3c-1a6f47e75dc0",
   "metadata": {},
   "source": [
    "### Step 1.2 Extract Subtopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "026f2d3a-34fa-4820-a46a-12d4295e130e",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt_1_2 = \"\"\"\n",
    "<s>[INST] <<SYS>>\n",
    "You are a helpful, respectful and honest assistant for extracting the subtopic from a topic. \n",
    "A topic comprises of a main topic and a subtopic: Main topic 1: Politics; Subtopic1: Elections and campaigns;\n",
    "Infer the Subtopic from the text that follows the word 'Subtopic':\n",
    "Subtopic 1: Elections and campaigns\\n\n",
    "\n",
    "Given a topic, you must always return the Subtopic for each text and nothing else in the following format: Subtopic1:, Subtopic2: \n",
    "\n",
    "<</SYS>>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "96804171-9789-4436-a4b5-51fda293bef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_prompt_1_2 = \"\"\"\n",
    "I have a pair of topics:\n",
    "\n",
    "Main topic 1: Politics; Subtopic1 : Elections and campaigns; \\n\n",
    "Main topic 2: Politics; Subtopic2: Elections, campaigns and fraud \\n\n",
    "\n",
    "Infer the subtopic from the text that follows the word 'Subtopic'\n",
    "The subtopic of each text is described by the following:\n",
    "\n",
    "[/INST] Subtopic1: Elections and campaigns; Subtopic2: Elections, campaigns and fraud\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "f2c35ecb-2f9a-4f64-8f23-c9d4b80fc24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_prompt_1_2 = \"\"\"\n",
    "[INST]\n",
    "I have a pair of topics:\n",
    "{topics}\n",
    "\n",
    "Infer the subtopic from the text that follows the word 'Subtopic'\n",
    "The subtopic of each text is described by the following:\n",
    "Subtopic1: ; Subtopic2: \n",
    "[/INST]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "547f60b9-e6a2-47c8-8bd9-ca35e7fb3209",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_1_2 = system_prompt_1_2 + example_prompt_1_2 + main_prompt_1_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "5d7a275d-117c-4673-a322-9f7367890c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a PromptTemplate instance\n",
    "prompt_template_1_2 = PromptTemplate(\n",
    "    input_variables=[\"topics\"],\n",
    "    template=prompt_1_1\n",
    ")\n",
    "\n",
    "# Create the LLMChain instance\n",
    "chain_1_2 = LLMChain(llm = llm, prompt = prompt_template_1_2, output_key=\"subtopic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "3997d72b-20d2-4735-b720-1a73833338a0",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "overall_chain = SequentialChain(chains=[chain_1, chain_1_2], input_variables = [\"text1\", \"text2\", \"proper_nouns1\", \"proper_nouns2\", 'keywords1', 'keywords2'],output_variables=[\"topics\",  \"subtopic\"],\n",
    "                  verbose=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "0ecff774-0185-4094-a5ca-4e73e2e5ee2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'text1': 'Alle pijlen zijn gericht op Rutte in RTL-debat; Reportage verkiezingscampagne Alles op Rutte, dat is de stilzwijgende afspraak waaraan al diens opponenten zich in deze campagne tot dusver houden. Na het lijsttrekkersdebat van Radio 1 en het running mate-debat is ook het premiersdebat van RTL het eerste grote tv-debat van deze verkiezingen een meertrapsaanval op de minister-president, die graag aan zijn vierde termijn zou beginnen. De tactiek van de VVD tekent zich scherper af bouw zo min mogelijk profiel op, pareer aanvallen met verzoenende reacties en blijf dichtbij de kernboodschap gelieve de premier te koesteren die het land door de coronacrisis leidt. Een ruimte die hij pakt als het aan het eind van het debat over vaccinatiebewijzen gaat We moeten verstandig blijven. De politiek moet niet op de stoel van artsen en verpleegkundigen gaan zitten, zeggen Sigrid Kaag D66 en Jesse Klaver GroenLinks op de vraag of de gewone zorg weer voorrang moet krijgen. Zo nemen ze meteen afstand van VVD en CDA, die eerder voor code zwart waarschuwden, en daarmee voor triage. Rutte springt soepel bij hen achterop. Of je nog wel naar de icwilt, dat zijn heel tere afwegingen, zegt hij.', 'text2': 'Helft van de Forum-stemmers ziet complot; De helft van de mensen die op Forum voor Democratie FVD willen stemmen, denkt dat het coronavirus bewust is ontwikkeld om burgers wereldwijd te onderdrukken. 51 procent denkt dat corona een biologisch wapen is dat in een laboratorium is gefabriceerd. Dat komt naar voren uit onderzoek van Ipsos, in opdracht van Nieuwsuur. De opvattingen van FVD-kiezers over complottheori n wijken behoorlijk af van die van de gemiddelde Nederlander. Onder alle Nederlanders gelooft 11 procent dat het virus bewust is ontwikkeld en 13 procent dat het een biologisch wapen is.', 'proper_nouns1': 'Radio 1, RTL, VVD, kernboodschap gelieve, Sigrid, D66, Jesse Klaver, GroenLinks, VVD, CDA', 'proper_nouns2': 'Forum voor Democratie, Ipsos', 'keywords1': \"['lijsttrekkersdebat', 'premiersdebat', 'pareer', 'icwilt', 'meertrapsaanval']\", 'keywords2': \"['ipsos', 'coronavirus', 'gefabriceerd', 'complottheori', 'nieuwsuur']\", 'topics': '\\nMain topic 1: Politics; Subtopic 1: Elections and campaigns; Main topic 2: Politics; Subtopic 2: Conspiracy theories and misinformation regarding the COVID-19 pandemic', 'subtopic': '\\nMain topic 1: Politics; Main topic 2: Politics'}\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'text1': 'Hoogste bestuursrechter liet forse steken vallen in affaire kinderopvangtoeslagen; De affaire rond de kinderopvangtoeslagen zal nog lang blijven nadreunen . Vorige week kwam de onderzoekscommissie onder leiding van Tweede Kamerlid Andr Bosman VVD tot de conclusie dat het tussen instanties aan vertrouwen ontbreekt. En na het eerdere parlementair onderzoek haalt de Tweede Kamer ook haar zwaarste middel, een echte parlementaire enqu te, uit de kast om in het schandaal de onderste steen boven te krijgen. Ondertussen wijst in Den Haag de ene overheidsinstantie naar de andere, om een schuldige van de ellende te benoemen. Zo ook de afdeling Bestuursrechtspraak van de Raad van State. Deze wijst, bij monde van voorzitter Bart Jan van Ettekoven, naar de wetgever, die hoofdverantwoordelijk zou zijn voor de affaire. In zijn kielzog stelt ook Herman Tjeenk Willink, voormalige vicepresident van de Raad van State, dat de Kamer als medewetgever zelf in de spiegel moet kijken. Zowel de Wet kinderopvang Wko als de Algemene wet inkomensafhankelijke regelingen Awir zouden zo dwingendrechtelijk zijn geformuleerd dat er voor de bestuursrechter geen ruimte was om te toetsen aan de beginselen van behoorlijk bestuur. Fundamentele uitgangspunten Zij behoren tot de fundamentele uitgangspunten van de rechtsstaat en gelden daarom onverkort.', 'text2': 'Stelling 3: Om de klimaatdoelen te halen moet Nederland nieuwe kerncentrales bouwen; Het gaat nu over het klimaat . Rutte zegt stellig We hebben echt kernenergie nodig. Want de wind waait niet altijd, de zon schijnt niet altijd en de VVD wil niet afhankelijk zijn van het gas van Poetin in Rusland. Rutte denkt aan een kerncentrale in Groningen.', 'proper_nouns1': 'Andr Bosman, VVD, Tweede Kamer, Raad van State, Bart Jan van Ettekoven, Herman Tjeenk Willink, Raad van State', 'proper_nouns2': 'VVD, Poetin', 'keywords1': \"['overheidsinstantie', 'kinderopvangtoeslagen', 'ettekoven', 'dwingendrechtelijk', 'tjeenk']\", 'keywords2': \"['klimaatdoelen', 'kerncentrales', 'rusland', 'waait', 'rutte']\", 'topics': '\\nMain topic 1: Politics; Subtopic1: Government scandals and investigations; Main topic 2: Energy and Environment; Subtopic2: Climate goals and nuclear energy', 'subtopic': '\\nMain topic 1: Politics; Main topic 2: Energy and Environment'}\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'text1': \"Planbureau: vertrek bedrijven reëel risico bij ambitieuze klimaatplannen; De scherpere milieuregels voor de industrie waarmee politieke partijen klimaatwinst hopen te boeken, leiden tot re le risico's dat bedrijven uit Nederland vertrekken. De mondiale broeikasgasuitstoot wordt dan nauwelijks minder. Daarvoor waarschuwt het Planbureau voor de Leefomgeving PBL maandag. De kans op dit zogeheten weglekeffect is het grootst bij de klimaatvoorstellen die de SP, GroenLinks, D66 en in mindere mate de PvdA doen, zegt het PBL. Bij de ChristenUnie en het CDA speelt dit risico minder. Het PBL heeft de verkiezingsprogramma's van deze politieke partijen geanalyseerd op effecten voor klimaat en milieu. De resultaten daarvan werden maandagochtend gepresenteerd. Het PBL rekent dit door op verzoek van de partijen zelf. De grote afwezige was de VVD, die het klimaatdeel van zijn partijprogramma niet liet doorrekenen. In industrie meeste klimaatwinst Uit de analyse blijkt dat alle politieke partijen grote klimaatwinst hopen te halen in de industri le sector. De vermeden uitstoot in 2030 is daar dan ook het grootst met 16 miljoen ton CO2 in de CDA-plannen tot 32 miljoen ton CO2 in de GroenLinks-plannen.\", 'text2': 'Baudet: corona niet bewust wereld in geslingerd; Het coronavirus is niet bewust de wereld in geslingerd . Dat zei Forum voor Democratie-voorman Thierry Baudet in het NOS Radio 1 Journaal, waar hij als eerste lijsttrekker te gast was in de verkiezingsreeks met interviews. Uit een peiling bleek afgelopen weekend dat ruim de helft van FvD-kiezers denkt dat het coronavirus bewust is ontwikkeld om burgers wereldwijd te onderdrukken. 51 procent denkt dat corona een biologisch wapen is dat in een laboratorium is gefabriceerd. Baudet deelt die opvatting dus niet, maar vindt het wel extreem toevallig dat het virus ontstaan is in de buurt van een Chinees laboratorium waar onderzoek werd gedaan naar virussen. Verder ziet Baudet dat corona gebruikt wordt door wereldleiders om maatregelen door te voeren op weg naar een wereldstaat. Het woord complot vindt hij in dat verband niet gek. Het wordt als scheldwoord gebruikt, maar betekent letterlijk dat er onderlinge afspraken gemaakt worden die je niet naar buiten brengt. Ingestonken Online beantwoordde Baudet in een live Q&A de vragen van kijkers. De FvD-leider zegt dat hij niet betoogt dat het virus niet bestaat. Hij noemt corona een stevige griep. Maar hij ontdekte dat corona niet het ebolavirus is.', 'proper_nouns1': 'Planbureau, Planbureau voor de Leefomgeving, PBL, SP, GroenLinks, D66, PvdA, PBL, ChristenUnie, CDA, PBL, PBL, VVD', 'proper_nouns2': 'Baudet, Forum voor Democratie-voorman Thierry Baudet, NOS, Radio 1 Journaal, FvD-kiezers, Baudet, Baudet, Baudet', 'keywords1': \"['broeikasgasuitstoot', 'klimaatwinst', 'leefomgeving', 'milieuregels', 'zogeheten']\", 'keywords2': \"['virussen', 'chinees', 'ebolavirus', 'ingestonken', 'coronavirus']\", 'topics': '\\nMain topic 1: Politics; Subtopic 1: Climate change and environmental policies; Main topic 2: Politics; Subtopic 2: Conspiracy theories and misinformation about the COVID-19 pandemic', 'subtopic': '\\nMain topic 1: Politics; Main topic 2: Politics'}\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'text1': \"Recht op reparatie van apparatuur komt steeds dichterbij; REPAIR CAF S Jeroen Groot en Caitlin Stooker Philip Leenman 68 wijst naar een Senseo. Het koffiezetapparaat van Philips staat in half gedemonteerde toestand op de werkbank in zijn werkkamer in Naarden. Voor het ongeoefende oog valt er weinig te zien aan het binnenste van het apparaat, maar Leenman weet precies wat er mis is. In dit geval betreft het de boiler om het water op temperatuur te brengen. Als het verwarmingselement wordt aangezet terwijl er geen water in zit, gaat het binnen zes seconden stuk, zegt de gepensioneerde ICT'er. Een kapot huishoudelijk apparaat belandt vaak bij het afval, omdat de kosten van reparatie door een professionele reparateur niet in verhouding staan tot de prijs van een nieuwe. Zonde, stelt het al in 2009 opgerichte Repair Caf. Hier zetten dan ook duizenden vrijwilligers zich in om huis-tuin-en-keukenspullen te repareren. Onder wie Leenman. Normaliter komen consumenten langs bij de Repair Caf s, waar vrijwilligers de kapotte spullen beoordelen en indien mogelijk ter plaatse repareren. Maar vanwege het coronavirus werken ook de reparateurs vanuit huis. Inmiddels zijn er in Nederland meer dan 500 Repair Caf s. Caf s, in 36 landen.\", 'text2': 'Niet een lijsttrekker, maar een kiezer brengt Mark Rutte bij RTL in het nauw; Eerste TV-Debat Het format van het verkiezingsdebat op RTL4 ontregelde premier Mark Rutte VVD, die normaliter sto cijns debatten voert.,Een tv-format kan een beslissende rol spelen in een lijsttrekkersdebat. Vooral demissionair premier Mark Rutte VVD zal die les geleerd hebben. De lijsttrekkers naast Rutte ook Geert Wilders PVV, Wopke Hoekstra CDA, Sigrid Kaag D66 , Lilian Marijnissen SP en Jesse Klaver GroenLinks moesten zondagavond in het RTL-debat niet alleen met elkaar in debat, maar ook met een kiezer. De lijsttrekkers kenden het onderwerp niet in het geval van Rutte was dat de Toeslagenaffaire. Ook wisten ze niet wie ze tegenover zich zouden krijgen. Rutte had tot dan toe een vrij eenvoudig debat. Hij kent zijn tegenstanders, debatteert zich behendig onder hun beschuldigingen uit, en gaat onbewogen door. Maar het gesprek met de kiezer had een totaal ander effect. Rutte werd tegenover Kristie Rongen geplaatst. Zij is gedupeerde in de Toeslagenaffaire, die had geleid tot de val van het derde kabinet-Rutte. Wij zaten als ratten in de val. U bent daar ook schuldig aan, zei ze. U niet.', 'proper_nouns1': 'REPAIR, CAF S Jeroen Groot, Philips, Leenman, Caf, Leenman, Repair Caf s, Caf s', 'proper_nouns2': 'Mark Rutte, RTL, Mark Rutte, Mark Rutte, Geert Wilders, PVV, Wopke Hoekstra, CDA, Sigrid, Lilian Marijnissen, SP, Jesse, GroenLinks, Kristie Rongen', 'keywords1': \"['verwarmingselement', 'reparateurs', 'koffiezetapparaat', 'reparateur', 'boiler']\", 'keywords2': \"['lijsttrekkersdebat', 'toeslagenaffaire', 'ontregelde', 'cijns', 'marijnissen']\", 'topics': '\\nMain topic 1: Politics; Subtopic 1: Elections and campaigns\\nMain topic 2: Economy; Subtopic 2: Consumer issues and rights', 'subtopic': '\\nMain topic 1: Politics; Main topic 2: Economy'}\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'text1': 'Dode en gewonde door zuurstofexplosie corona-afdeling Oekraïne; In een ziekenhuis in Tsjernivtsi, in het westen van Oekra ne, zijn op de corona-afdeling een dode en een gewonde gevallen door een explosie. Een zuurstofleiding ontplofte, waarna er brand ontstond. Twintig mensen konden op tijd worden ge vacueerd. Het is het tweede soortgelijke incident in korte tijd in Oekra ne. Begin deze maand overleden een dokter en drie pati nten in Zaporizja, in het zuidoosten van Oekra ne, nadat er brand was ontstaan op een IC door een zuurstoflek.', 'text2': 'Wilders in de schijnwerpers; Wilders in de schijnwerpers Den Haag Wilders tegen de rest . Dat was zondagavond de teneur bij het verkiezingsdebat van RTL. Meerdere lijsttrekkers probeerden Mark Rutte VVD te vloeren nu die in de peilingen nog steeds fier aan kop staat. Dat lukte niet. Het was vooral Wilders die opviel. Zo wist hij Sigrid Kaag D66 op de kast te krijgen met een discussie over diversiteitsquota. Dat k n toch niet, riep ze uit toen Wilders zei dat hij niet houdt van dit soort quota, maar wel graag iemand van kleur wil nomineren voor de positie van minister van Cultuur, namelijk Zwarte Piet. GL er Jesse Klaver ging onderuit door te stellen dat Ronald Koeman nog bondscoach van Oranje is. Dat hij inmiddels allang bij FC Barcelona zit, was hem kennelijk ontgaan.', 'proper_nouns1': 'Oekra, Twintig, Oekra', 'proper_nouns2': 'Wilders, Mark Rutte, Sigrid Kaag D66, Wilders, Zwarte Piet, Jesse Klaver, Ronald Koeman, Oranje', 'keywords1': \"['tsjernivtsi', 'zaporizja', 'zuurstofexplosie', 'oekraïne', 'zuurstofleiding']\", 'keywords2': \"['diversiteitsquota', 'ronald', 'rtl', 'zit', 'wilders']\", 'topics': '\\nMain topic 1: Politics; Subtopic1: Elections and campaigns; Main topic 2: Politics; Subtopic2: Extremism and controversial issues\\n\\n\\n\\nPlease note that I have only returned the labels and not any additional notes or information.', 'subtopic': '\\nMain topic 1: Politics; Main topic 2: Politics'}\n"
     ]
    }
   ],
   "source": [
    "for index, row in df2.iterrows():\n",
    "    full_text1 = row['Text1']  \n",
    "    full_text2 = row['Text2']  \n",
    "\n",
    "    input_variables = {\n",
    "        \"text1\": full_text1,\n",
    "        \"text2\": full_text2,\n",
    "        \"proper_nouns1\": row['proper_nouns1'],\n",
    "        \"proper_nouns2\": row['proper_nouns2'],\n",
    "        \"keywords1\": row['keywords1'],\n",
    "        \"keywords2\": row['keywords2'],\n",
    "    }\n",
    "\n",
    "    # Generate text using the chain\n",
    "    results = overall_chain(input_variables)\n",
    "    \n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c1fd05-4d0c-4a6b-a5ba-7d9b640c7ff2",
   "metadata": {},
   "source": [
    "## Step 2: Evaluate topic level match\n",
    "Compare the topics of the text pairs and made eveluation about the match level  \n",
    "\n",
    "* We create a second chain for this task that uses the texts as well as the extrcated topics as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "id": "d2e9a0db-7285-4a78-a12a-036c4a1f99a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the system prompt from the default one to a specific one in order to focus the model on a single task. \n",
    "# This system prompt will be\n",
    "system_prompt_2 = \"\"\"\n",
    "<s>[INST] <<SYS>>\n",
    "You are a helpful, respectful, and honest assistant for comparing the main topics of two texts. In this comparison, a match is solely based on the main topic and nothing else.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "id": "711b57fe-e781-4578-8285-40a97fd56803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example prompt demonstrating the output we are looking for\n",
    "example_prompt_2 = \"\"\"\n",
    "\n",
    "The main topic of each text is described by the following labels:\n",
    "\n",
    "Main topic 1: Politics;  \n",
    "Main topic 2: Politics; \n",
    "\n",
    "\n",
    "Based on the information about the main topics above, please write a short evaluation about whether the two texts match on a main topic level. Make sure to only return the evaluation and nothing more in the following format:\n",
    "\n",
    "[/INST] Topic Evaluation: Yes, the two texts match on a main topic level because both texts touch upon the broader context of Politics as seen by their main Topic. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "id": "6b17947b-70af-4abd-9ba4-0084ea40bac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#main prompt describing the task once more and adding the input variables to be considered\n",
    "main_prompt_2 = \"\"\"\n",
    "[INST]\n",
    "\n",
    "The main topic of each text is the following: \n",
    "{main_topic}\n",
    "\n",
    "Based on the information about the topics above, please write a short evaluation about whether the two texts match on a main topic level. Make sure to only return the evaluation and nothing more in the following format:\n",
    "Topic Evaluation:\n",
    "[/INST] \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "id": "19600ef7-e635-461f-9e2c-dba231419966",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_2 = system_prompt_2 + example_prompt_2 + main_prompt_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "id": "d4dd2a0c-56c3-4d95-b348-b15a00689bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_2 = PromptTemplate(input_variables=[\"main_topic\"], template=prompt_2, batch_size=32, max_iterations = 1)\n",
    "chain_2 = LLMChain(llm = llm, prompt = prompt_template_2, output_key=\"topic_evaluation\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5940ddc7-73c3-41f7-a3d4-0dbdaf8dc334",
   "metadata": {},
   "source": [
    "## Step 3: Create classification label based on evaluation\n",
    "Provide single label for the match level\n",
    "\n",
    "* We create a third chain for this task that uses the texts as well as the extracted topics and evaluation as input.\n",
    "* Labels: topic match, not topic match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "id": "fecbc38c-b157-441f-a6f6-b682ef673a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the system prompt. It describes information given to all conversations\n",
    "# This system prompt will be\n",
    "system_prompt_3 = \"\"\"\n",
    "<s>[INST] <<SYS>>\n",
    "You are a helpful, respectful and honest assistant for classifying whether two texts match on a main topic level based on an evaluation provided. \n",
    "\n",
    "At each request excplicitly assign one of the two labels below. \n",
    "0 - no match\n",
    "1 - topic match\n",
    "\n",
    "Make sure you to only return the label and nothing else.\n",
    "<</SYS>>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "id": "28398820-cab0-4adb-b95d-be13c983f317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example prompt demonstrating the output we are looking for\n",
    "example_prompt_3 = \"\"\"\n",
    "\n",
    "The following evaluation describes the topic match level:\n",
    "Yes, the two texts match on a main topic level. Both texts touch upon the broader context of Politics. \n",
    "Based on this information, please assign either '0 - no match' or '1 - topic match'. Make sure to only return the label and nothing more in the following format:\n",
    "\n",
    "[/INST]: 1 \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "id": "ea469ecd-17db-422d-ae07-f82c7b2cdf94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our main prompt with documents ([DOCUMENTS]) and keywords ([KEYWORDS]) tags\n",
    "main_prompt_3 = \"\"\"\n",
    "[INST]\n",
    "\n",
    "The following evaluation describes the topic match level:\n",
    "{topic_evaluation}\n",
    "\n",
    "Based on this information, please assign either '0 - no match' or '1 - topic match'. Make sure to only return the label and nothing more in the following format:\n",
    "[/INST] \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "id": "7b78d994-404d-43de-a5e2-12278ec47538",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_3 = system_prompt_3 + example_prompt_3 + main_prompt_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "id": "83565f57-c842-4cb5-8be7-481b82c8cb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_3 = PromptTemplate(input_variables=[ \"topic_evaluation\"], template=prompt_3, batch_size=32, max_iterations = 1)\n",
    "chain_3 = LLMChain(llm = llm, prompt = prompt_template_3, output_key=\"match_topic\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334a661c-8dac-4a55-8cea-985a6172e43f",
   "metadata": {},
   "source": [
    "## Step 4: Identify news events\n",
    "* we ask the model the identify the news event described in each text\n",
    "* input data remains the same\n",
    "* this is in preparation of assessing news event level matching similar to topic level matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "id": "8ab4b2cc-a97a-4c4f-be0d-401b552e2126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the system prompt. It describes information given to all conversations\n",
    "# This system prompt will be\n",
    "system_prompt_4 = \"\"\"\n",
    "<s>[INST] <<SYS>>\n",
    "You are a helpful, respectful and honest assistant for idenitifying the news event described in a pair of documents. \n",
    "News events are specific events that lead to news coverage, such as a specific debate on a specific day in a specific parliament, a specific accident, or a specific football match. They can be covered by one or more articles in one or more outlets, but relate to one specific and identifiable event and are thus much more fine-grained than news topics, issues, or news categories.\n",
    "News events can span over multiple days but not more than 10 days. Therefore articles that cover the same news event are published within the same few hours and in the course of a few days. \n",
    "\n",
    "Provide your answer as an explanation in maximum 100 tokens. Make sure you to only return the news event identified and nothing else. Be very specific, name actors and places where possible. \n",
    "<</SYS>>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "id": "fd766de4-6396-49c6-aec1-0c9695528c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example prompt demonstrating the output we are looking for\n",
    "example_prompt_4 = \"\"\"\n",
    "I have a document pair of the following texts:\n",
    "- Contact met de kiezer; Deze keer zie je geen lijsttrekkers in windjacks rondlopen op markten. Kandidaat-Kamerleden moeten noodgedwongen online contact zoeken met de kiezers. Zoals de lijsttrekker van de ChristenUnie, Gert-Jan Segers, te zien is op de bovenstaande afbeelding terwijl hij vragen beantwoordt die kiezers hem stellen op het online platform Instagram. In plaats van direct met de burgers te praten, spreken politici nu voor de camera's. Livestreams op Facebook zijn ook populair. Zo had Mark Rutte dit weekend een gesprek met horeca-ondernemers en zond de VVD dat uit op Facebook. Naast de online campagne werd er dit weekend ook op de ouderwetse manier geflyerd. Maar de meeste campagnevoerende partijleden gingen niet aanbellen uit angst voor verdere verspreiding van het coronavirus. Forum voor Democratie was de enige partij die de straat op ging om campagne te voeren. Met een vrijheidskaravaan bezocht de partij Nijmegen en Venlo voor een manifestatie. Toen er meer dan tweehonderd mensen kwamen opdagen, moest burgemeester Hubert Bruls de bijeenkomst voortijdig beëindigen, hoewel deze wel was aangekondigd en aangevraagd. Een bezoeker in Venlo twitterde dat het centrale plein voor het eerst sinds carnaval vorig jaar weer vol stond met de komst van Baudet.\n",
    "- Forum voor Democratie op zoek naar extra stemmen; Terwijl andere partijen zich nauwelijks op straat vertonen, reist Forum voor Democratie stad en land af. Deze optredens trekken niet alleen de aandacht van kiezers; het Openbaar Ministerie onderzoekt nu ook of het campagneteam van Baudet de coronaregels op grote schaal heeft overtreden. Volgens getuigen werden bij een bezoek aan Urk honderden handen geschud. En dan was er nog de volmachtrel. In een live-uitzending riep Baudet zijn kijkers op om zoveel mogelijk volmachtstemmen te regelen, aangezien kiezers dit jaar niet twee, maar drie volmachtstemmen mogen uitbrengen om de kans op besmetting te verkleinen. \"Een persoon kan eigenlijk vier keer stemmen, als je maar die volmachten kunt regelen,\" zei Baudet, en dat was een enorme kans. Maar het ministerie van Binnenlandse Zaken zei: \"Ho, dat is niet de bedoeling en is niet toegestaan.\" Het campagneteam van Forum leek daar toen al achter te komen, want de suggestie om stemmen te regelen werd snel uit de video van Baudet geknipt. Baudet houdt echter wel openlijk vast aan zijn standpunt dat er een grote kans is op verkiezingsfraude, maar dan door anderen, uiteraard.\\n\n",
    "\n",
    "The following keywords appear in each text: 'livesessies', 'vrijheidskaravaan', 'flyerende', 'facebook', 'windjacks'; besmettingskansen', 'volmachtsstemmen', 'schielijk', 'volmachten', 'baudets'\n",
    "The following proper nouns appear in each text: Gert-Jan Segers, Mark Rutte, Forum voor Democratie, Hubert Bruls, Baudet; Forum voor Democratie, Forum voor Democratie, Ministerie kijkt, Urk, Baudet, Baudet, Baudet, Baudet\n",
    "\n",
    "The topic of each text is the following:\n",
    "Main topic 1: Politics; Subtopic: Elections and campaigns; \\n\n",
    "Main topic 2: Politics; Subtopic: Elections, campaigns and fraud \\n\n",
    "\n",
    "Based on the information above, please identify the news events that describe the texts. Be as specific as possible. Make sure to only return the events and nothing more for each text in the following format:\n",
    "\n",
    "[/INST] Event 1: Most political parties are shifting their campaign activity stategies due to the COVID-19 pandemic; Event 2: Forum voor Democratie party's campaign activities violate COVID-19 regulations while other parties have more pandemic-proof startegies. \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "id": "728dc550-3900-44bd-8060-4f2596dfb925",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example prompt demonstrating the output we are looking for\n",
    "main_prompt_4 = \"\"\"\n",
    "\n",
    "I have a document pair of the following texts:\n",
    "{text1} and {text2}\n",
    "\n",
    "The following keywords appear in each text: {keywords1} and {keywords2}\n",
    "The following proper nouns appear in each text: {proper_nouns1}, {proper_nouns2}\n",
    "\n",
    "The topic of each text is the following:\n",
    "{topics}\n",
    "\n",
    "Based on the information above, please identify the news events that describe the texts. Make sure to only return the news events and nothing more in the following format:\n",
    "[/INST] \n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "id": "2c2242af-37bc-4482-8748-f315ed60910b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_4 = system_prompt_4 + example_prompt_4 + main_prompt_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "id": "c376673a-c2c9-4712-96d8-88e5a1c0c6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_4 = PromptTemplate(input_variables=[\"text1\", \"text2\", \"proper_nouns1\", \"proper_nouns2\", 'keywords1', 'keywords2', \"topics\" ], template=prompt_4, batch_size=32, max_iterations = 1)\n",
    "chain_4 = LLMChain(llm = llm, prompt = prompt_template_4, output_key=\"news_events\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570ed895-7395-45da-86ee-57d2937d2a67",
   "metadata": {},
   "source": [
    "## Step 5: Evaluate news event level match\n",
    "\n",
    "* we ask the model to compare the news events identified on whether they match \n",
    "* input data remains the same plus the dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "id": "285193cb-5e60-497a-8e52-04a74365da07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the system prompt. It describes information given to all conversations\n",
    "# This system prompt will be\n",
    "system_prompt_5 = \"\"\"\n",
    "<s>[INST] <<SYS>>\n",
    "You are a helpful, respectful and honest assistant for evaluating whether two texts pertain to the same news event.\n",
    "News events are comprised of specific events that lead to news coverage around a news story, such as a specific debate on a specific day in a specific parliament, a specific accident, or a specific football match. \\n\n",
    "They can be covered by one or more articles in one or more outlets, but relate to one specific and identifiable event and are thus much more fine-grained than news topics, issues, or news categories.\\n\n",
    "News events can span over multiple days but not more than 10 days. Therefore articles that cover the same news event are published very close in time, a matter of hours or maximum a few days. \n",
    "Different news events can also be published on the same date or on a very close date. \\n\n",
    "The most important criteria for determining whether the two texts pertain to the same news event are the events mentioned in the text. The date overlap is a secondary objective. \\n\n",
    "\n",
    "An event within a news event must refer to a specific event or related developments around the event. A news event can include various articles, reports, and updates from news outlets, all contributing to the coverage of that specific event or issue and its sorrounding aspects. \\n\n",
    "For example, the news event might revolve around the presidential election of a specific year, detailing campaign events, candidate profiles, polling data, and key issues.\n",
    "Provide your answer as an explanation in maximum 100 tokens. Make sure to only return the evaluation and nothing else.\n",
    "<</SYS>>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "id": "2e7ade21-4985-470e-aa5d-d4e846854185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example prompt demonstrating the output we are looking for\n",
    "example_prompt_5 = \"\"\"\n",
    "\n",
    "The news events of each text is the following:\n",
    " Event 1: Most political parties are shifting their campaign activity stategies due to the COVID-19 pandemic; \\n\n",
    " Event 2: Forum voor Democratie party's campaign activities violate COVID-19 regulations while other parties have more pandemic-proof strategies. \\n\n",
    "\n",
    "The pubishing dates of the texts is the following:\\n\n",
    "date1: 01/03/2021; date2: 01/03/2021 \\n \n",
    "\n",
    "Based on the information above, please write a short evaluation about whether the two texts match on a news event level. Make sure to only return the evaluation and nothing more in the following format:\n",
    "\n",
    "[/INST] Event Evaluation: Both texts focus on one particular news event, the election campaign and party campaign activities amid the COVID-19 pandemic which is distintive event. Both texts discuss aspects of the same election campaign, political parties and campaign strategies during the pandemic indicating that they pertain to the same news event.\n",
    "The texts were also published at a similar time and date which further indicates that they belong to the same news event. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "id": "53c114e2-b556-4280-aecf-b755377b6532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example prompt demonstrating the output we are looking for\n",
    "main_prompt_5 = \"\"\"\n",
    "\n",
    "The news events of each text is the following:\n",
    "{news_events}\n",
    "\n",
    "The pubishing dates of the texts is the following:\n",
    "{date1} and {date2}\n",
    "\n",
    "Based on the information above, please write a short evaluation about whether the two texts match on a news event level. Make sure to only return the evaluation and nothing more in the following format:\n",
    "[/INST] \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "id": "91199987-0633-49a5-8335-34d85c093628",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_5 = system_prompt_5 + example_prompt_5 + main_prompt_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "id": "5e77640b-d2e2-408c-81e7-1bae8c728739",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_5 = PromptTemplate(input_variables=[\"news_events\", \"date1\", \"date2\"], template=prompt_5, batch_size=32, max_iterations = 1)\n",
    "chain_5 = LLMChain(llm = llm, prompt = prompt_template_5, output_key=\"event_evaluation\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f26b118-3760-4295-afb0-31f080ff548d",
   "metadata": {},
   "source": [
    "## Step 6: Provide single label for news event level match\n",
    "\n",
    "* we use the evalution and the events to make a classication whether there is a match or no match on the news event level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "id": "b446524e-b4e0-4eea-9697-eb89c1063162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the system prompt. It describes information given to all conversations\n",
    "# This system prompt will be\n",
    "system_prompt_6 = \"\"\"\n",
    "<s>[INST] <<SYS>>\n",
    "You are a helpful, respectful and honest assistant for classifying whether two texts match on news event level based on an evaluation provided. \n",
    "\n",
    "At each request excplicitly assign one of the two labels below. \n",
    "0 - no match\n",
    "1 - event match\n",
    "\n",
    "Make sure you to only return the label and nothing else.\n",
    "<</SYS>>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "id": "51f0eeb0-7850-49f3-bd4b-87492b1473b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example prompt demonstrating the output we are looking for\n",
    "example_prompt_6 = \"\"\"\n",
    "\n",
    "The following evaluation describes the news event match level:\n",
    "Both texts focus on one particular news event, the election campaign and party campaign activities amid the COVID-19 pandemic which is distintive event. Both texts discuss aspects of the same election campaign, political parties and campaign strategies during the pandemic indicating that they pertain to the same news event.\n",
    "The texts were also published at a similar time and date which further indicates that they belong to the same news event. \n",
    "Based on this information, please assign either '0 - no match' or '1 - topic match'. Make sure to only return the label and nothing more in the following format:\n",
    "\n",
    "[/INST]: 1 \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "id": "3561f2bb-f6f5-40a4-b718-310d4b1c4002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our main prompt with documents ([DOCUMENTS]) and keywords ([KEYWORDS]) tags\n",
    "main_prompt_6 = \"\"\"\n",
    "[INST]\n",
    "\n",
    "The following evaluation describes the news event match level:\n",
    "{event_evaluation}\n",
    "\n",
    "Based on this information, please assign either '0 - no match' or '1 -event match'. Make sure to only return the label and nothing more in the following format:\n",
    "[/INST] \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "id": "ce8b7e06-7e4a-4d0e-bdcc-bce06c6a5b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_6 = system_prompt_6 + example_prompt_6 + main_prompt_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "id": "c5139873-ecab-4728-ac18-92b46d9c005e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_6 = system_prompt_6 + example_prompt_6 + main_prompt_6\n",
    "\n",
    "prompt_template_6 = PromptTemplate(input_variables=[ \"event_evaluation\"], template=prompt_6, batch_size=32, max_iterations = 1)\n",
    "chain_6 = LLMChain(llm = llm, prompt = prompt_template_6, output_key=\"match_event\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8ff746-6bfc-42bc-87c5-9433a69ea2a6",
   "metadata": {},
   "source": [
    "## Create overall chain to combine previous chains into one big sequential chain\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d46bba-ffa5-4d1b-9365-4615cb191e19",
   "metadata": {},
   "source": [
    "### Run the overall chain and save the results into the df column\n",
    "\n",
    "this is to be modified based on all the new output variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "id": "9b07da48-2d22-47a0-9da9-0bd9d8336f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 0 in 19.11 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 1 in 19.77 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 2 in 19.74 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 3 in 17.64 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 4 in 20.69 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 5 in 20.11 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 6 in 16.86 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 7 in 20.45 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 8 in 21.77 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 9 in 17.09 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 10 in 20.22 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 11 in 20.43 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 12 in 19.71 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 13 in 20.47 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 14 in 20.59 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 15 in 19.04 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 16 in 18.26 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 17 in 18.03 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 18 in 18.83 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 19 in 18.11 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 20 in 18.11 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 21 in 17.24 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 22 in 20.28 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 23 in 21.52 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 24 in 18.70 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 25 in 17.80 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 26 in 25.23 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 27 in 22.21 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 28 in 20.62 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 29 in 19.59 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 30 in 19.56 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 31 in 16.85 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 32 in 19.76 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 33 in 20.09 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 34 in 18.06 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 35 in 18.36 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 36 in 19.96 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 37 in 17.26 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 38 in 19.64 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 39 in 19.84 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 40 in 20.40 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 41 in 19.68 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 42 in 18.95 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 43 in 20.21 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 44 in 22.51 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 45 in 23.13 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 46 in 18.93 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 47 in 19.00 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 48 in 21.28 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 49 in 20.39 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 50 in 18.14 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 51 in 19.47 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 52 in 21.88 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 53 in 19.34 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 54 in 22.06 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 55 in 17.15 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 56 in 19.77 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 57 in 21.51 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 58 in 17.76 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 59 in 17.72 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 60 in 19.02 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 61 in 19.75 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 62 in 17.67 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 63 in 18.80 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 64 in 23.07 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 65 in 28.94 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 66 in 19.03 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 67 in 18.63 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 68 in 20.68 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 69 in 19.20 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 70 in 19.80 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 71 in 17.87 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 72 in 17.62 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 73 in 20.47 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 74 in 20.35 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 75 in 22.60 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 76 in 17.87 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 77 in 18.44 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 78 in 18.70 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 79 in 19.10 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 80 in 20.12 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 81 in 19.49 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 82 in 21.04 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 83 in 19.53 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 84 in 19.95 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 85 in 19.49 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 86 in 20.78 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 87 in 19.37 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 88 in 20.10 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 89 in 18.78 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 90 in 19.82 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 91 in 18.58 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 92 in 17.10 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 93 in 18.28 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 94 in 20.45 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 95 in 18.92 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 96 in 21.38 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 97 in 17.50 seconds\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Processed row 98 in 19.54 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "# Create empty lists to collect the results\n",
    "pd.options.mode.chained_assignment = None  # Disable the warning (not recommended)\n",
    "\n",
    "topics = []\n",
    "topic_eval = []\n",
    "match_topic = []\n",
    "news_events = []\n",
    "event_eval = []\n",
    "match_event = []\n",
    "\n",
    "# Iterating over the DataFrame\n",
    "for index, row in df.iterrows():\n",
    "    full_text1 = str(row['Text1'])  \n",
    "    full_text2 = str(row['Text2'])  \n",
    "\n",
    "    input_variables = {\n",
    "        \"text1\": full_text1,\n",
    "        \"text2\": full_text2,\n",
    "        \"proper_nouns1\": row['proper_nouns1'],\n",
    "        \"proper_nouns2\": row['proper_nouns2'],\n",
    "        \"keywords1\": row['keywords1'],\n",
    "        \"keywords2\": row['keywords2'],\n",
    "        \"date1\": row['Date1'],\n",
    "        \"date2\": row['Date2']\n",
    "    }\n",
    "\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Process the input_variables and get the results\n",
    "    #create overall chain to combine previous chains into one big sequential chain\n",
    "    overall_chain = SequentialChain(\n",
    "                  chains=[chain_1, chain_1_1, chain_2, chain_3, chain_4, chain_5, chain_6], input_variables = [\"text1\", \"text2\", \"proper_nouns1\", \"proper_nouns2\", 'keywords1', 'keywords2', 'date1', 'date2'],output_variables=[\"topics\", \"main_topic\", \"topic_evaluation\", \"match_topic\",\"news_events\",\"event_evaluation\", \"match_event\"],\n",
    "                  verbose=True )\n",
    "    \n",
    "    results = overall_chain(input_variables)\n",
    "    # Stop the timer\n",
    "    end_time = time.time()\n",
    "\n",
    "\n",
    "    # Append results to respective lists\n",
    "    topics.append(results['topics'].strip())\n",
    "    match_topic.append(results['match_topic'].strip())\n",
    "    topic_eval.append(results['topic_evaluation'].strip())\n",
    "    news_events.append(results['news_events'].strip())\n",
    "    event_eval.append(results['event_evaluation'].strip())\n",
    "    match_event.append(results['match_event'].strip())\n",
    "\n",
    "    # Calculate and print the time taken for processing this row\n",
    "    row_processing_time = end_time - start_time\n",
    "    print(f\"Processed row {index} in {row_processing_time:.2f} seconds\")\n",
    "\n",
    "# Add new columns to the DataFrame\n",
    "df.loc[:,'Topic'] = topics\n",
    "df.loc[:,'Topic_eval'] = topic_eval\n",
    "df.loc[:,'Topic_match'] = match_topic\n",
    "df.loc[:,'News_events'] = news_events\n",
    "df.loc[:,'Event_eval'] = event_eval\n",
    "df.loc[:,'Event_match'] = match_event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f859ba5c-e4be-4d7d-9583-83e2fc09192e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "id": "112e5e6b-d3b9-4db1-9ec0-578020970acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the folder 4 levels up where you want to save the DataFrame\n",
    "save_folder_path = os.path.join(parent_directory, 'initial_out')\n",
    "\n",
    "# Create the folder if it doesn't exist\n",
    "os.makedirs(save_folder_path, exist_ok=True)\n",
    "\n",
    "# Define the full path to save the DataFrame\n",
    "save_file_path = os.path.join(save_folder_path, '13b_prompt_quality_00.csv')\n",
    "\n",
    "# Save the DataFrame to the specified path\n",
    "df.to_csv(save_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc466914-eb18-4e5e-bb59-ca4f9cf1a4ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python 3.10",
   "language": "python",
   "name": "python_3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
