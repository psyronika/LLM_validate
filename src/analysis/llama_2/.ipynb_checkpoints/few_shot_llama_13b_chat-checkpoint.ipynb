{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dde61e5e-e9cc-4399-a8d5-048d00697c5a",
   "metadata": {},
   "source": [
    "## Llama 13b for validation task\n",
    "\n",
    "* input: dataframe with text pairs and additional info LLama 2 should use to make informed decision\n",
    "* output: dataframe with additional columns: topic, topic match evalutation, topic match classification, news event, news event match evaluation, news event match classification, final classification on topic-level and news event level matching\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "629e3acb-b512-4f07-bd44-ad67fa7d8e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from torch import cuda, bfloat16\n",
    "import transformers\n",
    "import pandas as pd\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chains import SequentialChain\n",
    "from transformers import pipeline\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "371f18fb-3b68-41b7-8a86-c9535756dc2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function torch.clear_autocast_cache>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.clear_autocast_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84f6e465-bc47-4ca8-9a12-250219ecc871",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_auth_file = 'analysis/hf_auth.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51dd8c64-1d6a-472e-a669-e39b09784450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the API token from the file\n",
    "with open(hf_auth_file, \"r\") as file:\n",
    "    hf_auth = file.read().strip()  # Remove leading/trailing whitespaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cec9f8ed-1605-49f4-a9f1-0b4f356301ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/volume_2/python_3.10/lib/python3.10/site-packages/transformers/modeling_utils.py:2193: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec1880149c4e42cba102b4924509c224",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded on cuda:0\n"
     ]
    }
   ],
   "source": [
    "model_id = 'meta-llama/Llama-2-13b-chat-hf'\n",
    "\n",
    "device = f'cuda:{cuda.current_device()}' if cuda.is_available() else 'cpu'\n",
    "\n",
    "# set quantization configuration to load large model with less GPU memory\n",
    "# this requires the `bitsandbytes` library\n",
    "bnb_config = transformers.BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type='nf4',\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=bfloat16\n",
    ")\n",
    "\n",
    "# begin initializing HF items, need auth token for these\n",
    "\n",
    "model_config = transformers.AutoConfig.from_pretrained(\n",
    "    model_id,\n",
    "    use_auth_token=hf_auth\n",
    ")\n",
    "\n",
    "model = transformers.AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    trust_remote_code=True,\n",
    "    config=model_config,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map='auto',\n",
    "    use_auth_token=hf_auth\n",
    ")\n",
    "model.eval()\n",
    "print(f\"Model loaded on {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "799a7a2f-9784-403d-9e23-71e6b2d1f7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
    "    model_id,\n",
    "    use_auth_token=hf_auth\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a4c1b09-5715-46e7-88eb-822b2b2fa4ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Name: NVIDIA A10\n",
      "Memory Usage: 3.559241771697998 GB\n",
      "Max Memory Usage: 3.604752540588379 GB\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda')\n",
    "print(\"GPU Name:\", torch.cuda.get_device_name(device))\n",
    "print(\"Memory Usage:\", torch.cuda.memory_allocated(device) / 1024 ** 3, \"GB\")\n",
    "print(\"Max Memory Usage:\", torch.cuda.max_memory_allocated(device) / 1024 ** 3, \"GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b54484da-e4b1-457b-8c36-8d50e6ee2bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_text = transformers.pipeline(\n",
    "    model=model, tokenizer=tokenizer,\n",
    "    return_full_text=True,  # langchain expects the full text\n",
    "    task='text-generation',\n",
    "    # we pass model parameters here too\n",
    "    temperature=0.0,  # 'randomness' of outputs, 0.0 is the min and 1.0 the max we do not want any randomness here as we want the model to stick to the prompt as closely as possible\n",
    "    max_new_tokens=512,  # max number of tokens to generate in the output\n",
    "    repetition_penalty=1.1  # without this output begins repeating\n",
    ")\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=generate_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f474429-5dd0-4991-9975-352fa8b0d7bc",
   "metadata": {},
   "source": [
    "### Read in file\n",
    "\n",
    "This is a file for prompt engineering that we devide into smaller samples for tuning our prompts. There are 100 rows in this data and we split them up into 20, 5 row dfs for quick testing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "455618db-c310-4aa4-a33c-85f30770ef86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to navigate up 'n' levels\n",
    "def navigate_up(current_directory, levels):\n",
    "    for _ in range(levels):\n",
    "        current_directory = os.path.dirname(current_directory)\n",
    "    return current_directory\n",
    "\n",
    "# Get the current working directory\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# Specify the number of levels to navigate up (4 levels in this case)\n",
    "levels_to_navigate = 4\n",
    "\n",
    "# Navigate up 'levels_to_navigate' folders\n",
    "parent_directory = navigate_up(current_directory, levels_to_navigate)\n",
    "\n",
    "# Define the path to the data file\n",
    "file_path = os.path.join(parent_directory, 'newspaper_data', 'sample_1percent.csv')\n",
    "\n",
    "# Now you can open and read the CSV file using pandas\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f8a58d5f-caf5-44c4-aff5-bd7fbd6e4f7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Similarity_Score</th>\n",
       "      <th>Text1</th>\n",
       "      <th>Text2</th>\n",
       "      <th>Group</th>\n",
       "      <th>Date1</th>\n",
       "      <th>Date2</th>\n",
       "      <th>Publisher1</th>\n",
       "      <th>Publisher2</th>\n",
       "      <th>ID1</th>\n",
       "      <th>ID2</th>\n",
       "      <th>proper_nouns1</th>\n",
       "      <th>proper_nouns2</th>\n",
       "      <th>keywords1</th>\n",
       "      <th>keywords2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.777635</td>\n",
       "      <td>Een sterkere EU graag, maar nu is dat even bij...</td>\n",
       "      <td>En toch is Rutte erbij in verkiezingsdebat van...</td>\n",
       "      <td>high</td>\n",
       "      <td>2021-03-01 00:00:00</td>\n",
       "      <td>2021-03-01 00:00:00</td>\n",
       "      <td>Trouw</td>\n",
       "      <td>De Volkskrant</td>\n",
       "      <td>3285325</td>\n",
       "      <td>3285230</td>\n",
       "      <td>PVV, D66, VVD</td>\n",
       "      <td>WNL, CDA'er Pieter Omtzigt, Tamara van Ark, Je...</td>\n",
       "      <td>['bikkelharde', 'mondkapjes', 'europese', 'opr...</td>\n",
       "      <td>['oneliners', 'ludieke', 'omtzigt', 'pitbull',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.772102</td>\n",
       "      <td>Makers van vaccins redden de mens, niet de bel...</td>\n",
       "      <td>Een vraag van een slachtoffer van de toeslagen...</td>\n",
       "      <td>high</td>\n",
       "      <td>2021-02-28 00:00:00</td>\n",
       "      <td>2021-02-28 22:15:58</td>\n",
       "      <td>Het Financieele Dagblad</td>\n",
       "      <td>NOS liveblog</td>\n",
       "      <td>3290697</td>\n",
       "      <td>3287475</td>\n",
       "      <td>Makers van vaccins redden de mens, Martin Shkr...</td>\n",
       "      <td>Kristie, Jullie, Kristie, Jullie</td>\n",
       "      <td>['farmaceut', 'dwanglicenties', 'pharmaceutica...</td>\n",
       "      <td>['toeslagenaffaire', 'schandvlek', 'kristie', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.866637</td>\n",
       "      <td>Opstand begin van corona-uitbraak; Opstand beg...</td>\n",
       "      <td>Europese Volt rekent op een  zetel in Den Haag...</td>\n",
       "      <td>high</td>\n",
       "      <td>2021-03-01 00:00:00</td>\n",
       "      <td>2021-03-01 00:00:00</td>\n",
       "      <td>De Telegraaf</td>\n",
       "      <td>NRC Handelsblad</td>\n",
       "      <td>3286378</td>\n",
       "      <td>3285633</td>\n",
       "      <td>Opstand, Ter Apel, FNV, Sander Dekker, PI, Ter...</td>\n",
       "      <td>Europese Volt, Volt, Jan Boekestijn, Sander Sc...</td>\n",
       "      <td>['indigd', 'coronavirus', 'sander', 'bajes', '...</td>\n",
       "      <td>['grensoverschrijdende', 'schimmelpenninck', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.833621</td>\n",
       "      <td>Economen: hogere belastingen jagen bedrijven w...</td>\n",
       "      <td>Meeste partijen willen hoger minimumloon, maar...</td>\n",
       "      <td>high</td>\n",
       "      <td>2021-03-01 00:00:00</td>\n",
       "      <td>2021-03-01 00:00:00</td>\n",
       "      <td>Het Financieele Dagblad</td>\n",
       "      <td>Het Financieele Dagblad</td>\n",
       "      <td>3290606</td>\n",
       "      <td>3290622</td>\n",
       "      <td>Economen, Jakob de Haan, VVD, Centraal Planbur...</td>\n",
       "      <td>VVD, CDA, D66, ChristenUnie, CDA, SP, VVD, Gro...</td>\n",
       "      <td>['verslechtert', 'vestigingsklimaat', 'verkiez...</td>\n",
       "      <td>['bijstandsuitkeringen', '50pluss', 'maandloon...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Similarity_Score                                              Text1  \\\n",
       "95          0.777635  Een sterkere EU graag, maar nu is dat even bij...   \n",
       "96          0.772102  Makers van vaccins redden de mens, niet de bel...   \n",
       "97          0.866637  Opstand begin van corona-uitbraak; Opstand beg...   \n",
       "98          0.833621  Economen: hogere belastingen jagen bedrijven w...   \n",
       "\n",
       "                                                Text2 Group  \\\n",
       "95  En toch is Rutte erbij in verkiezingsdebat van...  high   \n",
       "96  Een vraag van een slachtoffer van de toeslagen...  high   \n",
       "97  Europese Volt rekent op een  zetel in Den Haag...  high   \n",
       "98  Meeste partijen willen hoger minimumloon, maar...  high   \n",
       "\n",
       "                  Date1                Date2               Publisher1  \\\n",
       "95  2021-03-01 00:00:00  2021-03-01 00:00:00                    Trouw   \n",
       "96  2021-02-28 00:00:00  2021-02-28 22:15:58  Het Financieele Dagblad   \n",
       "97  2021-03-01 00:00:00  2021-03-01 00:00:00             De Telegraaf   \n",
       "98  2021-03-01 00:00:00  2021-03-01 00:00:00  Het Financieele Dagblad   \n",
       "\n",
       "                 Publisher2      ID1      ID2  \\\n",
       "95            De Volkskrant  3285325  3285230   \n",
       "96             NOS liveblog  3290697  3287475   \n",
       "97          NRC Handelsblad  3286378  3285633   \n",
       "98  Het Financieele Dagblad  3290606  3290622   \n",
       "\n",
       "                                        proper_nouns1  \\\n",
       "95                                      PVV, D66, VVD   \n",
       "96  Makers van vaccins redden de mens, Martin Shkr...   \n",
       "97  Opstand, Ter Apel, FNV, Sander Dekker, PI, Ter...   \n",
       "98  Economen, Jakob de Haan, VVD, Centraal Planbur...   \n",
       "\n",
       "                                        proper_nouns2  \\\n",
       "95  WNL, CDA'er Pieter Omtzigt, Tamara van Ark, Je...   \n",
       "96                   Kristie, Jullie, Kristie, Jullie   \n",
       "97  Europese Volt, Volt, Jan Boekestijn, Sander Sc...   \n",
       "98  VVD, CDA, D66, ChristenUnie, CDA, SP, VVD, Gro...   \n",
       "\n",
       "                                            keywords1  \\\n",
       "95  ['bikkelharde', 'mondkapjes', 'europese', 'opr...   \n",
       "96  ['farmaceut', 'dwanglicenties', 'pharmaceutica...   \n",
       "97  ['indigd', 'coronavirus', 'sander', 'bajes', '...   \n",
       "98  ['verslechtert', 'vestigingsklimaat', 'verkiez...   \n",
       "\n",
       "                                            keywords2  \n",
       "95  ['oneliners', 'ludieke', 'omtzigt', 'pitbull',...  \n",
       "96  ['toeslagenaffaire', 'schandvlek', 'kristie', ...  \n",
       "97  ['grensoverschrijdende', 'schimmelpenninck', '...  \n",
       "98  ['bijstandsuitkeringen', '50pluss', 'maandloon...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the DataFrame into 20 smaller DataFrames for the sake of fast tuning of prompting, each containing 5 rows\n",
    "chunk_size = 5\n",
    "chunks = [df.iloc[i:i+chunk_size] for i in range(0, len(df), chunk_size)]\n",
    "\n",
    "# Create variables for each smaller DataFrame\n",
    "for i, chunk in enumerate(chunks):\n",
    "    globals()[f'df{i + 1}'] = chunk\n",
    "\n",
    "# Now you have variables df1, df2, df3, ... containing the smaller DataFrames\n",
    "# You can access and work with them as needed\n",
    "df20\n",
    "#df2\n",
    "#....\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7223f53a-b58e-4f8b-8288-b7afc0989552",
   "metadata": {},
   "source": [
    "#  Prompting \n",
    "\n",
    "Prompting takes shapes in many sequetial instructions. We divide the prompts themselves into system prompt, example prompt, and main prompt to geenrate a template for each subtask. We begin with the broadest level, topic-level matching task. This task is also divided into three sepearate subtasks: (1) create topic labels for eacg text, (2) compare the topic labels and texts to decide to what extent they match, and (3) based on the explanation create a single classification topic match or no topic match. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0916b9e-02e6-4ed8-9994-f1067cf8f0b2",
   "metadata": {},
   "source": [
    "## Step 1: Extract topics. \n",
    "The prompt template is based on Grootendorst, BERTopic LLama2 implementation with example from our full dataset.\n",
    "* Important to note that for each step we pass in a system prompt, give and example, and provide a main prompt that signifies the variables and content to be considered.\n",
    "* Then we create a chain from the prompt for further sequential chaining with LangChain\n",
    "* Very important here to intially extract main topic and subtopic in order to obtain clear topics. If subtopics are not requested then the model might not understand that a topic that mentions politicians and conspiracy theories belongs to the broader topic of politics and instead it may label it as conspiracy theories alone. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e22ef277-6196-42ed-9f66-562bc5451c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the system prompt. It describes information given to all conversations\n",
    "# This system prompt will b\n",
    "system_prompt_1 = \"\"\"\n",
    "<s>[INST] <<SYS>>\n",
    "You are a helpful, respectful and honest assistant for labeling topics. A \"topic\" is a fundamental subject or theme that encompasses all aspects related to a particular area of interest or discussion. \n",
    "A topic serves as the overarching framework for exploring and discussing various facets within that subject. A topic comprises of a main topic and a subtopic. A main topic is an overarching theme, a subtopic is a more specific thematic or content-based divisions within a broader main topic. All main topics are labeled Politics if the documents' keywords and proper nouns relate to politics. For instance if the text discusses the economy but a politician, party, or government is mentioned either in the text or in the keywords then it should be categorized as Politics and not Economy. \\n\n",
    "Main topic: Politics; Subtopic: Elections and campaigns\n",
    "Main topic: Economy; Subtopic: Interest rates\n",
    "Main topic: Health; Subtopic: Mental health\n",
    "Main topic: Entertainment; Subtopic: Film and Television \\n\n",
    "\n",
    "If a text mentions politics, politicians names functions, partirs, policy, or any other politics-related term, the main topic should always be Politics.\\n\n",
    "\n",
    "\n",
    "You must always return a main topic and a subtopic and nothing else in the following format: Main topic1 : Subtopic;, Main topic2: Subtopic \\n\n",
    "Do not return any notes. Only return the label and nothing more for each text.\n",
    "\n",
    "<</SYS>>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7dfff572-4e5d-456c-a487-f3a5709fd042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example prompt demonstrating the output we are looking for\n",
    "example_prompt_1 = \"\"\"\n",
    "I have a document pair of the following texts:\\n\n",
    "- Contact met de kiezer; Deze keer zie je geen lijsttrekkers in windjacks rondlopen op markten. Kandidaat-Kamerleden moeten noodgedwongen online contact zoeken met de kiezers. Zoals de lijsttrekker van de ChristenUnie, Gert-Jan Segers, te zien is op de bovenstaande afbeelding terwijl hij vragen beantwoordt die kiezers hem stellen op het online platform Instagram. In plaats van direct met de burgers te praten, spreken politici nu voor de camera's. Livestreams op Facebook zijn ook populair. Zo had Mark Rutte dit weekend een gesprek met horeca-ondernemers en zond de VVD dat uit op Facebook. Naast de online campagne werd er dit weekend ook op de ouderwetse manier geflyerd. Maar de meeste campagnevoerende partijleden gingen niet aanbellen uit angst voor verdere verspreiding van het coronavirus. Forum voor Democratie was de enige partij die de straat op ging om campagne te voeren. Met een vrijheidskaravaan bezocht de partij Nijmegen en Venlo voor een manifestatie. Toen er meer dan tweehonderd mensen kwamen opdagen, moest burgemeester Hubert Bruls de bijeenkomst voortijdig beëindigen, hoewel deze wel was aangekondigd en aangevraagd. Een bezoeker in Venlo twitterde dat het centrale plein voor het eerst sinds carnaval vorig jaar weer vol stond met de komst van Baudet.\n",
    "- Forum voor Democratie op zoek naar extra stemmen; Terwijl andere partijen zich nauwelijks op straat vertonen, reist Forum voor Democratie stad en land af. Deze optredens trekken niet alleen de aandacht van kiezers; het Openbaar Ministerie onderzoekt nu ook of het campagneteam van Baudet de coronaregels op grote schaal heeft overtreden. Volgens getuigen werden bij een bezoek aan Urk honderden handen geschud. En dan was er nog de volmachtrel. In een live-uitzending riep Baudet zijn kijkers op om zoveel mogelijk volmachtstemmen te regelen, aangezien kiezers dit jaar niet twee, maar drie volmachtstemmen mogen uitbrengen om de kans op besmetting te verkleinen. \"Een persoon kan eigenlijk vier keer stemmen, als je maar die volmachten kunt regelen,\" zei Baudet, en dat was een enorme kans. Maar het ministerie van Binnenlandse Zaken zei: \"Ho, dat is niet de bedoeling en is niet toegestaan.\" Het campagneteam van Forum leek daar toen al achter te komen, want de suggestie om stemmen te regelen werd snel uit de video van Baudet geknipt. Baudet houdt echter wel openlijk vast aan zijn standpunt dat er een grote kans is op verkiezingsfraude, maar dan door anderen, uiteraard.\n",
    "\n",
    "The topic of each text is described by the following keywords: 'livesessies', 'vrijheidskaravaan', 'flyerende', 'facebook', 'windjacks'; besmettingskansen', 'volmachtsstemmen', 'schielijk', 'volmachten', 'baudets'\n",
    "The following proper nouns appear in each text: Gert-Jan Segers, Mark Rutte, Forum voor Democratie, Hubert Bruls, Baudet; Forum voor Democratie, Forum voor Democratie, Ministerie kijkt, Urk, Baudet, Baudet, Baudet, Baudet\n",
    "\n",
    "Based on the information about the topic above, please create a short label of the topic for each text. Only return the label and nothing more for each text in the following format:\n",
    "\n",
    "[/INST] Main topic 1: Politics; Subtopic: Elections and campaigns; Main topic 2: Politics; Subtopic: Elections, campaigns and fraud \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7c877972-294b-487f-9aac-ff6f219a8f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_prompt_1 = \"\"\"\n",
    "[INST]\n",
    "I have a document pair of the following texts:\n",
    "{text1} and {text2}\n",
    "\n",
    "The topic of each text is described by the following keywords: {keywords1} and {keywords2}\n",
    "The following proper nouns appear in each text: {proper_nouns1}, {proper_nouns2}\n",
    "\n",
    "Based on the information about the topic above, please create a short label of this topic for each text. Only return the label and nothing more for each text in the following format: Main topic 1 : Subtopic ; Main topic 2: Subtopic\n",
    "[/INST]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fc436448-e169-4fb8-8074-d545954cda23",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_1 = system_prompt_1 + example_prompt_1 + main_prompt_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "db37e1b9-405c-4f3b-b596-f74c31742551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a PromptTemplate instance\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"text1\", \"text2\", 'proper_nouns1', 'proper_nouns2', 'keywords1', 'keywords2'],\n",
    "    template=prompt_1\n",
    ")\n",
    "\n",
    "# Create the LLMChain instance\n",
    "chain_1 = LLMChain(llm = llm, prompt = prompt_template, output_key=\"topics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b27fe3f-2cf4-4b8e-8045-eb12d338dfdd",
   "metadata": {},
   "source": [
    "### Step 1.1: Extract main topic from topics for matching\n",
    "\n",
    "¶This is a must otherwise the chain considers subtopics as the level of match and disregards those that match on a broad level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8493b2e7-1417-4789-9d70-8407fe74c1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the system prompt. It describes information given to all conversations\n",
    "# This system prompt will b\n",
    "system_prompt_1_1 = \"\"\"\n",
    "<s>[INST] <<SYS>>\n",
    "You are a helpful, respectful and honest assistant for extracting the main topic from a topic. \n",
    "A topic comprises of a main topic and a subtopic. A main topic is an overarching theme, a subtopic is a more specific thematic or content-based divisions within a broader main topic.\n",
    "Main topic: Economy; Subtopic: Interest rates\n",
    "Main topic: Health; Subtopic: Mental health\n",
    "Main topic: Entertainment; Subtopic: Film and Television \n",
    "\n",
    "A main topic is everything before the word 'Subtopic'\n",
    "Given a topic, you must always return the main topic nothing else in the following format: Main topic1, Main topic2: \n",
    "Only return the main topic label and nothing more for each text.\n",
    "\n",
    "<</SYS>>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ce1fc52f-1630-44e0-9293-7710b0b4e2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example prompt demonstrating the output we are looking for\n",
    "example_prompt_1_1 = \"\"\"\n",
    "I have a pair of topics:\n",
    "Main topic 1: Politics; Subtopic: Elections and campaigns; \\n\n",
    "Main topic 2: Politics; Subtopic: Elections, campaigns and fraud \\n\n",
    "\n",
    "Based on the information about the topic above, please extract the main topic from each topic. A main topic is everything before the word 'Subtopic'. In this case this word is Politics. Only return the label of the main topic and nothing more in the following format:\n",
    "\n",
    "[/INST] Main topic 1: Politics; Main topic 2: Politics\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c5233e73-ba42-403b-92a2-df91a0f3b2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_prompt_1_1 = \"\"\"\n",
    "[INST]\n",
    "I have a pair of topics:\n",
    "{topics}\n",
    "\n",
    "Based on the information about the topic above, please extract the main topic from each topic. Only return the label of the main topic and nothing more in the following format:\n",
    "Main topic 1: ; Main topic 2: \n",
    "[/INST]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bec45d2e-f56a-400f-be92-ed91a4925e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_1_1 = system_prompt_1_1 + example_prompt_1_1 + main_prompt_1_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a51d9dbb-651f-4ee3-8bc8-8910c0baec4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a PromptTemplate instance\n",
    "prompt_template_1 = PromptTemplate(\n",
    "    input_variables=[\"topics\"],\n",
    "    template=prompt_1_1\n",
    ")\n",
    "\n",
    "# Create the LLMChain instance\n",
    "chain_1_1 = LLMChain(llm = llm, prompt = prompt_template_1, output_key=\"main_topic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c1fd05-4d0c-4a6b-a5ba-7d9b640c7ff2",
   "metadata": {},
   "source": [
    "## Step 2: Evaluate topic level match\n",
    "Compare the topics of the text pairs and made eveluation about the match level  \n",
    "\n",
    "* We create a second chain for this task that uses the texts as well as the extrcated topics as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d2e9a0db-7285-4a78-a12a-036c4a1f99a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the system prompt from the default one to a specific one in order to focus the model on a single task. \n",
    "# This system prompt will be\n",
    "system_prompt_2 = \"\"\"\n",
    "<s>[INST] <<SYS>>\n",
    "You are a helpful, respectful, and honest assistant for comparing the main topics of two texts. In this comparison, a match is solely based on the main topic and nothing else.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "711b57fe-e781-4578-8285-40a97fd56803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example prompt demonstrating the output we are looking for\n",
    "example_prompt_2 = \"\"\"\n",
    "\n",
    "The main topic of each text is described by the following labels:\n",
    "\n",
    "Main topic 1: Politics;  \n",
    "Main topic 2: Politics; \n",
    "\n",
    "\n",
    "Based on the information about the main topics above, please write a short evaluation about whether the two texts match on a main topic level. Make sure to only return the evaluation and nothing more in the following format:\n",
    "\n",
    "[/INST] Evaluation: Yes, the two texts match on a main topic level because both texts touch upon the broader context of Politics. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6b17947b-70af-4abd-9ba4-0084ea40bac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#main prompt describing the task once more and adding the input variables to be considered\n",
    "main_prompt_2 = \"\"\"\n",
    "[INST]\n",
    "\n",
    "The main topic of each text is the following: \n",
    "{main_topic}\n",
    "\n",
    "Based on the information about the topics above, please write a short evaluation about whether the two texts match on a main topic level. Make sure to only return the evaluation and nothing more in the following format:\n",
    "Evaluation:\n",
    "[/INST] \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "19600ef7-e635-461f-9e2c-dba231419966",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_2 = system_prompt_2 + example_prompt_2 + main_prompt_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d4dd2a0c-56c3-4d95-b348-b15a00689bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_2 = PromptTemplate(input_variables=[\"main_topic\"], template=prompt_2, batch_size=32, max_iterations = 1)\n",
    "chain_2 = LLMChain(llm = llm, prompt = prompt_template_2, output_key=\"topic_evaluation\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5940ddc7-73c3-41f7-a3d4-0dbdaf8dc334",
   "metadata": {},
   "source": [
    "## Step 3: Create classification label based on evaluation\n",
    "Provide single label for the match level\n",
    "\n",
    "* We create a third chain for this task that uses the texts as well as the extracted topics and evaluation as input.\n",
    "* Labels: topic match, not topic match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fecbc38c-b157-441f-a6f6-b682ef673a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the system prompt. It describes information given to all conversations\n",
    "# This system prompt will be\n",
    "system_prompt_3 = \"\"\"\n",
    "<s>[INST] <<SYS>>\n",
    "You are a helpful, respectful and honest assistant for classifying whether two texts match on a main topic level based on an evaluation provided. \n",
    "\n",
    "At each request excplicitly assign one of the two labels below. \n",
    "0 - no match\n",
    "1 - topic match\n",
    "\n",
    "Make sure you to only return the label and nothing else.\n",
    "<</SYS>>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "28398820-cab0-4adb-b95d-be13c983f317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example prompt demonstrating the output we are looking for\n",
    "example_prompt_3 = \"\"\"\n",
    "\n",
    "The following evaluation describes the topic match level:\n",
    "Yes, the two texts match on a main topic level. Both texts touch upon the broader context of Politics. \n",
    "Based on this information, please assign either '0 - no match' or '1 - topic match'. Make sure to only return the label and nothing more in the following format:\n",
    "\n",
    "[/INST]: 1 \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ea469ecd-17db-422d-ae07-f82c7b2cdf94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our main prompt with documents ([DOCUMENTS]) and keywords ([KEYWORDS]) tags\n",
    "main_prompt_3 = \"\"\"\n",
    "[INST]\n",
    "\n",
    "The following evaluation describes the topic match level:\n",
    "{topic_evaluation}\n",
    "\n",
    "Based on this information, please assign either '0 - no match' or '1 - topic match'. Make sure to only return the label and nothing more in the following format:\n",
    "[/INST] \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7b78d994-404d-43de-a5e2-12278ec47538",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_3 = system_prompt_3 + example_prompt_3 + main_prompt_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "83565f57-c842-4cb5-8be7-481b82c8cb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_3 = PromptTemplate(input_variables=[ \"topic_evaluation\"], template=prompt_3, batch_size=32, max_iterations = 1)\n",
    "chain_3 = LLMChain(llm = llm, prompt = prompt_template_3, output_key=\"match_topic\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334a661c-8dac-4a55-8cea-985a6172e43f",
   "metadata": {},
   "source": [
    "## Step 4: Identify news events\n",
    "* we ask the model the identify the news event described in each text\n",
    "* input data remains the same\n",
    "* this is in preparation of assessing news event level matching similar to topic level matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8ab4b2cc-a97a-4c4f-be0d-401b552e2126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the system prompt. It describes information given to all conversations\n",
    "# This system prompt will be\n",
    "system_prompt_4 = \"\"\"\n",
    "<s>[INST] <<SYS>>\n",
    "You are a helpful, respectful and honest assistant for idenitifying the news event described in a pair of documents. \n",
    "News events are specific events that lead to news coverage, such as a specific debate on a specific day in a specific parliament, a specific accident, or a specific football match. They can be covered by one or more articles in one or more outlets, but relate to one specific and identifiable event and are thus much more fine-grained than news topics, issues, or news categories.\n",
    "News events can span over multiple days but not more than 10 days. Therefore articles that cover the same news event are published within the same few hours and in the course of a few days. \n",
    "\n",
    "Provide your answer as an explanation in maximum 100 tokens. Make sure you to only return the news event identified and nothing else. Be very specific, name actors and places where possible. \n",
    "<</SYS>>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "fd766de4-6396-49c6-aec1-0c9695528c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example prompt demonstrating the output we are looking for\n",
    "example_prompt_4 = \"\"\"\n",
    "I have a document pair of the following texts:\n",
    "- Contact met de kiezer; Deze keer zie je geen lijsttrekkers in windjacks rondlopen op markten. Kandidaat-Kamerleden moeten noodgedwongen online contact zoeken met de kiezers. Zoals de lijsttrekker van de ChristenUnie, Gert-Jan Segers, te zien is op de bovenstaande afbeelding terwijl hij vragen beantwoordt die kiezers hem stellen op het online platform Instagram. In plaats van direct met de burgers te praten, spreken politici nu voor de camera's. Livestreams op Facebook zijn ook populair. Zo had Mark Rutte dit weekend een gesprek met horeca-ondernemers en zond de VVD dat uit op Facebook. Naast de online campagne werd er dit weekend ook op de ouderwetse manier geflyerd. Maar de meeste campagnevoerende partijleden gingen niet aanbellen uit angst voor verdere verspreiding van het coronavirus. Forum voor Democratie was de enige partij die de straat op ging om campagne te voeren. Met een vrijheidskaravaan bezocht de partij Nijmegen en Venlo voor een manifestatie. Toen er meer dan tweehonderd mensen kwamen opdagen, moest burgemeester Hubert Bruls de bijeenkomst voortijdig beëindigen, hoewel deze wel was aangekondigd en aangevraagd. Een bezoeker in Venlo twitterde dat het centrale plein voor het eerst sinds carnaval vorig jaar weer vol stond met de komst van Baudet.\n",
    "- Forum voor Democratie op zoek naar extra stemmen; Terwijl andere partijen zich nauwelijks op straat vertonen, reist Forum voor Democratie stad en land af. Deze optredens trekken niet alleen de aandacht van kiezers; het Openbaar Ministerie onderzoekt nu ook of het campagneteam van Baudet de coronaregels op grote schaal heeft overtreden. Volgens getuigen werden bij een bezoek aan Urk honderden handen geschud. En dan was er nog de volmachtrel. In een live-uitzending riep Baudet zijn kijkers op om zoveel mogelijk volmachtstemmen te regelen, aangezien kiezers dit jaar niet twee, maar drie volmachtstemmen mogen uitbrengen om de kans op besmetting te verkleinen. \"Een persoon kan eigenlijk vier keer stemmen, als je maar die volmachten kunt regelen,\" zei Baudet, en dat was een enorme kans. Maar het ministerie van Binnenlandse Zaken zei: \"Ho, dat is niet de bedoeling en is niet toegestaan.\" Het campagneteam van Forum leek daar toen al achter te komen, want de suggestie om stemmen te regelen werd snel uit de video van Baudet geknipt. Baudet houdt echter wel openlijk vast aan zijn standpunt dat er een grote kans is op verkiezingsfraude, maar dan door anderen, uiteraard.\\n\n",
    "\n",
    "The following keywords appear in each text: 'livesessies', 'vrijheidskaravaan', 'flyerende', 'facebook', 'windjacks'; besmettingskansen', 'volmachtsstemmen', 'schielijk', 'volmachten', 'baudets'\n",
    "The following proper nouns appear in each text: Gert-Jan Segers, Mark Rutte, Forum voor Democratie, Hubert Bruls, Baudet; Forum voor Democratie, Forum voor Democratie, Ministerie kijkt, Urk, Baudet, Baudet, Baudet, Baudet\n",
    "\n",
    "The topic of each text is the following:\n",
    "Main topic 1: Politics; Subtopic: Elections and campaigns; \\n\n",
    "Main topic 2: Politics; Subtopic: Elections, campaigns and fraud \\n\n",
    "\n",
    "Based on the information above, please identify the news events that describe the texts. Be as specific as possible. Make sure to only return the events and nothing more for each text in the following format:\n",
    "\n",
    "[/INST] Event 1: Most political parties are shifting their campaign activity stategies due to the COVID-19 pandemic; Event 2: Forum voor Democratie party's campaign activities violate COVID-19 regulations while other parties have more pandemic-proof startegies. \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "728dc550-3900-44bd-8060-4f2596dfb925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example prompt demonstrating the output we are looking for\n",
    "main_prompt_4 = \"\"\"\n",
    "\n",
    "I have a document pair of the following texts:\n",
    "{text1} and {text2}\n",
    "\n",
    "The following keywords appear in each text: {keywords1} and {keywords2}\n",
    "The following proper nouns appear in each text: {proper_nouns1}, {proper_nouns2}\n",
    "\n",
    "The topic of each text is the following:\n",
    "{topics}\n",
    "\n",
    "Based on the information above, please identify the news events that describe the texts. Make sure to only return the news events and nothing more in the following format:\n",
    "[/INST] \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2c2242af-37bc-4482-8748-f315ed60910b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_4 = system_prompt_4 + example_prompt_4 + main_prompt_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c376673a-c2c9-4712-96d8-88e5a1c0c6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_4 = PromptTemplate(input_variables=[\"text1\", \"text2\", \"proper_nouns1\", \"proper_nouns2\", 'keywords1', 'keywords2', \"topics\" ], template=prompt_4, batch_size=32, max_iterations = 1)\n",
    "chain_4 = LLMChain(llm = llm, prompt = prompt_template_4, output_key=\"news_events\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570ed895-7395-45da-86ee-57d2937d2a67",
   "metadata": {},
   "source": [
    "## Step 5: Evaluate news event level match\n",
    "\n",
    "* we ask the model to compare the news events identified on whether they match \n",
    "* input data remains the same plus the dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "285193cb-5e60-497a-8e52-04a74365da07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the system prompt. It describes information given to all conversations\n",
    "# This system prompt will be\n",
    "system_prompt_5 = \"\"\"\n",
    "<s>[INST] <<SYS>>\n",
    "You are a helpful, respectful and honest assistant for evaluating whether two texts pertain to the same news event.\n",
    "News events are comprised of specific events that lead to news coverage around a news story, such as a specific debate on a specific day in a specific parliament, a specific accident, or a specific football match. \\n\n",
    "They can be covered by one or more articles in one or more outlets, but relate to one specific and identifiable event and are thus much more fine-grained than news topics, issues, or news categories.\\n\n",
    "News events can span over multiple days but not more than 10 days. Therefore articles that cover the same news event are published very close in time, a matter of hours or maximum a few days. \n",
    "Different news events can also be published on the same date or on a very close date. \\n\n",
    "The most important criteria for determining whether the two texts pertain to the same news event are the events mentioned in the text. The date overlap is a secondary objective. \\n\n",
    "\n",
    "An event within a news event must refer to a specific event or related developments around the event. A news event can include various articles, reports, and updates from news outlets, all contributing to the coverage of that specific event or issue and its sorrounding aspects. \\n\n",
    "For example, the news event might revolve around the presidential election of a specific year, detailing campaign events, candidate profiles, polling data, and key issues.\n",
    "Provide your answer as an explanation in maximum 100 tokens. Make sure to only return the evaluation and nothing else.\n",
    "<</SYS>>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "2e7ade21-4985-470e-aa5d-d4e846854185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example prompt demonstrating the output we are looking for\n",
    "example_prompt_5 = \"\"\"\n",
    "\n",
    "The news events of each text is the following:\n",
    " Event 1: Most political parties are shifting their campaign activity stategies due to the COVID-19 pandemic; \\n\n",
    " Event 2: Forum voor Democratie party's campaign activities violate COVID-19 regulations while other parties have more pandemic-proof strategies. \\n\n",
    "\n",
    "The pubishing dates of the texts is the following:\\n\n",
    "date1: 01/03/2021; date2: 01/03/2021 \\n \n",
    "\n",
    "Based on the information above, please write a short evaluation about whether the two texts match on a news event level. Make sure to only return the evaluation and nothing more in the following format:\n",
    "\n",
    "[/INST] Evaluation: Both texts focus on one particular news event, the election campaign and party campaign activities amid the COVID-19 pandemic which is distintive event. Both texts discuss aspects of the same election campaign, political parties and campaign strategies during the pandemic indicating that they pertain to the same news event.\n",
    "The texts were also published at a similar time and date which further indicates that they belong to the same news event. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "53c114e2-b556-4280-aecf-b755377b6532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example prompt demonstrating the output we are looking for\n",
    "main_prompt_5 = \"\"\"\n",
    "\n",
    "The news events of each text is the following:\n",
    "{news_events}\n",
    "\n",
    "The pubishing dates of the texts is the following:\n",
    "{date1} and {date2}\n",
    "\n",
    "Based on the information above, please write a short evaluation about whether the two texts match on a news event level. Make sure to only return the evaluation and nothing more in the following format:\n",
    "[/INST] \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "91199987-0633-49a5-8335-34d85c093628",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_5 = system_prompt_5 + example_prompt_5 + main_prompt_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "5e77640b-d2e2-408c-81e7-1bae8c728739",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_5 = PromptTemplate(input_variables=[\"news_events\", \"date1\", \"date2\"], template=prompt_5, batch_size=32, max_iterations = 1)\n",
    "chain_5 = LLMChain(llm = llm, prompt = prompt_template_5, output_key=\"event_evaluation\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f26b118-3760-4295-afb0-31f080ff548d",
   "metadata": {},
   "source": [
    "## Step 6: Provide single label for news event level match\n",
    "\n",
    "* we use the evalution and the events to make a classication whether there is a match or no match on the news event level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b446524e-b4e0-4eea-9697-eb89c1063162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the system prompt. It describes information given to all conversations\n",
    "# This system prompt will be\n",
    "system_prompt_6 = \"\"\"\n",
    "<s>[INST] <<SYS>>\n",
    "You are a helpful, respectful and honest assistant for classifying whether two texts match on news event level based on an evaluation provided. \n",
    "\n",
    "At each request excplicitly assign one of the two labels below. \n",
    "0 - no match\n",
    "1 - event match\n",
    "\n",
    "Make sure you to only return the label and nothing else.\n",
    "<</SYS>>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f0eeb0-7850-49f3-bd4b-87492b1473b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example prompt demonstrating the output we are looking for\n",
    "example_prompt_6 = \"\"\"\n",
    "\n",
    "The following evaluation describes the news event match level:\n",
    "Both texts focus on one particular news event, the election campaign and party campaign activities amid the COVID-19 pandemic which is distintive event. Both texts discuss aspects of the same election campaign, political parties and campaign strategies during the pandemic indicating that they pertain to the same news event.\n",
    "The texts were also published at a similar time and date which further indicates that they belong to the same news event. \n",
    "Based on this information, please assign either '0 - no match' or '1 - topic match'. Make sure to only return the label and nothing more in the following format:\n",
    "\n",
    "[/INST]: 1 \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3561f2bb-f6f5-40a4-b718-310d4b1c4002",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1d8ff746-6bfc-42bc-87c5-9433a69ea2a6",
   "metadata": {},
   "source": [
    "## Create overall chain to combine previous chains into one big sequential chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "7042b2e6-4ea6-459b-80c7-e257878fce0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create overall chain to combine previous chains into one big sequential chain\n",
    "overall_chain = SequentialChain(\n",
    "                  chains=[chain_1, chain_1_1, chain_2, chain_3, chain_4, chain_5], input_variables = [\"text1\", \"text2\", \"proper_nouns1\", \"proper_nouns2\", 'keywords1', 'keywords2', 'date1', 'date2'],output_variables=[\"topics\", \"main_topic\", \"topic_evaluation\", \"match_topic\",\"news_events\",\"event_evaluation\" ],\n",
    "                  verbose=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "0958be2c-cb35-411d-9b6b-ecebb829a17f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'text1': 'Alle pijlen zijn gericht op Rutte in RTL-debat; Reportage verkiezingscampagne Alles op Rutte, dat is de stilzwijgende afspraak waaraan al diens opponenten zich in deze campagne tot dusver houden. Na het lijsttrekkersdebat van Radio 1 en het running mate-debat is ook het premiersdebat van RTL het eerste grote tv-debat van deze verkiezingen een meertrapsaanval op de minister-president, die graag aan zijn vierde termijn zou beginnen. De tactiek van de VVD tekent zich scherper af bouw zo min mogelijk profiel op, pareer aanvallen met verzoenende reacties en blijf dichtbij de kernboodschap gelieve de premier te koesteren die het land door de coronacrisis leidt. Een ruimte die hij pakt als het aan het eind van het debat over vaccinatiebewijzen gaat We moeten verstandig blijven. De politiek moet niet op de stoel van artsen en verpleegkundigen gaan zitten, zeggen Sigrid Kaag D66 en Jesse Klaver GroenLinks op de vraag of de gewone zorg weer voorrang moet krijgen. Zo nemen ze meteen afstand van VVD en CDA, die eerder voor code zwart waarschuwden, en daarmee voor triage. Rutte springt soepel bij hen achterop. Of je nog wel naar de icwilt, dat zijn heel tere afwegingen, zegt hij.', 'text2': 'Helft van de Forum-stemmers ziet complot; De helft van de mensen die op Forum voor Democratie FVD willen stemmen, denkt dat het coronavirus bewust is ontwikkeld om burgers wereldwijd te onderdrukken. 51 procent denkt dat corona een biologisch wapen is dat in een laboratorium is gefabriceerd. Dat komt naar voren uit onderzoek van Ipsos, in opdracht van Nieuwsuur. De opvattingen van FVD-kiezers over complottheori n wijken behoorlijk af van die van de gemiddelde Nederlander. Onder alle Nederlanders gelooft 11 procent dat het virus bewust is ontwikkeld en 13 procent dat het een biologisch wapen is.', 'proper_nouns1': 'Radio 1, RTL, VVD, kernboodschap gelieve, Sigrid, D66, Jesse Klaver, GroenLinks, VVD, CDA', 'proper_nouns2': 'Forum voor Democratie, Ipsos', 'keywords1': \"['lijsttrekkersdebat', 'premiersdebat', 'pareer', 'icwilt', 'meertrapsaanval']\", 'keywords2': \"['ipsos', 'coronavirus', 'gefabriceerd', 'complottheori', 'nieuwsuur']\", 'date1': '2021-03-01 00:00:00', 'date2': '2021-03-01 00:00:00', 'topics': '\\nMain topic 1: Politics; Subtopic: Elections and campaigns; Main topic 2: Politics; Subtopic: Conspiracy theories and misinformation\\n\\n', 'main_topic': '\\nMain topic 1: Politics; Main topic 2: Politics', 'topic_evaluation': '\\nEvaluation: Yes, the two texts match on a main topic level because they both address Politics.', 'match_topic': '\\n1', 'news_events': 'Event 1: The ongoing elections and campaigns in the Netherlands, specifically the debate between Prime Minister Mark Rutte and his opponents; Event 2: The spread of conspiracy theories and misinformation regarding the COVID-19 pandemic and its origins.', 'event_evaluation': 'Evaluation: Both texts do not pertain to the same news event. Text 1 covers the ongoing elections and campaigns in the Netherlands, specifically the debate between Prime Minister Mark Rutte and his opponents, while text 2 discusses the spread of conspiracy theories and misinformation regarding the COVID-19 pandemic and its origins. These are distinct and unrelated news events.\\n\\nTherefore, the two texts do not match on a news event level.'}\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'text1': 'Hoogste bestuursrechter liet forse steken vallen in affaire kinderopvangtoeslagen; De affaire rond de kinderopvangtoeslagen zal nog lang blijven nadreunen . Vorige week kwam de onderzoekscommissie onder leiding van Tweede Kamerlid Andr Bosman VVD tot de conclusie dat het tussen instanties aan vertrouwen ontbreekt. En na het eerdere parlementair onderzoek haalt de Tweede Kamer ook haar zwaarste middel, een echte parlementaire enqu te, uit de kast om in het schandaal de onderste steen boven te krijgen. Ondertussen wijst in Den Haag de ene overheidsinstantie naar de andere, om een schuldige van de ellende te benoemen. Zo ook de afdeling Bestuursrechtspraak van de Raad van State. Deze wijst, bij monde van voorzitter Bart Jan van Ettekoven, naar de wetgever, die hoofdverantwoordelijk zou zijn voor de affaire. In zijn kielzog stelt ook Herman Tjeenk Willink, voormalige vicepresident van de Raad van State, dat de Kamer als medewetgever zelf in de spiegel moet kijken. Zowel de Wet kinderopvang Wko als de Algemene wet inkomensafhankelijke regelingen Awir zouden zo dwingendrechtelijk zijn geformuleerd dat er voor de bestuursrechter geen ruimte was om te toetsen aan de beginselen van behoorlijk bestuur. Fundamentele uitgangspunten Zij behoren tot de fundamentele uitgangspunten van de rechtsstaat en gelden daarom onverkort.', 'text2': 'Stelling 3: Om de klimaatdoelen te halen moet Nederland nieuwe kerncentrales bouwen; Het gaat nu over het klimaat . Rutte zegt stellig We hebben echt kernenergie nodig. Want de wind waait niet altijd, de zon schijnt niet altijd en de VVD wil niet afhankelijk zijn van het gas van Poetin in Rusland. Rutte denkt aan een kerncentrale in Groningen.', 'proper_nouns1': 'Andr Bosman, VVD, Tweede Kamer, Raad van State, Bart Jan van Ettekoven, Herman Tjeenk Willink, Raad van State', 'proper_nouns2': 'VVD, Poetin', 'keywords1': \"['overheidsinstantie', 'kinderopvangtoeslagen', 'ettekoven', 'dwingendrechtelijk', 'tjeenk']\", 'keywords2': \"['klimaatdoelen', 'kerncentrales', 'rusland', 'waait', 'rutte']\", 'date1': '2021-02-28 00:00:00', 'date2': '2021-02-28 22:22:56', 'topics': '\\nMain topic 1: Politics; Subtopic: Government accountability and transparency\\nMain topic 2: Energy and Environment; Subtopic: Climate goals and nuclear energy', 'main_topic': '\\nMain topic 1: Politics; Main topic 2: Energy and Environment', 'topic_evaluation': '\\nEvaluation: No, the two texts do not match on a main topic level because one text focuses on Politics while the other text focuses on Energy and Environment.', 'match_topic': '\\n0', 'news_events': 'Event 1: Affair surrounding childcare allowances; Event 2: Proposal for new nuclear power plants to meet climate goals.', 'event_evaluation': 'Evaluation: The two texts do not match on a news event level. The first text discusses an affair surrounding childcare allowances, while the second text proposes new nuclear power plants to meet climate goals. These are two distinct and unrelated news events, and therefore, the texts do not pertain to the same news event.\\n\\n'}\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'text1': \"Planbureau: vertrek bedrijven reëel risico bij ambitieuze klimaatplannen; De scherpere milieuregels voor de industrie waarmee politieke partijen klimaatwinst hopen te boeken, leiden tot re le risico's dat bedrijven uit Nederland vertrekken. De mondiale broeikasgasuitstoot wordt dan nauwelijks minder. Daarvoor waarschuwt het Planbureau voor de Leefomgeving PBL maandag. De kans op dit zogeheten weglekeffect is het grootst bij de klimaatvoorstellen die de SP, GroenLinks, D66 en in mindere mate de PvdA doen, zegt het PBL. Bij de ChristenUnie en het CDA speelt dit risico minder. Het PBL heeft de verkiezingsprogramma's van deze politieke partijen geanalyseerd op effecten voor klimaat en milieu. De resultaten daarvan werden maandagochtend gepresenteerd. Het PBL rekent dit door op verzoek van de partijen zelf. De grote afwezige was de VVD, die het klimaatdeel van zijn partijprogramma niet liet doorrekenen. In industrie meeste klimaatwinst Uit de analyse blijkt dat alle politieke partijen grote klimaatwinst hopen te halen in de industri le sector. De vermeden uitstoot in 2030 is daar dan ook het grootst met 16 miljoen ton CO2 in de CDA-plannen tot 32 miljoen ton CO2 in de GroenLinks-plannen.\", 'text2': 'Baudet: corona niet bewust wereld in geslingerd; Het coronavirus is niet bewust de wereld in geslingerd . Dat zei Forum voor Democratie-voorman Thierry Baudet in het NOS Radio 1 Journaal, waar hij als eerste lijsttrekker te gast was in de verkiezingsreeks met interviews. Uit een peiling bleek afgelopen weekend dat ruim de helft van FvD-kiezers denkt dat het coronavirus bewust is ontwikkeld om burgers wereldwijd te onderdrukken. 51 procent denkt dat corona een biologisch wapen is dat in een laboratorium is gefabriceerd. Baudet deelt die opvatting dus niet, maar vindt het wel extreem toevallig dat het virus ontstaan is in de buurt van een Chinees laboratorium waar onderzoek werd gedaan naar virussen. Verder ziet Baudet dat corona gebruikt wordt door wereldleiders om maatregelen door te voeren op weg naar een wereldstaat. Het woord complot vindt hij in dat verband niet gek. Het wordt als scheldwoord gebruikt, maar betekent letterlijk dat er onderlinge afspraken gemaakt worden die je niet naar buiten brengt. Ingestonken Online beantwoordde Baudet in een live Q&A de vragen van kijkers. De FvD-leider zegt dat hij niet betoogt dat het virus niet bestaat. Hij noemt corona een stevige griep. Maar hij ontdekte dat corona niet het ebolavirus is.', 'proper_nouns1': 'Planbureau, Planbureau voor de Leefomgeving, PBL, SP, GroenLinks, D66, PvdA, PBL, ChristenUnie, CDA, PBL, PBL, VVD', 'proper_nouns2': 'Baudet, Forum voor Democratie-voorman Thierry Baudet, NOS, Radio 1 Journaal, FvD-kiezers, Baudet, Baudet, Baudet', 'keywords1': \"['broeikasgasuitstoot', 'klimaatwinst', 'leefomgeving', 'milieuregels', 'zogeheten']\", 'keywords2': \"['virussen', 'chinees', 'ebolavirus', 'ingestonken', 'coronavirus']\", 'date1': '2021-03-01 00:00:00', 'date2': '2021-03-01 10:34:06', 'topics': '\\nMain topic 1: Politics; Subtopic: Climate change and environmental policies\\nMain topic 2: Health; Subtopic: Coronavirus conspiracy theories', 'main_topic': '\\nMain topic 1: Politics; Main topic 2: Health', 'topic_evaluation': '\\nEvaluation: No, the two texts do not match on a main topic level because one text focuses on Politics while the other text focuses on Health.', 'match_topic': '\\n0', 'news_events': \"Event 1: Political parties' climate change and environmental policies are being analyzed by the Planbureau for their potential impact on the environment and industry; Event 2: Conspiracy theories surrounding the origin of the coronavirus are being discussed by Forum voor Democratie leader Thierry Baudet, with some believing it is a biological weapon created in a Chinese laboratory.\", 'event_evaluation': \"Evaluation: Both texts do not pertain to the same news event. Event 1 discusses political parties' climate change and environmental policies, while Event 2 discusses conspiracy theories surrounding the origin of the coronavirus. These are distinct and unrelated news events, and therefore, the texts do not match on a news event level.\\n\\n\"}\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'text1': \"Recht op reparatie van apparatuur komt steeds dichterbij; REPAIR CAF S Jeroen Groot en Caitlin Stooker Philip Leenman 68 wijst naar een Senseo. Het koffiezetapparaat van Philips staat in half gedemonteerde toestand op de werkbank in zijn werkkamer in Naarden. Voor het ongeoefende oog valt er weinig te zien aan het binnenste van het apparaat, maar Leenman weet precies wat er mis is. In dit geval betreft het de boiler om het water op temperatuur te brengen. Als het verwarmingselement wordt aangezet terwijl er geen water in zit, gaat het binnen zes seconden stuk, zegt de gepensioneerde ICT'er. Een kapot huishoudelijk apparaat belandt vaak bij het afval, omdat de kosten van reparatie door een professionele reparateur niet in verhouding staan tot de prijs van een nieuwe. Zonde, stelt het al in 2009 opgerichte Repair Caf. Hier zetten dan ook duizenden vrijwilligers zich in om huis-tuin-en-keukenspullen te repareren. Onder wie Leenman. Normaliter komen consumenten langs bij de Repair Caf s, waar vrijwilligers de kapotte spullen beoordelen en indien mogelijk ter plaatse repareren. Maar vanwege het coronavirus werken ook de reparateurs vanuit huis. Inmiddels zijn er in Nederland meer dan 500 Repair Caf s. Caf s, in 36 landen.\", 'text2': 'Niet een lijsttrekker, maar een kiezer brengt Mark Rutte bij RTL in het nauw; Eerste TV-Debat Het format van het verkiezingsdebat op RTL4 ontregelde premier Mark Rutte VVD, die normaliter sto cijns debatten voert.,Een tv-format kan een beslissende rol spelen in een lijsttrekkersdebat. Vooral demissionair premier Mark Rutte VVD zal die les geleerd hebben. De lijsttrekkers naast Rutte ook Geert Wilders PVV, Wopke Hoekstra CDA, Sigrid Kaag D66 , Lilian Marijnissen SP en Jesse Klaver GroenLinks moesten zondagavond in het RTL-debat niet alleen met elkaar in debat, maar ook met een kiezer. De lijsttrekkers kenden het onderwerp niet in het geval van Rutte was dat de Toeslagenaffaire. Ook wisten ze niet wie ze tegenover zich zouden krijgen. Rutte had tot dan toe een vrij eenvoudig debat. Hij kent zijn tegenstanders, debatteert zich behendig onder hun beschuldigingen uit, en gaat onbewogen door. Maar het gesprek met de kiezer had een totaal ander effect. Rutte werd tegenover Kristie Rongen geplaatst. Zij is gedupeerde in de Toeslagenaffaire, die had geleid tot de val van het derde kabinet-Rutte. Wij zaten als ratten in de val. U bent daar ook schuldig aan, zei ze. U niet.', 'proper_nouns1': 'REPAIR, CAF S Jeroen Groot, Philips, Leenman, Caf, Leenman, Repair Caf s, Caf s', 'proper_nouns2': 'Mark Rutte, RTL, Mark Rutte, Mark Rutte, Geert Wilders, PVV, Wopke Hoekstra, CDA, Sigrid, Lilian Marijnissen, SP, Jesse, GroenLinks, Kristie Rongen', 'keywords1': \"['verwarmingselement', 'reparateurs', 'koffiezetapparaat', 'reparateur', 'boiler']\", 'keywords2': \"['lijsttrekkersdebat', 'toeslagenaffaire', 'ontregelde', 'cijns', 'marijnissen']\", 'date1': '2021-03-01 00:00:00', 'date2': '2021-03-01 00:00:00', 'topics': '\\nMain topic 1: Politics; Subtopic: Elections and campaigns\\nMain topic 2: Society; Subtopic: Consumer rights and repairs', 'main_topic': '\\nMain topic 1: Politics; Main topic 2: Society', 'topic_evaluation': '\\nEvaluation: No, the two texts do not match on a main topic level because one text focuses on Politics while the other text focuses on Society.', 'match_topic': '\\n0', 'news_events': 'Event 1: The rise of Repair Cafes as an alternative to throwing away broken household items; Event 2: The impact of the Toeslagenaffaire on the elections and the debate between Mark Rutte and a affected citizen.', 'event_evaluation': 'Evaluation: The two texts do not match on a news event level. While both texts were published on the same date (March 1st, 2021), they do not share a common news event. The first text discusses the rise of Repair Cafes as an alternative to throwing away broken household items, while the second text covers the impact of the Toeslagenaffaire on the elections and a debate between Mark Rutte and a affected citizen. These are two distinct news events, and therefore, the two texts do not pertain to the same news event.'}\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'text1': 'Dode en gewonde door zuurstofexplosie corona-afdeling Oekraïne; In een ziekenhuis in Tsjernivtsi, in het westen van Oekra ne, zijn op de corona-afdeling een dode en een gewonde gevallen door een explosie. Een zuurstofleiding ontplofte, waarna er brand ontstond. Twintig mensen konden op tijd worden ge vacueerd. Het is het tweede soortgelijke incident in korte tijd in Oekra ne. Begin deze maand overleden een dokter en drie pati nten in Zaporizja, in het zuidoosten van Oekra ne, nadat er brand was ontstaan op een IC door een zuurstoflek.', 'text2': 'Wilders in de schijnwerpers; Wilders in de schijnwerpers Den Haag Wilders tegen de rest . Dat was zondagavond de teneur bij het verkiezingsdebat van RTL. Meerdere lijsttrekkers probeerden Mark Rutte VVD te vloeren nu die in de peilingen nog steeds fier aan kop staat. Dat lukte niet. Het was vooral Wilders die opviel. Zo wist hij Sigrid Kaag D66 op de kast te krijgen met een discussie over diversiteitsquota. Dat k n toch niet, riep ze uit toen Wilders zei dat hij niet houdt van dit soort quota, maar wel graag iemand van kleur wil nomineren voor de positie van minister van Cultuur, namelijk Zwarte Piet. GL er Jesse Klaver ging onderuit door te stellen dat Ronald Koeman nog bondscoach van Oranje is. Dat hij inmiddels allang bij FC Barcelona zit, was hem kennelijk ontgaan.', 'proper_nouns1': 'Oekra, Twintig, Oekra', 'proper_nouns2': 'Wilders, Mark Rutte, Sigrid Kaag D66, Wilders, Zwarte Piet, Jesse Klaver, Ronald Koeman, Oranje', 'keywords1': \"['tsjernivtsi', 'zaporizja', 'zuurstofexplosie', 'oekraïne', 'zuurstofleiding']\", 'keywords2': \"['diversiteitsquota', 'ronald', 'rtl', 'zit', 'wilders']\", 'date1': '2021-02-27 22:39:37', 'date2': '2021-03-01 00:00:00', 'topics': '\\nMain topic 1: Politics; Subtopic: International relations and conflicts; Main topic 2: Politics; Subtopic: Elections and debates', 'main_topic': '\\nMain topic 1: Politics; Main topic 2: Politics', 'topic_evaluation': '\\nEvaluation: Yes, the two texts match on a main topic level because they both address Politics.', 'match_topic': '\\n1', 'news_events': 'Event 1: Explosion at a hospital in Ukraine kills one person and injures another; Event 2: Geert Wilders participates in a televised election debate and engages in controversial statements.', 'event_evaluation': \"Evaluation: The two texts do not match on a news event level. The first text reports on an explosion at a hospital in Ukraine, while the second text covers Geert Wilders' participation in a televised election debate. These are two distinct and unrelated news events, and therefore, the texts do not pertain to the same news event.\\n\\n\"}\n"
     ]
    }
   ],
   "source": [
    "#this purely for tests\n",
    "\n",
    "\n",
    "for index, row in df2.iterrows():\n",
    "    full_text1 = row['Text1']  # Get the full text of Text1\n",
    "    full_text2 = row['Text2']  # Get the full text of Text2\n",
    "\n",
    "    input_variables = {\n",
    "        \"text1\": full_text1,\n",
    "        \"text2\": full_text2,\n",
    "        \"proper_nouns1\": row['proper_nouns1'],\n",
    "        \"proper_nouns2\": row['proper_nouns2'],\n",
    "        \"keywords1\": row['keywords1'],\n",
    "        \"keywords2\": row['keywords2'],\n",
    "        \"date1\":row['Date1'],\n",
    "        \"date2\":row['Date2']\n",
    "\n",
    "    }\n",
    "\n",
    "    # Generate text using the chain\n",
    "    \n",
    "    results = overall_chain(input_variables)\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d46bba-ffa5-4d1b-9365-4615cb191e19",
   "metadata": {},
   "source": [
    "### Run the overall chain and save the results into the df column\n",
    "\n",
    "this is to be modified based on all the new output variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b07da48-2d22-47a0-9da9-0bd9d8336f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty lists to collect the results\n",
    "topics = []\n",
    "topic_eval = []\n",
    "match_topic = []\n",
    "news_events = []\n",
    "event_eval = []\n",
    "match_event = []\n",
    "\n",
    "# Iterating over the DataFrame\n",
    "for index, row in df2.iterrows():\n",
    "    full_text1 = row['Text1']  # Get the full text of Text1\n",
    "    full_text2 = row['Text2']  # Get the full text of Text2\n",
    "\n",
    "    input_variables = {\n",
    "        \"text1\": full_text1,\n",
    "        \"text2\": full_text2,\n",
    "        \"proper_nouns1\": row['proper_nouns1'],\n",
    "        \"proper_nouns2\": row['proper_nouns2'],\n",
    "        \"keywords1\": row['keywords1'],\n",
    "        \"keywords2\": row['keywords2'],\n",
    "        \"date1\": row['Date1'],\n",
    "        \"date2\": row['Date2']\n",
    "    }\n",
    "\n",
    "    # Process the input_variables and get the results\n",
    "    results = overall_chain(input_variables)  # Assuming 'overall_chain' is your processing function\n",
    "\n",
    "    # Append results to respective lists\n",
    "    topics.append(results['topics'])\n",
    "    match_topic.append(results['match_topic'])\n",
    "    topic_eval.append(results['topic_evaluation'])\n",
    "    news_events.append(results['news_events'])\n",
    "    event_eval.append(results['event_evaluation'])\n",
    "    match_event.append(results['match_event'])\n",
    "\n",
    "# Add new columns to the DataFrame\n",
    "df2['Topic'] = topics\n",
    "df2['Topic_eval'] = topic_eval\n",
    "df2['Topic_match'] = match_topic\n",
    "df2['News_events'] = news_events\n",
    "df2['Event_eval'] = event_eval\n",
    "df2['Event_match'] = match_event"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python 3.10",
   "language": "python",
   "name": "python_3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
