{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dde61e5e-e9cc-4399-a8d5-048d00697c5a",
   "metadata": {},
   "source": [
    "# Llama 13b for validation task\n",
    "\n",
    "* input: dataframe with text pairs and additional info LLama 2 should use to make informed decision\n",
    "* output: dataframe with additional columns: topic, topic match evalutation, topic match classification, news event, news event match evaluation, news event match classification, final classification on topic-level and news event level matching\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c86ae2-8644-451b-855d-9a4625b6b94d",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "629e3acb-b512-4f07-bd44-ad67fa7d8e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from torch import cuda, bfloat16\n",
    "import transformers\n",
    "import pandas as pd\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chains import SequentialChain\n",
    "from transformers import pipeline\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96555da-98cc-426b-b3a6-517a3e6abe8f",
   "metadata": {},
   "source": [
    "## Load model through Huggingface pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cec9f8ed-1605-49f4-a9f1-0b4f356301ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/volume_2/python_3.10/lib/python3.10/site-packages/transformers/modeling_utils.py:2193: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec1880149c4e42cba102b4924509c224",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded on cuda:0\n"
     ]
    }
   ],
   "source": [
    "hf_auth_file = 'analysis/hf_auth.txt'\n",
    "\n",
    "# Read the API token from the file\n",
    "with open(hf_auth_file, \"r\") as file:\n",
    "    hf_auth = file.read().strip()  # Remove leading/trailing whitespaces\n",
    "\n",
    "\n",
    "model_id = 'meta-llama/Llama-2-13b-chat-hf'\n",
    "\n",
    "device = f'cuda:{cuda.current_device()}' if cuda.is_available() else 'cpu'\n",
    "\n",
    "# set quantization configuration to load large model with less GPU memory\n",
    "# this requires the `bitsandbytes` library\n",
    "bnb_config = transformers.BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type='nf4',\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=bfloat16\n",
    ")\n",
    "\n",
    "# begin initializing HF items, need auth token for these\n",
    "\n",
    "model_config = transformers.AutoConfig.from_pretrained(\n",
    "    model_id,\n",
    "    use_auth_token=hf_auth\n",
    ")\n",
    "\n",
    "model = transformers.AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    trust_remote_code=True,\n",
    "    config=model_config,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map='auto',\n",
    "    use_auth_token=hf_auth\n",
    ")\n",
    "model.eval()\n",
    "print(f\"Model loaded on {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "799a7a2f-9784-403d-9e23-71e6b2d1f7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
    "    model_id,\n",
    "    use_auth_token=hf_auth\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a4c1b09-5715-46e7-88eb-822b2b2fa4ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Name: NVIDIA A10\n",
      "Memory Usage: 3.559241771697998 GB\n",
      "Max Memory Usage: 3.604752540588379 GB\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda')\n",
    "print(\"GPU Name:\", torch.cuda.get_device_name(device))\n",
    "print(\"Memory Usage:\", torch.cuda.memory_allocated(device) / 1024 ** 3, \"GB\")\n",
    "print(\"Max Memory Usage:\", torch.cuda.max_memory_allocated(device) / 1024 ** 3, \"GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c404a3-5ee9-429e-9b64-1e1b4d60f72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.clear_autocast_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b54484da-e4b1-457b-8c36-8d50e6ee2bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_text = transformers.pipeline(\n",
    "    model=model, tokenizer=tokenizer,\n",
    "    return_full_text=True,  # langchain expects the full text\n",
    "    task='text-generation',\n",
    "    # we pass model parameters here too\n",
    "    temperature=0.0,  # 'randomness' of outputs, 0.0 is the min and 1.0 the max we do not want any randomness here as we want the model to stick to the prompt as closely as possible\n",
    "    max_new_tokens=512,  # max number of tokens to generate in the output\n",
    "    repetition_penalty=1.1  # without this output begins repeating\n",
    ")\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=generate_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f474429-5dd0-4991-9975-352fa8b0d7bc",
   "metadata": {},
   "source": [
    "### Read in file\n",
    "\n",
    "This is a file for prompt engineering that we devide into smaller samples for tuning our prompts. There are 100 rows in this data and we split them up into 20, 5 row dfs for quick testing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "455618db-c310-4aa4-a33c-85f30770ef86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to navigate up 'n' levels\n",
    "def navigate_up(current_directory, levels):\n",
    "    for _ in range(levels):\n",
    "        current_directory = os.path.dirname(current_directory)\n",
    "    return current_directory\n",
    "\n",
    "# Get the current working directory\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# Specify the number of levels to navigate up (4 levels in this case)\n",
    "levels_to_navigate = 4\n",
    "\n",
    "# Navigate up 'levels_to_navigate' folders\n",
    "parent_directory = navigate_up(current_directory, levels_to_navigate)\n",
    "\n",
    "# Define the path to the data file\n",
    "file_path = os.path.join(parent_directory, 'newspaper_data', 'sample_1percent.csv')\n",
    "\n",
    "# Now you can open and read the CSV file using pandas\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "f8a58d5f-caf5-44c4-aff5-bd7fbd6e4f7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Similarity_Score</th>\n",
       "      <th>Text1</th>\n",
       "      <th>Text2</th>\n",
       "      <th>Group</th>\n",
       "      <th>Date1</th>\n",
       "      <th>Date2</th>\n",
       "      <th>Publisher1</th>\n",
       "      <th>Publisher2</th>\n",
       "      <th>ID1</th>\n",
       "      <th>ID2</th>\n",
       "      <th>proper_nouns1</th>\n",
       "      <th>proper_nouns2</th>\n",
       "      <th>keywords1</th>\n",
       "      <th>keywords2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.765668</td>\n",
       "      <td>Alle pijlen zijn gericht op Rutte in RTL-debat...</td>\n",
       "      <td>Helft van de Forum-stemmers ziet complot; De h...</td>\n",
       "      <td>high</td>\n",
       "      <td>2021-03-01 00:00:00</td>\n",
       "      <td>2021-03-01 00:00:00</td>\n",
       "      <td>De Volkskrant</td>\n",
       "      <td>Trouw</td>\n",
       "      <td>3285226</td>\n",
       "      <td>3285337</td>\n",
       "      <td>Radio 1, RTL, VVD, kernboodschap gelieve, Sigr...</td>\n",
       "      <td>Forum voor Democratie, Ipsos</td>\n",
       "      <td>['lijsttrekkersdebat', 'premiersdebat', 'paree...</td>\n",
       "      <td>['ipsos', 'coronavirus', 'gefabriceerd', 'comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.683993</td>\n",
       "      <td>Hoogste bestuursrechter liet forse steken vall...</td>\n",
       "      <td>Stelling 3: Om de klimaatdoelen te halen moet ...</td>\n",
       "      <td>medium</td>\n",
       "      <td>2021-02-28 00:00:00</td>\n",
       "      <td>2021-02-28 22:22:56</td>\n",
       "      <td>Het Financieele Dagblad</td>\n",
       "      <td>NOS liveblog</td>\n",
       "      <td>3290695</td>\n",
       "      <td>3287474</td>\n",
       "      <td>Andr Bosman, VVD, Tweede Kamer, Raad van State...</td>\n",
       "      <td>VVD, Poetin</td>\n",
       "      <td>['overheidsinstantie', 'kinderopvangtoeslagen'...</td>\n",
       "      <td>['klimaatdoelen', 'kerncentrales', 'rusland', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.848039</td>\n",
       "      <td>Planbureau: vertrek bedrijven reëel risico bij...</td>\n",
       "      <td>Baudet: corona niet bewust wereld in geslinger...</td>\n",
       "      <td>high</td>\n",
       "      <td>2021-03-01 00:00:00</td>\n",
       "      <td>2021-03-01 10:34:06</td>\n",
       "      <td>Het Financieele Dagblad</td>\n",
       "      <td>NOS nieuws</td>\n",
       "      <td>3290604</td>\n",
       "      <td>6290556</td>\n",
       "      <td>Planbureau, Planbureau voor de Leefomgeving, P...</td>\n",
       "      <td>Baudet, Forum voor Democratie-voorman Thierry ...</td>\n",
       "      <td>['broeikasgasuitstoot', 'klimaatwinst', 'leefo...</td>\n",
       "      <td>['virussen', 'chinees', 'ebolavirus', 'ingesto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.805225</td>\n",
       "      <td>Recht op reparatie van apparatuur komt steeds ...</td>\n",
       "      <td>Niet een lijsttrekker, maar een kiezer brengt ...</td>\n",
       "      <td>high</td>\n",
       "      <td>2021-03-01 00:00:00</td>\n",
       "      <td>2021-03-01 00:00:00</td>\n",
       "      <td>Het Financieele Dagblad</td>\n",
       "      <td>NRC Handelsblad</td>\n",
       "      <td>3290567</td>\n",
       "      <td>3285627</td>\n",
       "      <td>REPAIR, CAF S Jeroen Groot, Philips, Leenman, ...</td>\n",
       "      <td>Mark Rutte, RTL, Mark Rutte, Mark Rutte, Geert...</td>\n",
       "      <td>['verwarmingselement', 'reparateurs', 'koffiez...</td>\n",
       "      <td>['lijsttrekkersdebat', 'toeslagenaffaire', 'on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.631177</td>\n",
       "      <td>Dode en gewonde door zuurstofexplosie corona-a...</td>\n",
       "      <td>Wilders in de schijnwerpers; Wilders in de sch...</td>\n",
       "      <td>medium</td>\n",
       "      <td>2021-02-27 22:39:37</td>\n",
       "      <td>2021-03-01 00:00:00</td>\n",
       "      <td>NOS liveblog</td>\n",
       "      <td>De Telegraaf</td>\n",
       "      <td>3287529</td>\n",
       "      <td>3286364</td>\n",
       "      <td>Oekra, Twintig, Oekra</td>\n",
       "      <td>Wilders, Mark Rutte, Sigrid Kaag D66, Wilders,...</td>\n",
       "      <td>['tsjernivtsi', 'zaporizja', 'zuurstofexplosie...</td>\n",
       "      <td>['diversiteitsquota', 'ronald', 'rtl', 'zit', ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Similarity_Score                                              Text1  \\\n",
       "5          0.765668  Alle pijlen zijn gericht op Rutte in RTL-debat...   \n",
       "6          0.683993  Hoogste bestuursrechter liet forse steken vall...   \n",
       "7          0.848039  Planbureau: vertrek bedrijven reëel risico bij...   \n",
       "8          0.805225  Recht op reparatie van apparatuur komt steeds ...   \n",
       "9          0.631177  Dode en gewonde door zuurstofexplosie corona-a...   \n",
       "\n",
       "                                               Text2   Group  \\\n",
       "5  Helft van de Forum-stemmers ziet complot; De h...    high   \n",
       "6  Stelling 3: Om de klimaatdoelen te halen moet ...  medium   \n",
       "7  Baudet: corona niet bewust wereld in geslinger...    high   \n",
       "8  Niet een lijsttrekker, maar een kiezer brengt ...    high   \n",
       "9  Wilders in de schijnwerpers; Wilders in de sch...  medium   \n",
       "\n",
       "                 Date1                Date2               Publisher1  \\\n",
       "5  2021-03-01 00:00:00  2021-03-01 00:00:00            De Volkskrant   \n",
       "6  2021-02-28 00:00:00  2021-02-28 22:22:56  Het Financieele Dagblad   \n",
       "7  2021-03-01 00:00:00  2021-03-01 10:34:06  Het Financieele Dagblad   \n",
       "8  2021-03-01 00:00:00  2021-03-01 00:00:00  Het Financieele Dagblad   \n",
       "9  2021-02-27 22:39:37  2021-03-01 00:00:00             NOS liveblog   \n",
       "\n",
       "        Publisher2      ID1      ID2  \\\n",
       "5            Trouw  3285226  3285337   \n",
       "6     NOS liveblog  3290695  3287474   \n",
       "7       NOS nieuws  3290604  6290556   \n",
       "8  NRC Handelsblad  3290567  3285627   \n",
       "9     De Telegraaf  3287529  3286364   \n",
       "\n",
       "                                       proper_nouns1  \\\n",
       "5  Radio 1, RTL, VVD, kernboodschap gelieve, Sigr...   \n",
       "6  Andr Bosman, VVD, Tweede Kamer, Raad van State...   \n",
       "7  Planbureau, Planbureau voor de Leefomgeving, P...   \n",
       "8  REPAIR, CAF S Jeroen Groot, Philips, Leenman, ...   \n",
       "9                              Oekra, Twintig, Oekra   \n",
       "\n",
       "                                       proper_nouns2  \\\n",
       "5                       Forum voor Democratie, Ipsos   \n",
       "6                                        VVD, Poetin   \n",
       "7  Baudet, Forum voor Democratie-voorman Thierry ...   \n",
       "8  Mark Rutte, RTL, Mark Rutte, Mark Rutte, Geert...   \n",
       "9  Wilders, Mark Rutte, Sigrid Kaag D66, Wilders,...   \n",
       "\n",
       "                                           keywords1  \\\n",
       "5  ['lijsttrekkersdebat', 'premiersdebat', 'paree...   \n",
       "6  ['overheidsinstantie', 'kinderopvangtoeslagen'...   \n",
       "7  ['broeikasgasuitstoot', 'klimaatwinst', 'leefo...   \n",
       "8  ['verwarmingselement', 'reparateurs', 'koffiez...   \n",
       "9  ['tsjernivtsi', 'zaporizja', 'zuurstofexplosie...   \n",
       "\n",
       "                                           keywords2  \n",
       "5  ['ipsos', 'coronavirus', 'gefabriceerd', 'comp...  \n",
       "6  ['klimaatdoelen', 'kerncentrales', 'rusland', ...  \n",
       "7  ['virussen', 'chinees', 'ebolavirus', 'ingesto...  \n",
       "8  ['lijsttrekkersdebat', 'toeslagenaffaire', 'on...  \n",
       "9  ['diversiteitsquota', 'ronald', 'rtl', 'zit', ...  "
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the DataFrame into 20 smaller DataFrames for the sake of fast tuning of prompting, each containing 5 rows\n",
    "chunk_size = 5\n",
    "chunks = [df.iloc[i:i+chunk_size] for i in range(0, len(df), chunk_size)]\n",
    "\n",
    "# Create variables for each smaller DataFrame\n",
    "for i, chunk in enumerate(chunks):\n",
    "    globals()[f'df{i + 1}'] = chunk\n",
    "\n",
    "# Now you have variables df1, df2, df3, ... containing the smaller DataFrames\n",
    "# You can access and work with them as needed\n",
    "df2\n",
    "#df2\n",
    "#....\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7223f53a-b58e-4f8b-8288-b7afc0989552",
   "metadata": {},
   "source": [
    "#  Prompting \n",
    "\n",
    "Prompting takes shapes in many sequetial instructions. We divide the prompts themselves into system prompt, example prompt, and main prompt to geenrate a template for each subtask. We begin with the broadest level, topic-level matching task. This task is also divided into three sepearate subtasks: (1) create topic labels for eacg text, (2) compare the topic labels and texts to decide to what extent they match, and (3) based on the explanation create a single classification topic match or no topic match. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0916b9e-02e6-4ed8-9994-f1067cf8f0b2",
   "metadata": {},
   "source": [
    "## Step 1: Extract topics. \n",
    "The prompt template is based on Grootendorst, BERTopic LLama2 implementation with example from our full dataset.\n",
    "* Important to note that for each step we pass in a system prompt, give and example, and provide a main prompt that signifies the variables and content to be considered.\n",
    "* Then we create a chain from the prompt for further sequential chaining with LangChain\n",
    "* Very important here to intially extract main topic and subtopic in order to obtain clear topics. If subtopics are not requested then the model might not understand that a topic that mentions politicians and conspiracy theories belongs to the broader topic of politics and instead it may label it as conspiracy theories alone. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e22ef277-6196-42ed-9f66-562bc5451c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the system prompt. It describes information given to all conversations\n",
    "# This system prompt will b\n",
    "system_prompt_1 = \"\"\"\n",
    "<s>[INST] <<SYS>>\n",
    "You are a helpful, respectful and honest assistant for labeling topics. A \"topic\" is a fundamental subject or theme that encompasses all aspects related to a particular area of interest or discussion. \n",
    "A topic serves as the overarching framework for exploring and discussing various facets within that subject. A topic comprises of a main topic and a subtopic. A main topic is an overarching theme, a subtopic is a more specific thematic or content-based divisions within a broader main topic. All main topics are labeled Politics if the documents' keywords and proper nouns relate to politics. For instance if the text discusses the economy but a politician, party, or government is mentioned either in the text or in the keywords then it should be categorized as Politics and not Economy. \\n\n",
    "Main topic: Politics; Subtopic: Elections and campaigns\n",
    "Main topic: Economy; Subtopic: Interest rates\n",
    "Main topic: Health; Subtopic: Mental health\n",
    "Main topic: Entertainment; Subtopic: Film and Television \\n\n",
    "\n",
    "If a text mentions politics, politicians names functions, partirs, policy, or any other politics-related term, the main topic should always be Politics.\\n\n",
    "\n",
    "\n",
    "You must always return a main topic and a subtopic and nothing else in the following format: Main topic1 : Subtopic;, Main topic2: Subtopic \\n\n",
    "Do not return any notes. Only return the label and nothing more for each text.\n",
    "\n",
    "<</SYS>>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7dfff572-4e5d-456c-a487-f3a5709fd042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example prompt demonstrating the output we are looking for\n",
    "example_prompt_1 = \"\"\"\n",
    "I have a document pair of the following texts:\\n\n",
    "- Contact met de kiezer; Deze keer zie je geen lijsttrekkers in windjacks rondlopen op markten. Kandidaat-Kamerleden moeten noodgedwongen online contact zoeken met de kiezers. Zoals de lijsttrekker van de ChristenUnie, Gert-Jan Segers, te zien is op de bovenstaande afbeelding terwijl hij vragen beantwoordt die kiezers hem stellen op het online platform Instagram. In plaats van direct met de burgers te praten, spreken politici nu voor de camera's. Livestreams op Facebook zijn ook populair. Zo had Mark Rutte dit weekend een gesprek met horeca-ondernemers en zond de VVD dat uit op Facebook. Naast de online campagne werd er dit weekend ook op de ouderwetse manier geflyerd. Maar de meeste campagnevoerende partijleden gingen niet aanbellen uit angst voor verdere verspreiding van het coronavirus. Forum voor Democratie was de enige partij die de straat op ging om campagne te voeren. Met een vrijheidskaravaan bezocht de partij Nijmegen en Venlo voor een manifestatie. Toen er meer dan tweehonderd mensen kwamen opdagen, moest burgemeester Hubert Bruls de bijeenkomst voortijdig beëindigen, hoewel deze wel was aangekondigd en aangevraagd. Een bezoeker in Venlo twitterde dat het centrale plein voor het eerst sinds carnaval vorig jaar weer vol stond met de komst van Baudet.\n",
    "- Forum voor Democratie op zoek naar extra stemmen; Terwijl andere partijen zich nauwelijks op straat vertonen, reist Forum voor Democratie stad en land af. Deze optredens trekken niet alleen de aandacht van kiezers; het Openbaar Ministerie onderzoekt nu ook of het campagneteam van Baudet de coronaregels op grote schaal heeft overtreden. Volgens getuigen werden bij een bezoek aan Urk honderden handen geschud. En dan was er nog de volmachtrel. In een live-uitzending riep Baudet zijn kijkers op om zoveel mogelijk volmachtstemmen te regelen, aangezien kiezers dit jaar niet twee, maar drie volmachtstemmen mogen uitbrengen om de kans op besmetting te verkleinen. \"Een persoon kan eigenlijk vier keer stemmen, als je maar die volmachten kunt regelen,\" zei Baudet, en dat was een enorme kans. Maar het ministerie van Binnenlandse Zaken zei: \"Ho, dat is niet de bedoeling en is niet toegestaan.\" Het campagneteam van Forum leek daar toen al achter te komen, want de suggestie om stemmen te regelen werd snel uit de video van Baudet geknipt. Baudet houdt echter wel openlijk vast aan zijn standpunt dat er een grote kans is op verkiezingsfraude, maar dan door anderen, uiteraard.\n",
    "\n",
    "The topic of each text is described by the following keywords: 'livesessies', 'vrijheidskaravaan', 'flyerende', 'facebook', 'windjacks'; besmettingskansen', 'volmachtsstemmen', 'schielijk', 'volmachten', 'baudets'\n",
    "The following proper nouns appear in each text: Gert-Jan Segers, Mark Rutte, Forum voor Democratie, Hubert Bruls, Baudet; Forum voor Democratie, Forum voor Democratie, Ministerie kijkt, Urk, Baudet, Baudet, Baudet, Baudet\n",
    "\n",
    "Based on the information about the topic above, please create a short label of the topic for each text. Only return the label and nothing more for each text in the following format:\n",
    "\n",
    "[/INST] Main topic 1: Politics; Subtopic: Elections and campaigns; Main topic 2: Politics; Subtopic: Elections, campaigns and fraud \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7c877972-294b-487f-9aac-ff6f219a8f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_prompt_1 = \"\"\"\n",
    "[INST]\n",
    "I have a document pair of the following texts:\n",
    "{text1} and {text2}\n",
    "\n",
    "The topic of each text is described by the following keywords: {keywords1} and {keywords2}\n",
    "The following proper nouns appear in each text: {proper_nouns1}, {proper_nouns2}\n",
    "\n",
    "Based on the information about the topic above, please create a short label of this topic for each text. Only return the label and nothing more for each text in the following format: Main topic 1 : Subtopic ; Main topic 2: Subtopic\n",
    "[/INST]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fc436448-e169-4fb8-8074-d545954cda23",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_1 = system_prompt_1 + example_prompt_1 + main_prompt_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "db37e1b9-405c-4f3b-b596-f74c31742551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a PromptTemplate instance\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"text1\", \"text2\", 'proper_nouns1', 'proper_nouns2', 'keywords1', 'keywords2'],\n",
    "    template=prompt_1\n",
    ")\n",
    "\n",
    "# Create the LLMChain instance\n",
    "chain_1 = LLMChain(llm = llm, prompt = prompt_template, output_key=\"topics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b27fe3f-2cf4-4b8e-8045-eb12d338dfdd",
   "metadata": {},
   "source": [
    "### Step 1.1: Extract main topic from topics for matching\n",
    "\n",
    "¶This is a must otherwise the chain considers subtopics as the level of match and disregards those that match on a broad level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8493b2e7-1417-4789-9d70-8407fe74c1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the system prompt. It describes information given to all conversations\n",
    "# This system prompt will b\n",
    "system_prompt_1_1 = \"\"\"\n",
    "<s>[INST] <<SYS>>\n",
    "You are a helpful, respectful and honest assistant for extracting the main topic from a topic. \n",
    "A topic comprises of a main topic and a subtopic. A main topic is an overarching theme, a subtopic is a more specific thematic or content-based divisions within a broader main topic.\n",
    "Main topic: Economy; Subtopic: Interest rates\n",
    "Main topic: Health; Subtopic: Mental health\n",
    "Main topic: Entertainment; Subtopic: Film and Television \n",
    "\n",
    "A main topic is everything before the word 'Subtopic'\n",
    "Given a topic, you must always return the main topic nothing else in the following format: Main topic1, Main topic2: \n",
    "Only return the main topic label and nothing more for each text.\n",
    "\n",
    "<</SYS>>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ce1fc52f-1630-44e0-9293-7710b0b4e2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example prompt demonstrating the output we are looking for\n",
    "example_prompt_1_1 = \"\"\"\n",
    "I have a pair of topics:\n",
    "Main topic 1: Politics; Subtopic: Elections and campaigns; \\n\n",
    "Main topic 2: Politics; Subtopic: Elections, campaigns and fraud \\n\n",
    "\n",
    "Based on the information about the topic above, please extract the main topic from each topic. A main topic is everything before the word 'Subtopic'. In this case this word is Politics. Only return the label of the main topic and nothing more in the following format:\n",
    "\n",
    "[/INST] Main topic 1: Politics; Main topic 2: Politics\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c5233e73-ba42-403b-92a2-df91a0f3b2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_prompt_1_1 = \"\"\"\n",
    "[INST]\n",
    "I have a pair of topics:\n",
    "{topics}\n",
    "\n",
    "Based on the information about the topic above, please extract the main topic from each topic. Only return the label of the main topic and nothing more in the following format:\n",
    "Main topic 1: ; Main topic 2: \n",
    "[/INST]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bec45d2e-f56a-400f-be92-ed91a4925e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_1_1 = system_prompt_1_1 + example_prompt_1_1 + main_prompt_1_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a51d9dbb-651f-4ee3-8bc8-8910c0baec4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a PromptTemplate instance\n",
    "prompt_template_1 = PromptTemplate(\n",
    "    input_variables=[\"topics\"],\n",
    "    template=prompt_1_1\n",
    ")\n",
    "\n",
    "# Create the LLMChain instance\n",
    "chain_1_1 = LLMChain(llm = llm, prompt = prompt_template_1, output_key=\"main_topic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c1fd05-4d0c-4a6b-a5ba-7d9b640c7ff2",
   "metadata": {},
   "source": [
    "## Step 2: Evaluate topic level match\n",
    "Compare the topics of the text pairs and made eveluation about the match level  \n",
    "\n",
    "* We create a second chain for this task that uses the texts as well as the extrcated topics as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d2e9a0db-7285-4a78-a12a-036c4a1f99a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the system prompt from the default one to a specific one in order to focus the model on a single task. \n",
    "# This system prompt will be\n",
    "system_prompt_2 = \"\"\"\n",
    "<s>[INST] <<SYS>>\n",
    "You are a helpful, respectful, and honest assistant for comparing the main topics of two texts. In this comparison, a match is solely based on the main topic and nothing else.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "711b57fe-e781-4578-8285-40a97fd56803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example prompt demonstrating the output we are looking for\n",
    "example_prompt_2 = \"\"\"\n",
    "\n",
    "The main topic of each text is described by the following labels:\n",
    "\n",
    "Main topic 1: Politics;  \n",
    "Main topic 2: Politics; \n",
    "\n",
    "\n",
    "Based on the information about the main topics above, please write a short evaluation about whether the two texts match on a main topic level. Make sure to only return the evaluation and nothing more in the following format:\n",
    "\n",
    "[/INST] Evaluation: Yes, the two texts match on a main topic level because both texts touch upon the broader context of Politics. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6b17947b-70af-4abd-9ba4-0084ea40bac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#main prompt describing the task once more and adding the input variables to be considered\n",
    "main_prompt_2 = \"\"\"\n",
    "[INST]\n",
    "\n",
    "The main topic of each text is the following: \n",
    "{main_topic}\n",
    "\n",
    "Based on the information about the topics above, please write a short evaluation about whether the two texts match on a main topic level. Make sure to only return the evaluation and nothing more in the following format:\n",
    "Evaluation:\n",
    "[/INST] \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "19600ef7-e635-461f-9e2c-dba231419966",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_2 = system_prompt_2 + example_prompt_2 + main_prompt_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d4dd2a0c-56c3-4d95-b348-b15a00689bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_2 = PromptTemplate(input_variables=[\"main_topic\"], template=prompt_2, batch_size=32, max_iterations = 1)\n",
    "chain_2 = LLMChain(llm = llm, prompt = prompt_template_2, output_key=\"topic_evaluation\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5940ddc7-73c3-41f7-a3d4-0dbdaf8dc334",
   "metadata": {},
   "source": [
    "## Step 3: Create classification label based on evaluation\n",
    "Provide single label for the match level\n",
    "\n",
    "* We create a third chain for this task that uses the texts as well as the extracted topics and evaluation as input.\n",
    "* Labels: topic match, not topic match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fecbc38c-b157-441f-a6f6-b682ef673a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the system prompt. It describes information given to all conversations\n",
    "# This system prompt will be\n",
    "system_prompt_3 = \"\"\"\n",
    "<s>[INST] <<SYS>>\n",
    "You are a helpful, respectful and honest assistant for classifying whether two texts match on a main topic level based on an evaluation provided. \n",
    "\n",
    "At each request excplicitly assign one of the two labels below. \n",
    "0 - no match\n",
    "1 - topic match\n",
    "\n",
    "Make sure you to only return the label and nothing else.\n",
    "<</SYS>>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "28398820-cab0-4adb-b95d-be13c983f317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example prompt demonstrating the output we are looking for\n",
    "example_prompt_3 = \"\"\"\n",
    "\n",
    "The following evaluation describes the topic match level:\n",
    "Yes, the two texts match on a main topic level. Both texts touch upon the broader context of Politics. \n",
    "Based on this information, please assign either '0 - no match' or '1 - topic match'. Make sure to only return the label and nothing more in the following format:\n",
    "\n",
    "[/INST]: 1 \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ea469ecd-17db-422d-ae07-f82c7b2cdf94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our main prompt with documents ([DOCUMENTS]) and keywords ([KEYWORDS]) tags\n",
    "main_prompt_3 = \"\"\"\n",
    "[INST]\n",
    "\n",
    "The following evaluation describes the topic match level:\n",
    "{topic_evaluation}\n",
    "\n",
    "Based on this information, please assign either '0 - no match' or '1 - topic match'. Make sure to only return the label and nothing more in the following format:\n",
    "[/INST] \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7b78d994-404d-43de-a5e2-12278ec47538",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_3 = system_prompt_3 + example_prompt_3 + main_prompt_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "83565f57-c842-4cb5-8be7-481b82c8cb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_3 = PromptTemplate(input_variables=[ \"topic_evaluation\"], template=prompt_3, batch_size=32, max_iterations = 1)\n",
    "chain_3 = LLMChain(llm = llm, prompt = prompt_template_3, output_key=\"match_topic\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334a661c-8dac-4a55-8cea-985a6172e43f",
   "metadata": {},
   "source": [
    "## Step 4: Identify news events\n",
    "* we ask the model the identify the news event described in each text\n",
    "* input data remains the same\n",
    "* this is in preparation of assessing news event level matching similar to topic level matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8ab4b2cc-a97a-4c4f-be0d-401b552e2126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the system prompt. It describes information given to all conversations\n",
    "# This system prompt will be\n",
    "system_prompt_4 = \"\"\"\n",
    "<s>[INST] <<SYS>>\n",
    "You are a helpful, respectful and honest assistant for idenitifying the news event described in a pair of documents. \n",
    "News events are specific events that lead to news coverage, such as a specific debate on a specific day in a specific parliament, a specific accident, or a specific football match. They can be covered by one or more articles in one or more outlets, but relate to one specific and identifiable event and are thus much more fine-grained than news topics, issues, or news categories.\n",
    "News events can span over multiple days but not more than 10 days. Therefore articles that cover the same news event are published within the same few hours and in the course of a few days. \n",
    "\n",
    "Provide your answer as an explanation in maximum 100 tokens. Make sure you to only return the news event identified and nothing else. Be very specific, name actors and places where possible. \n",
    "<</SYS>>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "fd766de4-6396-49c6-aec1-0c9695528c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example prompt demonstrating the output we are looking for\n",
    "example_prompt_4 = \"\"\"\n",
    "I have a document pair of the following texts:\n",
    "- Contact met de kiezer; Deze keer zie je geen lijsttrekkers in windjacks rondlopen op markten. Kandidaat-Kamerleden moeten noodgedwongen online contact zoeken met de kiezers. Zoals de lijsttrekker van de ChristenUnie, Gert-Jan Segers, te zien is op de bovenstaande afbeelding terwijl hij vragen beantwoordt die kiezers hem stellen op het online platform Instagram. In plaats van direct met de burgers te praten, spreken politici nu voor de camera's. Livestreams op Facebook zijn ook populair. Zo had Mark Rutte dit weekend een gesprek met horeca-ondernemers en zond de VVD dat uit op Facebook. Naast de online campagne werd er dit weekend ook op de ouderwetse manier geflyerd. Maar de meeste campagnevoerende partijleden gingen niet aanbellen uit angst voor verdere verspreiding van het coronavirus. Forum voor Democratie was de enige partij die de straat op ging om campagne te voeren. Met een vrijheidskaravaan bezocht de partij Nijmegen en Venlo voor een manifestatie. Toen er meer dan tweehonderd mensen kwamen opdagen, moest burgemeester Hubert Bruls de bijeenkomst voortijdig beëindigen, hoewel deze wel was aangekondigd en aangevraagd. Een bezoeker in Venlo twitterde dat het centrale plein voor het eerst sinds carnaval vorig jaar weer vol stond met de komst van Baudet.\n",
    "- Forum voor Democratie op zoek naar extra stemmen; Terwijl andere partijen zich nauwelijks op straat vertonen, reist Forum voor Democratie stad en land af. Deze optredens trekken niet alleen de aandacht van kiezers; het Openbaar Ministerie onderzoekt nu ook of het campagneteam van Baudet de coronaregels op grote schaal heeft overtreden. Volgens getuigen werden bij een bezoek aan Urk honderden handen geschud. En dan was er nog de volmachtrel. In een live-uitzending riep Baudet zijn kijkers op om zoveel mogelijk volmachtstemmen te regelen, aangezien kiezers dit jaar niet twee, maar drie volmachtstemmen mogen uitbrengen om de kans op besmetting te verkleinen. \"Een persoon kan eigenlijk vier keer stemmen, als je maar die volmachten kunt regelen,\" zei Baudet, en dat was een enorme kans. Maar het ministerie van Binnenlandse Zaken zei: \"Ho, dat is niet de bedoeling en is niet toegestaan.\" Het campagneteam van Forum leek daar toen al achter te komen, want de suggestie om stemmen te regelen werd snel uit de video van Baudet geknipt. Baudet houdt echter wel openlijk vast aan zijn standpunt dat er een grote kans is op verkiezingsfraude, maar dan door anderen, uiteraard.\\n\n",
    "\n",
    "The following keywords appear in each text: 'livesessies', 'vrijheidskaravaan', 'flyerende', 'facebook', 'windjacks'; besmettingskansen', 'volmachtsstemmen', 'schielijk', 'volmachten', 'baudets'\n",
    "The following proper nouns appear in each text: Gert-Jan Segers, Mark Rutte, Forum voor Democratie, Hubert Bruls, Baudet; Forum voor Democratie, Forum voor Democratie, Ministerie kijkt, Urk, Baudet, Baudet, Baudet, Baudet\n",
    "\n",
    "The topic of each text is the following:\n",
    "Main topic 1: Politics; Subtopic: Elections and campaigns; \\n\n",
    "Main topic 2: Politics; Subtopic: Elections, campaigns and fraud \\n\n",
    "\n",
    "Based on the information above, please identify the news events that describe the texts. Be as specific as possible. Make sure to only return the events and nothing more for each text in the following format:\n",
    "\n",
    "[/INST] Event 1: Most political parties are shifting their campaign activity stategies due to the COVID-19 pandemic; Event 2: Forum voor Democratie party's campaign activities violate COVID-19 regulations while other parties have more pandemic-proof startegies. \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "728dc550-3900-44bd-8060-4f2596dfb925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example prompt demonstrating the output we are looking for\n",
    "main_prompt_4 = \"\"\"\n",
    "\n",
    "I have a document pair of the following texts:\n",
    "{text1} and {text2}\n",
    "\n",
    "The following keywords appear in each text: {keywords1} and {keywords2}\n",
    "The following proper nouns appear in each text: {proper_nouns1}, {proper_nouns2}\n",
    "\n",
    "The topic of each text is the following:\n",
    "{topics}\n",
    "\n",
    "Based on the information above, please identify the news events that describe the texts. Make sure to only return the news events and nothing more in the following format:\n",
    "[/INST] \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2c2242af-37bc-4482-8748-f315ed60910b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_4 = system_prompt_4 + example_prompt_4 + main_prompt_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c376673a-c2c9-4712-96d8-88e5a1c0c6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_4 = PromptTemplate(input_variables=[\"text1\", \"text2\", \"proper_nouns1\", \"proper_nouns2\", 'keywords1', 'keywords2', \"topics\" ], template=prompt_4, batch_size=32, max_iterations = 1)\n",
    "chain_4 = LLMChain(llm = llm, prompt = prompt_template_4, output_key=\"news_events\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570ed895-7395-45da-86ee-57d2937d2a67",
   "metadata": {},
   "source": [
    "## Step 5: Evaluate news event level match\n",
    "\n",
    "* we ask the model to compare the news events identified on whether they match \n",
    "* input data remains the same plus the dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "285193cb-5e60-497a-8e52-04a74365da07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the system prompt. It describes information given to all conversations\n",
    "# This system prompt will be\n",
    "system_prompt_5 = \"\"\"\n",
    "<s>[INST] <<SYS>>\n",
    "You are a helpful, respectful and honest assistant for evaluating whether two texts pertain to the same news event.\n",
    "News events are comprised of specific events that lead to news coverage around a news story, such as a specific debate on a specific day in a specific parliament, a specific accident, or a specific football match. \\n\n",
    "They can be covered by one or more articles in one or more outlets, but relate to one specific and identifiable event and are thus much more fine-grained than news topics, issues, or news categories.\\n\n",
    "News events can span over multiple days but not more than 10 days. Therefore articles that cover the same news event are published very close in time, a matter of hours or maximum a few days. \n",
    "Different news events can also be published on the same date or on a very close date. \\n\n",
    "The most important criteria for determining whether the two texts pertain to the same news event are the events mentioned in the text. The date overlap is a secondary objective. \\n\n",
    "\n",
    "An event within a news event must refer to a specific event or related developments around the event. A news event can include various articles, reports, and updates from news outlets, all contributing to the coverage of that specific event or issue and its sorrounding aspects. \\n\n",
    "For example, the news event might revolve around the presidential election of a specific year, detailing campaign events, candidate profiles, polling data, and key issues.\n",
    "Provide your answer as an explanation in maximum 100 tokens. Make sure to only return the evaluation and nothing else.\n",
    "<</SYS>>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "2e7ade21-4985-470e-aa5d-d4e846854185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example prompt demonstrating the output we are looking for\n",
    "example_prompt_5 = \"\"\"\n",
    "\n",
    "The news events of each text is the following:\n",
    " Event 1: Most political parties are shifting their campaign activity stategies due to the COVID-19 pandemic; \\n\n",
    " Event 2: Forum voor Democratie party's campaign activities violate COVID-19 regulations while other parties have more pandemic-proof strategies. \\n\n",
    "\n",
    "The pubishing dates of the texts is the following:\\n\n",
    "date1: 01/03/2021; date2: 01/03/2021 \\n \n",
    "\n",
    "Based on the information above, please write a short evaluation about whether the two texts match on a news event level. Make sure to only return the evaluation and nothing more in the following format:\n",
    "\n",
    "[/INST] Evaluation: Both texts focus on one particular news event, the election campaign and party campaign activities amid the COVID-19 pandemic which is distintive event. Both texts discuss aspects of the same election campaign, political parties and campaign strategies during the pandemic indicating that they pertain to the same news event.\n",
    "The texts were also published at a similar time and date which further indicates that they belong to the same news event. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "53c114e2-b556-4280-aecf-b755377b6532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example prompt demonstrating the output we are looking for\n",
    "main_prompt_5 = \"\"\"\n",
    "\n",
    "The news events of each text is the following:\n",
    "{news_events}\n",
    "\n",
    "The pubishing dates of the texts is the following:\n",
    "{date1} and {date2}\n",
    "\n",
    "Based on the information above, please write a short evaluation about whether the two texts match on a news event level. Make sure to only return the evaluation and nothing more in the following format:\n",
    "[/INST] \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "91199987-0633-49a5-8335-34d85c093628",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_5 = system_prompt_5 + example_prompt_5 + main_prompt_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "5e77640b-d2e2-408c-81e7-1bae8c728739",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_5 = PromptTemplate(input_variables=[\"news_events\", \"date1\", \"date2\"], template=prompt_5, batch_size=32, max_iterations = 1)\n",
    "chain_5 = LLMChain(llm = llm, prompt = prompt_template_5, output_key=\"event_evaluation\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f26b118-3760-4295-afb0-31f080ff548d",
   "metadata": {},
   "source": [
    "## Step 6: Provide single label for news event level match\n",
    "\n",
    "* we use the evalution and the events to make a classication whether there is a match or no match on the news event level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "b446524e-b4e0-4eea-9697-eb89c1063162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the system prompt. It describes information given to all conversations\n",
    "# This system prompt will be\n",
    "system_prompt_6 = \"\"\"\n",
    "<s>[INST] <<SYS>>\n",
    "You are a helpful, respectful and honest assistant for classifying whether two texts match on news event level based on an evaluation provided. \n",
    "\n",
    "At each request excplicitly assign one of the two labels below. \n",
    "0 - no match\n",
    "1 - event match\n",
    "\n",
    "Make sure you to only return the label and nothing else.\n",
    "<</SYS>>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "51f0eeb0-7850-49f3-bd4b-87492b1473b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example prompt demonstrating the output we are looking for\n",
    "example_prompt_6 = \"\"\"\n",
    "\n",
    "The following evaluation describes the news event match level:\n",
    "Both texts focus on one particular news event, the election campaign and party campaign activities amid the COVID-19 pandemic which is distintive event. Both texts discuss aspects of the same election campaign, political parties and campaign strategies during the pandemic indicating that they pertain to the same news event.\n",
    "The texts were also published at a similar time and date which further indicates that they belong to the same news event. \n",
    "Based on this information, please assign either '0 - no match' or '1 - topic match'. Make sure to only return the label and nothing more in the following format:\n",
    "\n",
    "[/INST]: 1 \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "3561f2bb-f6f5-40a4-b718-310d4b1c4002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our main prompt with documents ([DOCUMENTS]) and keywords ([KEYWORDS]) tags\n",
    "main_prompt_6 = \"\"\"\n",
    "[INST]\n",
    "\n",
    "The following evaluation describes the news event match level:\n",
    "{event_evaluation}\n",
    "\n",
    "Based on this information, please assign either '0 - no match' or '1 -event match'. Make sure to only return the label and nothing more in the following format:\n",
    "[/INST] \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "ce8b7e06-7e4a-4d0e-bdcc-bce06c6a5b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_6 = system_prompt_6 + example_prompt_6 + main_prompt_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "c5139873-ecab-4728-ac18-92b46d9c005e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_6 = PromptTemplate(input_variables=[ \"event_evaluation\"], template=prompt_6, batch_size=32, max_iterations = 1)\n",
    "chain_6 = LLMChain(llm = llm, prompt = prompt_template_6, output_key=\"match_event\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8ff746-6bfc-42bc-87c5-9433a69ea2a6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Create overall chain to combine previous chains into one big sequential chain\n",
    "This is for testing purposes"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d0507421-abc7-4496-8171-0b6c2a344192",
   "metadata": {},
   "source": [
    "#create overall chain to combine previous chains into one big sequential chain\n",
    "overall_chain = SequentialChain(\n",
    "                  chains=[chain_1, chain_1_1, chain_2, chain_3, chain_4, chain_5, chain_6], input_variables = [\"text1\", \"text2\", \"proper_nouns1\", \"proper_nouns2\", 'keywords1', 'keywords2', 'date1', 'date2'],output_variables=[\"topics\", \"main_topic\", \"topic_evaluation\", \"match_topic\",\"news_events\",\"event_evaluation\", \"match_event\"],\n",
    "                  verbose=True )"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fc60016e-52cc-4f94-8f6a-c3081ee66aa0",
   "metadata": {},
   "source": [
    "#this purely for tests\n",
    "\n",
    "\n",
    "for index, row in df2.iterrows():\n",
    "    full_text1 = row['Text1']  # Get the full text of Text1\n",
    "    full_text2 = row['Text2']  # Get the full text of Text2\n",
    "\n",
    "    input_variables = {\n",
    "        \"text1\": full_text1,\n",
    "        \"text2\": full_text2,\n",
    "        \"proper_nouns1\": row['proper_nouns1'],\n",
    "        \"proper_nouns2\": row['proper_nouns2'],\n",
    "        \"keywords1\": row['keywords1'],\n",
    "        \"keywords2\": row['keywords2'],\n",
    "        \"date1\":row['Date1'],\n",
    "        \"date2\":row['Date2']\n",
    "\n",
    "    }\n",
    "\n",
    "    # Generate text using the chain\n",
    "    \n",
    "    results = overall_chain(input_variables)\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d46bba-ffa5-4d1b-9365-4615cb191e19",
   "metadata": {},
   "source": [
    "## Run the overall chain and save the results into the df column\n",
    "\n",
    "this is to be modified based on all the new output variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "9b07da48-2d22-47a0-9da9-0bd9d8336f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/volume_2/python_3.10/lib/python3.10/site-packages/transformers/pipelines/base.py:1083: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Create empty lists to collect the results\n",
    "pd.options.mode.chained_assignment = None  # Disable the warning (not recommended)\n",
    "topics = []\n",
    "topic_eval = []\n",
    "match_topic = []\n",
    "news_events = []\n",
    "event_eval = []\n",
    "match_event = []\n",
    "\n",
    "# Iterating over the DataFrame\n",
    "for index, row in df3.iterrows():\n",
    "    full_text1 = row['Text1']  # Get the full text of Text1\n",
    "    full_text2 = row['Text2']  # Get the full text of Text2\n",
    "\n",
    "    input_variables = {\n",
    "        \"text1\": full_text1,\n",
    "        \"text2\": full_text2,\n",
    "        \"proper_nouns1\": row['proper_nouns1'],\n",
    "        \"proper_nouns2\": row['proper_nouns2'],\n",
    "        \"keywords1\": row['keywords1'],\n",
    "        \"keywords2\": row['keywords2'],\n",
    "        \"date1\": row['Date1'],\n",
    "        \"date2\": row['Date2']\n",
    "    }\n",
    "\n",
    "    # Process the input_variables and get the results\n",
    "    results = overall_chain(input_variables)  # Assuming 'overall_chain' is your processing function\n",
    "\n",
    "    # Append results to respective lists\n",
    "    topics.append(results['topics'].strip())\n",
    "    match_topic.append(results['match_topic'].strip())\n",
    "    topic_eval.append(results['topic_evaluation'].strip())\n",
    "    news_events.append(results['news_events'].strip())\n",
    "    event_eval.append(results['event_evaluation'].strip())\n",
    "    match_event.append(results['match_event'].strip())\n",
    "\n",
    "# Add new columns to the DataFrame\n",
    "df3.loc[:,'Topic'] = topics\n",
    "df3.loc[:,'Topic_eval'] = topic_eval\n",
    "df3.loc[:,'Topic_match'] = match_topic\n",
    "df3.loc[:,'News_events'] = news_events\n",
    "df3.loc[:,'Event_eval'] = event_eval\n",
    "df3.loc[:,'Event_match'] = match_event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "f859ba5c-e4be-4d7d-9583-83e2fc09192e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Similarity_Score</th>\n",
       "      <th>Text1</th>\n",
       "      <th>Text2</th>\n",
       "      <th>Group</th>\n",
       "      <th>Date1</th>\n",
       "      <th>Date2</th>\n",
       "      <th>Publisher1</th>\n",
       "      <th>Publisher2</th>\n",
       "      <th>ID1</th>\n",
       "      <th>ID2</th>\n",
       "      <th>proper_nouns1</th>\n",
       "      <th>proper_nouns2</th>\n",
       "      <th>keywords1</th>\n",
       "      <th>keywords2</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Topic_eval</th>\n",
       "      <th>Topic_match</th>\n",
       "      <th>News_events</th>\n",
       "      <th>Event_eval</th>\n",
       "      <th>Event_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.789124</td>\n",
       "      <td>Haagse plannen: hoe de politiek de volgende pa...</td>\n",
       "      <td>Het geld van de gemeenten raakt op, en dat gaa...</td>\n",
       "      <td>high</td>\n",
       "      <td>2021-02-28 06:52:07</td>\n",
       "      <td>2021-03-01 00:00:00</td>\n",
       "      <td>NOS nieuws</td>\n",
       "      <td>NRC Handelsblad</td>\n",
       "      <td>3287522</td>\n",
       "      <td>3285637</td>\n",
       "      <td>Al, VVD, SP</td>\n",
       "      <td>Gemeentefinanci n Slechts, Johan Hamster, Financi</td>\n",
       "      <td>['testwattenstaafjes', 'strubbelingen', 'mondk...</td>\n",
       "      <td>['welzijnswerk', 'bezuinigt', '2024', 'zit', '...</td>\n",
       "      <td>Main topic 1: Politics; Subtopic: Elections an...</td>\n",
       "      <td>Evaluation: Yes, the two texts match on a main...</td>\n",
       "      <td>1</td>\n",
       "      <td>Event 1: Political parties prepare for future ...</td>\n",
       "      <td>Evaluation: Both texts do not pertain to the s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.785079</td>\n",
       "      <td>Ondernemers in de race voor de Tweede Kamer; E...</td>\n",
       "      <td>Na de doorrekeningen is iedere partij klimaatk...</td>\n",
       "      <td>high</td>\n",
       "      <td>2021-03-01 00:00:00</td>\n",
       "      <td>2021-03-01 00:00:00</td>\n",
       "      <td>Het Financieele Dagblad</td>\n",
       "      <td>Het Financieele Dagblad</td>\n",
       "      <td>3290668</td>\n",
       "      <td>3290580</td>\n",
       "      <td>Tweede Kamer, Tweede Kamer, Romke</td>\n",
       "      <td>D66'er, CDA, Jaco Geurts, Planbureau voor de L...</td>\n",
       "      <td>['ijsmaker', 'romke', 'volksvertegenwoordiger'...</td>\n",
       "      <td>['doorrekeningen', 'geurts', 'leefomgeving', '...</td>\n",
       "      <td>Main topic 1: Politics; Subtopic: Elections an...</td>\n",
       "      <td>Evaluation: No, the two texts do not match on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Event 1: Political parties are campaigning for...</td>\n",
       "      <td>Evaluation: Both texts pertain to the same new...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.866669</td>\n",
       "      <td>Een vraag van een slachtoffer van de toeslagen...</td>\n",
       "      <td>'Opvallend en veelzeggend dat VVD en CDA hier ...</td>\n",
       "      <td>high</td>\n",
       "      <td>2021-02-28 22:15:58</td>\n",
       "      <td>2021-03-01 13:15:24</td>\n",
       "      <td>NOS liveblog</td>\n",
       "      <td>NOS liveblog</td>\n",
       "      <td>3287475</td>\n",
       "      <td>3287398</td>\n",
       "      <td>Kristie, Jullie, Kristie, Jullie</td>\n",
       "      <td>CDA, CPB, PBL, CDA, CDA, Kamerlid Van Weyenber...</td>\n",
       "      <td>['toeslagenaffaire', 'schandvlek', 'kristie', ...</td>\n",
       "      <td>['rampspoed', 'doorrekeningen', 'reductie', 'o...</td>\n",
       "      <td>Main topic 1: Politics; Subtopic: Elections an...</td>\n",
       "      <td>Evaluation: Yes, the two texts match on a main...</td>\n",
       "      <td>1</td>\n",
       "      <td>Event 1: The toeslagenaffaire scandal and its ...</td>\n",
       "      <td>Evaluation: Both texts do not match on a news ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.711729</td>\n",
       "      <td>Ook Texel begonnen met vaccineren; Als laatste...</td>\n",
       "      <td>Excuses van de koning voor slavernij zijn onaf...</td>\n",
       "      <td>high</td>\n",
       "      <td>2021-02-27 17:37:33</td>\n",
       "      <td>2021-03-01 00:00:00</td>\n",
       "      <td>NOS liveblog</td>\n",
       "      <td>NRC Handelsblad</td>\n",
       "      <td>3287533</td>\n",
       "      <td>3285647</td>\n",
       "      <td>NH</td>\n",
       "      <td>Slavernijverleden Ruttes, Tineke Bennema</td>\n",
       "      <td>['gevaccineerd', 'vaccineren', 'waddeneiland',...</td>\n",
       "      <td>['onafwendbaar', 'ruttes', 'opofferen', 'slave...</td>\n",
       "      <td>Main topic 1: Health; Subtopic: Vaccination\\nM...</td>\n",
       "      <td>Evaluation: No, the two texts do not match on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Event 1: The start of vaccination on the Wadde...</td>\n",
       "      <td>Evaluation: The two texts do not match on a ne...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.881295</td>\n",
       "      <td>Forum voor Democratie Jacht  op extra stemmen;...</td>\n",
       "      <td>Baudet: corona niet bewust wereld in geslinger...</td>\n",
       "      <td>high</td>\n",
       "      <td>2021-03-01 00:00:00</td>\n",
       "      <td>2021-03-01 10:34:06</td>\n",
       "      <td>NRC Handelsblad</td>\n",
       "      <td>NOS nieuws</td>\n",
       "      <td>3285636</td>\n",
       "      <td>6290556</td>\n",
       "      <td>Forum voor Democratie, Forum voor Democratie, ...</td>\n",
       "      <td>Baudet, Forum voor Democratie-voorman Thierry ...</td>\n",
       "      <td>['besmettingskansen', 'volmachtsstemmen', 'sch...</td>\n",
       "      <td>['virussen', 'chinees', 'ebolavirus', 'ingesto...</td>\n",
       "      <td>Main topic 1: Politics; Subtopic: Elections an...</td>\n",
       "      <td>Evaluation: Yes, the two texts match on a main...</td>\n",
       "      <td>1</td>\n",
       "      <td>Event 1: Political party Forum voor Democratie...</td>\n",
       "      <td>Evaluation: Both texts pertain to the same new...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Similarity_Score                                              Text1  \\\n",
       "10          0.789124  Haagse plannen: hoe de politiek de volgende pa...   \n",
       "11          0.785079  Ondernemers in de race voor de Tweede Kamer; E...   \n",
       "12          0.866669  Een vraag van een slachtoffer van de toeslagen...   \n",
       "13          0.711729  Ook Texel begonnen met vaccineren; Als laatste...   \n",
       "14          0.881295  Forum voor Democratie Jacht  op extra stemmen;...   \n",
       "\n",
       "                                                Text2 Group  \\\n",
       "10  Het geld van de gemeenten raakt op, en dat gaa...  high   \n",
       "11  Na de doorrekeningen is iedere partij klimaatk...  high   \n",
       "12  'Opvallend en veelzeggend dat VVD en CDA hier ...  high   \n",
       "13  Excuses van de koning voor slavernij zijn onaf...  high   \n",
       "14  Baudet: corona niet bewust wereld in geslinger...  high   \n",
       "\n",
       "                  Date1                Date2               Publisher1  \\\n",
       "10  2021-02-28 06:52:07  2021-03-01 00:00:00               NOS nieuws   \n",
       "11  2021-03-01 00:00:00  2021-03-01 00:00:00  Het Financieele Dagblad   \n",
       "12  2021-02-28 22:15:58  2021-03-01 13:15:24             NOS liveblog   \n",
       "13  2021-02-27 17:37:33  2021-03-01 00:00:00             NOS liveblog   \n",
       "14  2021-03-01 00:00:00  2021-03-01 10:34:06          NRC Handelsblad   \n",
       "\n",
       "                 Publisher2      ID1      ID2  \\\n",
       "10          NRC Handelsblad  3287522  3285637   \n",
       "11  Het Financieele Dagblad  3290668  3290580   \n",
       "12             NOS liveblog  3287475  3287398   \n",
       "13          NRC Handelsblad  3287533  3285647   \n",
       "14               NOS nieuws  3285636  6290556   \n",
       "\n",
       "                                        proper_nouns1  \\\n",
       "10                                        Al, VVD, SP   \n",
       "11                  Tweede Kamer, Tweede Kamer, Romke   \n",
       "12                   Kristie, Jullie, Kristie, Jullie   \n",
       "13                                                 NH   \n",
       "14  Forum voor Democratie, Forum voor Democratie, ...   \n",
       "\n",
       "                                        proper_nouns2  \\\n",
       "10  Gemeentefinanci n Slechts, Johan Hamster, Financi   \n",
       "11  D66'er, CDA, Jaco Geurts, Planbureau voor de L...   \n",
       "12  CDA, CPB, PBL, CDA, CDA, Kamerlid Van Weyenber...   \n",
       "13           Slavernijverleden Ruttes, Tineke Bennema   \n",
       "14  Baudet, Forum voor Democratie-voorman Thierry ...   \n",
       "\n",
       "                                            keywords1  \\\n",
       "10  ['testwattenstaafjes', 'strubbelingen', 'mondk...   \n",
       "11  ['ijsmaker', 'romke', 'volksvertegenwoordiger'...   \n",
       "12  ['toeslagenaffaire', 'schandvlek', 'kristie', ...   \n",
       "13  ['gevaccineerd', 'vaccineren', 'waddeneiland',...   \n",
       "14  ['besmettingskansen', 'volmachtsstemmen', 'sch...   \n",
       "\n",
       "                                            keywords2  \\\n",
       "10  ['welzijnswerk', 'bezuinigt', '2024', 'zit', '...   \n",
       "11  ['doorrekeningen', 'geurts', 'leefomgeving', '...   \n",
       "12  ['rampspoed', 'doorrekeningen', 'reductie', 'o...   \n",
       "13  ['onafwendbaar', 'ruttes', 'opofferen', 'slave...   \n",
       "14  ['virussen', 'chinees', 'ebolavirus', 'ingesto...   \n",
       "\n",
       "                                                Topic  \\\n",
       "10  Main topic 1: Politics; Subtopic: Elections an...   \n",
       "11  Main topic 1: Politics; Subtopic: Elections an...   \n",
       "12  Main topic 1: Politics; Subtopic: Elections an...   \n",
       "13  Main topic 1: Health; Subtopic: Vaccination\\nM...   \n",
       "14  Main topic 1: Politics; Subtopic: Elections an...   \n",
       "\n",
       "                                           Topic_eval Topic_match  \\\n",
       "10  Evaluation: Yes, the two texts match on a main...           1   \n",
       "11  Evaluation: No, the two texts do not match on ...           0   \n",
       "12  Evaluation: Yes, the two texts match on a main...           1   \n",
       "13  Evaluation: No, the two texts do not match on ...           0   \n",
       "14  Evaluation: Yes, the two texts match on a main...           1   \n",
       "\n",
       "                                          News_events  \\\n",
       "10  Event 1: Political parties prepare for future ...   \n",
       "11  Event 1: Political parties are campaigning for...   \n",
       "12  Event 1: The toeslagenaffaire scandal and its ...   \n",
       "13  Event 1: The start of vaccination on the Wadde...   \n",
       "14  Event 1: Political party Forum voor Democratie...   \n",
       "\n",
       "                                           Event_eval Event_match  \n",
       "10  Evaluation: Both texts do not pertain to the s...           0  \n",
       "11  Evaluation: Both texts pertain to the same new...           1  \n",
       "12  Evaluation: Both texts do not match on a news ...           0  \n",
       "13  Evaluation: The two texts do not match on a ne...           0  \n",
       "14  Evaluation: Both texts pertain to the same new...           1  "
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112e5e6b-d3b9-4db1-9ec0-578020970acc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python 3.10",
   "language": "python",
   "name": "python_3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
